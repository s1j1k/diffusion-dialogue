{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b271ec",
   "metadata": {},
   "source": [
    "# Diffusion Model for Open Dialogue\n",
    "\n",
    "Simplified version\n",
    "\n",
    "References\n",
    "- DiffuSeq (cited below)\n",
    "\n",
    "Adapted from:\n",
    "\n",
    "[1] @inproceedings{gong2022diffuseq,\n",
    "  author = {Gong, Shansan and Li, Mukai and Feng, Jiangtao and Wu, Zhiyong and Kong, Lingpeng},\n",
    "  booktitle = {International Conference on Learning Representations, ICLR},\n",
    "  title = {{DiffuSeq}: Sequence to Sequence Text Generation with Diffusion Models},\n",
    "  year = 2023\n",
    "}\n",
    "\n",
    "[2] @article{gong2023diffuseqv2,\n",
    "  title={DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models},\n",
    "  author={Gong, Shansan and Li, Mukai and Feng, Jiangtao and Wu, Zhiyong and Kong, Lingpeng},\n",
    "  journal={arXiv preprint arXiv:2310.05793},\n",
    "  year={2023}\n",
    "}\n",
    "\n",
    "## Dataset\n",
    "\n",
    "- Use Commonsense Conversation dataset (from Reddit)\n",
    "\n",
    "\n",
    "in diffuseq text_datasets.py some steps to load the dataset itself\n",
    "\n",
    "- [ ] prepare datasets for training and validation in the format (stored as jsonl file?)\n",
    "```\n",
    "{\"src\": \"\", \"train\": \"\"}\n",
    "```\n",
    "\n",
    "- word embeddings (to be loaded?)\n",
    "- use a corpus\n",
    "\n",
    "## Dataset\n",
    "\n",
    "- Use Commonsense Conversation dataset (from Reddit)\n",
    "\n",
    "\n",
    "in diffuseq text_datasets.py some steps to load the dataset itself\n",
    "\n",
    "- [ ] prepare datasets for training and validation in the format (stored as jsonl file?)\n",
    "```\n",
    "{\"src\": \"\", \"train\": \"\"}\n",
    "```\n",
    "\n",
    "- word embeddings (to be loaded?)\n",
    "- use a corpus\n",
    "## Training\n",
    "\n",
    "Note that, in DiffuSeq, a model file is created to store all training progress, configuration etc. (in bash format poitning to raw files?)\n",
    "\n",
    "- denoise rate ?\n",
    "- using updates in v2 diffuseq took it from 2 days -> 11 hr learning time\n",
    "\n",
    "Set parameters\n",
    "\n",
    "DiffuSeq [1]\n",
    "12 layers of Transformer with 12 attention\n",
    "heads, where the time step embedding is plugged akin to the position embedding. \n",
    "The\n",
    "maximum sequence length is 128, with embedding dimension d = 128, diffusion steps T = 2;000\n",
    "and a square-root noise schedule. To reduce the out-of-vocabulary generation, we apply Byte Pair\n",
    "Encoding (Sennrich et al., 2016) to construct the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7804fbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yun\\anaconda3\\envs\\AI4E\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import datasets\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import torch as th\n",
    "from datasets import Dataset, DatasetDict\n",
    "from functools import partial\n",
    "from transformer_model import TransformerNetModel\n",
    "from diffusion_model import GaussianDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a6d8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "# choose embedding dimension = 128\n",
    "embedding_dim = 128\n",
    "\n",
    "# hidden size of time embedding\n",
    "hidden_dim = 128 \n",
    "\n",
    "# :param seq_len: the max sequence length (one-side).\n",
    "seq_len = 128 \n",
    "\n",
    "# TODO good value for this\n",
    "output_dims = 128\n",
    "\n",
    "# Same as diffuSeq\n",
    "num_diffusion_timesteps = 500\n",
    "\n",
    "lr=1e-04\n",
    "\n",
    "# TODO figure out what are the right params to recreate diffuSeq\n",
    "batch_size = 10\n",
    "lr = 0.001 # learning rate\n",
    "ema_rate = 0.999\n",
    "weight_decay = 0.01\n",
    "learning_steps = 1000\n",
    "\n",
    "\n",
    "# use GPU if available\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "    \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ab428",
   "metadata": {},
   "source": [
    "Get tokenizer from BERT <br>\n",
    "Embedding function $EMB(w)$ to map the discrete text $w$ into a continuous space. <br>\n",
    "Load the sample text data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23e0161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb = torch.nn.Embedding(tokenizer.vocab_size, embedding_dim)\n",
    "\n",
    "# initialize random embeddings\n",
    "torch.nn.init.normal_(model_emb.weight)\n",
    "\n",
    "model_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e57ae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Samples: 1000\n",
      "Validation Data Samples: 200\n",
      "Test Data Samples: 200\n"
     ]
    }
   ],
   "source": [
    "# read in the data in training data json file \n",
    "# TODO do this in a different way \n",
    "# TODO load actual dataset from Amazon\n",
    "\n",
    "# data_dir = \"./datasets/sample\"\n",
    "# path = f'{data_dir}/train.jsonl'\n",
    "\n",
    "# sentence_lst = {'src':[], 'trg': []}\n",
    "# with open(path, 'r') as f_reader:\n",
    "#         for row in f_reader:\n",
    "#             content = json.loads(row)\n",
    "#             sentence_lst['src'].append(content['src'].strip())\n",
    "#             sentence_lst['trg'].append(content['trg'].strip())\n",
    "\n",
    "# TODO use pandas to load faster? any other package can just load json directly rather than row by row\n",
    "\n",
    "data_dir = \"./datasets\"\n",
    "train_path = f'{data_dir}/train_full.jsonl'\n",
    "valid_path = f'{data_dir}/valid_full.jsonl'\n",
    "test_path = f'{data_dir}/test_full.jsonl'\n",
    "\n",
    "def load_data(path, limit=None):\n",
    "    sentence_lst = {'src':[], 'trg': []}\n",
    "    with open(path, 'r') as f_reader:\n",
    "        for i, row in enumerate(f_reader):\n",
    "            if limit and i >= limit:\n",
    "                break\n",
    "            content = json.loads(row)\n",
    "            sentence_lst['src'].append(content['src'].strip())\n",
    "            sentence_lst['trg'].append(content['trg'].strip())\n",
    "    return sentence_lst\n",
    "\n",
    "# Load datasets with size restriction\n",
    "train_limit = 1000  # Limit the size of the training set\n",
    "valid_limit = 200   # Limit the size of the validation set\n",
    "test_limit = 200    # Limit the size of the test set\n",
    "\n",
    "train_data = load_data(train_path, limit=train_limit)\n",
    "valid_data = load_data(valid_path, limit=valid_limit)\n",
    "test_data = load_data(test_path, limit=test_limit)\n",
    "\n",
    "print(\"Training Data Samples:\", len(train_data['src']))\n",
    "print(\"Validation Data Samples:\", len(valid_data['src']))\n",
    "print(\"Test Data Samples:\", len(test_data['src']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28080cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': 'jesus , what kind of concerts do you go to where people sucker punch you for being born tall ?',\n",
       " 'trg': 'the kind that allow bitter short people in . so basically all of them .'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['src'][0]\n",
    "raw_datasets = Dataset.from_dict(train_data)\n",
    "raw_datasets\n",
    "raw_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1502352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 30522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing training dataset (num_proc=4): 100%|████████████████████████████| 1000/1000 [00:03<00:00, 263.54 examples/s]\n",
      "Tokenizing validation dataset (num_proc=4): 100%|█████████████████████████████| 200/200 [00:04<00:00, 47.52 examples/s]\n",
      "Tokenizing test dataset (num_proc=4): 100%|███████████████████████████████████| 200/200 [00:03<00:00, 51.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n",
      "Training Set: 1000\n",
      "Validation Set: 200\n",
      "Test Set: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize dataset\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    input_id_x = tokenizer(examples['src'], add_special_tokens=True)['input_ids']\n",
    "    input_id_y = tokenizer(examples['trg'], add_special_tokens=True)['input_ids']\n",
    "    result_dict = {'input_id_x': input_id_x, 'input_id_y': input_id_y}\n",
    "    return result_dict\n",
    "\n",
    "# Use partial to pass the tokenizer to the tokenize_function\n",
    "tokenize_function_with_tokenizer = partial(tokenize_function, tokenizer=tokenizer)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "valid_dataset = Dataset.from_dict(valid_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_function_with_tokenizer,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=['src', 'trg'],\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Tokenizing training dataset\",\n",
    ")\n",
    "\n",
    "tokenized_valid_dataset = valid_dataset.map(\n",
    "    tokenize_function_with_tokenizer,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=['src', 'trg'],\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Tokenizing validation dataset\",\n",
    ")\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_function_with_tokenizer,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=['src', 'trg'],\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Tokenizing test dataset\",\n",
    ")\n",
    "\n",
    "# Combine into DatasetDict\n",
    "tokenized_datasets = DatasetDict({\n",
    "    'train': tokenized_train_dataset,\n",
    "    'validation': tokenized_valid_dataset,\n",
    "    'test': tokenized_test_dataset\n",
    "})\n",
    "\n",
    "print(\"Tokenization complete.\")\n",
    "print(\"Training Set:\", len(tokenized_datasets['train']))\n",
    "print(\"Validation Set:\", len(tokenized_datasets['validation']))\n",
    "print(\"Test Set:\", len(tokenized_datasets['test']))\n",
    "\n",
    "# tokenized_datasets\n",
    "# len(tokenized_datasets['train'][\"input_id_x\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf1a1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging and masking: 100%|███████████████████████████████████████████████| 1000/1000 [00:00<00:00, 26309.77 examples/s]\n",
      "Merging and masking: 100%|█████████████████████████████████████████████████| 200/200 [00:00<00:00, 19997.16 examples/s]\n",
      "Merging and masking: 100%|█████████████████████████████████████████████████| 200/200 [00:00<00:00, 19997.16 examples/s]\n",
      "Padding: 100%|███████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13289.26 examples/s]\n",
      "Padding: 100%|█████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 14282.86 examples/s]\n",
      "Padding: 100%|█████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 14282.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging, masking, and padding complete.\n",
      "Training Set: 1000\n",
      "Validation Set: 200\n",
      "Test Set: 200\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "}) padded dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to merge and mask sequences\n",
    "def merge_and_mask(group_lst):\n",
    "    lst = []\n",
    "    mask = []\n",
    "    for i in range(len(group_lst['input_id_x'])):\n",
    "        end_token = group_lst['input_id_x'][i][-1]\n",
    "        src = group_lst['input_id_x'][i][:-1]\n",
    "        trg = group_lst['input_id_y'][i][:-1]\n",
    "        while len(src) + len(trg) > seq_len - 3:\n",
    "            if len(src) > len(trg):\n",
    "                src.pop()\n",
    "            elif len(src) < len(trg):\n",
    "                trg.pop()\n",
    "            else:\n",
    "                src.pop()\n",
    "                trg.pop()\n",
    "        src.append(end_token)\n",
    "        trg.append(end_token)\n",
    "\n",
    "        lst.append(src + [tokenizer.sep_token_id] + trg)\n",
    "        mask.append([0] * (len(src) + 1))\n",
    "    group_lst['input_ids'] = lst\n",
    "    group_lst['input_mask'] = mask\n",
    "    return group_lst\n",
    "\n",
    "# Function to pad sequences\n",
    "def _collate_batch_helper(examples, pad_token_id, max_length, return_mask=False):\n",
    "    result = torch.full([len(examples), max_length], pad_token_id, dtype=torch.int64).tolist()\n",
    "    mask_ = torch.full([len(examples), max_length], pad_token_id, dtype=torch.int64).tolist()\n",
    "    for i, example in enumerate(examples):\n",
    "        curr_len = min(len(example), max_length)\n",
    "        result[i][:curr_len] = example[:curr_len]\n",
    "        mask_[i][:curr_len] = [1] * curr_len\n",
    "    if return_mask:\n",
    "        return result, mask_\n",
    "    return result\n",
    "\n",
    "def pad_function(group_lst):\n",
    "    max_length = seq_len\n",
    "    group_lst['input_ids'] = _collate_batch_helper(group_lst['input_ids'], tokenizer.pad_token_id, max_length)\n",
    "    group_lst['input_mask'] = _collate_batch_helper(group_lst['input_mask'], 1, max_length)\n",
    "    return group_lst\n",
    "\n",
    "# Apply merge and mask to the tokenized datasets\n",
    "tokenized_datasets = DatasetDict({\n",
    "    'train': tokenized_train_dataset,\n",
    "    'validation': tokenized_valid_dataset,\n",
    "    'test': tokenized_test_dataset\n",
    "})\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(\n",
    "    merge_and_mask,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    desc=\"Merging and masking\"\n",
    ")\n",
    "\n",
    "# Apply padding to the datasets\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    pad_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    desc=\"Padding\"\n",
    ")\n",
    "\n",
    "print(\"Merging, masking, and padding complete.\")\n",
    "print(\"Training Set:\", len(lm_datasets['train']))\n",
    "print(\"Validation Set:\", len(lm_datasets['validation']))\n",
    "print(\"Test Set:\", len(lm_datasets['test']))\n",
    "\n",
    "print(lm_datasets, 'padded dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7029b351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from train dataset: (tensor([[  101.,  2028.,  2515.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  1045.,  1005.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  2079.,  2017.,  ...,     0.,     0.,     0.],\n",
      "        ...,\n",
      "        [  101.,  2204.,  2518.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  2130.,  1037.,  ...,     0.,     0.,     0.],\n",
      "        [  101., 18301.,  2003.,  ...,     0.,     0.,     0.]],\n",
      "       device='cuda:0'), {'input_ids': tensor([[  101,  2028,  2515,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  2079,  2017,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2204,  2518,  ...,     0,     0,     0],\n",
      "        [  101,  2130,  1037,  ...,     0,     0,     0],\n",
      "        [  101, 18301,  2003,  ...,     0,     0,     0]], device='cuda:0',\n",
      "       dtype=torch.int32), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0', dtype=torch.int32)})\n",
      "Sample from validation dataset: (tensor([[ 101., 2017., 2031.,  ...,    0.,    0.,    0.],\n",
      "        [ 101., 4283., 1010.,  ...,    0.,    0.,    0.],\n",
      "        [ 101., 2087., 3442.,  ...,    0.,    0.,    0.],\n",
      "        ...,\n",
      "        [ 101., 2054., 2016.,  ...,    0.,    0.,    0.],\n",
      "        [ 101., 1045., 2052.,  ...,    0.,    0.,    0.],\n",
      "        [ 101., 2061., 2052.,  ...,    0.,    0.,    0.]], device='cuda:0'), {'input_ids': tensor([[ 101, 2017, 2031,  ...,    0,    0,    0],\n",
      "        [ 101, 4283, 1010,  ...,    0,    0,    0],\n",
      "        [ 101, 2087, 3442,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2054, 2016,  ...,    0,    0,    0],\n",
      "        [ 101, 1045, 2052,  ...,    0,    0,    0],\n",
      "        [ 101, 2061, 2052,  ...,    0,    0,    0]], device='cuda:0',\n",
      "       dtype=torch.int32), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0', dtype=torch.int32)})\n",
      "Sample from test dataset: [tensor([[  101.,  4151.,  4485.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  2196.,  2209.,  ...,     0.,     0.,     0.],\n",
      "        [  101., 19465.,  3475.,  ...,     0.,     0.,     0.],\n",
      "        ...,\n",
      "        [  101.,  4638.,  1996.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  2065.,  2308.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  2017., 24185.,  ...,     0.,     0.,     0.]]), {'input_ids': tensor([[  101,  4151,  4485,  ...,     0,     0,     0],\n",
      "        [  101,  2196,  2209,  ...,     0,     0,     0],\n",
      "        [  101, 19465,  3475,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4638,  1996,  ...,     0,     0,     0],\n",
      "        [  101,  2065,  2308,  ...,     0,     0,     0],\n",
      "        [  101,  2017, 24185,  ...,     0,     0,     0]], dtype=torch.int32), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], dtype=torch.int32)}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import numpy as np\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_datasets, split, model_emb=None):\n",
    "        self.text_datasets = text_datasets[split]\n",
    "        self.length = len(self.text_datasets)\n",
    "        self.model_emb = model_emb\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with torch.no_grad():\n",
    "            input_ids = self.text_datasets[idx]['input_ids']\n",
    "            hidden_state = self.model_emb(torch.tensor(input_ids))\n",
    "\n",
    "            arr = np.array(hidden_state, dtype=np.float32)\n",
    "\n",
    "            out_kwargs = {}\n",
    "            out_kwargs['input_ids'] = np.array(self.text_datasets[idx]['input_ids'])\n",
    "            out_kwargs['input_mask'] = np.array(self.text_datasets[idx]['input_mask'])\n",
    "\n",
    "            return arr, out_kwargs\n",
    "\n",
    "# Define model embedding\n",
    "model_emb = lambda x: x  # Placeholder: Replace with actual model embedding function\n",
    "\n",
    "# Create datasets for training, validation, and test sets\n",
    "train_dataset = TextDataset(lm_datasets, 'train', model_emb=model_emb)\n",
    "valid_dataset = TextDataset(lm_datasets, 'validation', model_emb=model_emb)\n",
    "test_dataset = TextDataset(lm_datasets, 'test', model_emb=model_emb)\n",
    "\n",
    "# Create data loaders with RandomSampler\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=RandomSampler(train_dataset))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, sampler=RandomSampler(valid_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=RandomSampler(test_dataset))\n",
    "\n",
    "def infinite_data_loader(data_loader, device):\n",
    "    while True:\n",
    "        for batch in data_loader:\n",
    "            batch_data = batch[0].to(device)\n",
    "            batch_cond = {k: v.to(device) for k, v in batch[1].items()}\n",
    "            yield batch_data, batch_cond\n",
    "\n",
    "# Convert the data loaders to infinite data loaders\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader_infinite = infinite_data_loader(train_loader, device)  # Ensure train_loader returns batches on the correct device\n",
    "valid_loader_infinite = infinite_data_loader(valid_loader, device)  # Ensure valid_loader returns batches on the correct device\n",
    "\n",
    "# Sample data from the infinite data loaders\n",
    "train_data_iter = iter(train_loader_infinite)\n",
    "valid_data_iter = iter(valid_loader_infinite)\n",
    "test_data_iter = iter(test_loader)  # Test data is usually not infinite\n",
    "\n",
    "print(\"Sample from train dataset:\", next(train_data_iter))\n",
    "print(\"Sample from validation dataset:\", next(valid_data_iter))\n",
    "print(\"Sample from test dataset:\", next(test_data_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "690e1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO explore other simplistic sample code\n",
    "# # https://github.com/lucidrains/denoising-diffusion-pytorch\n",
    "# # https://e-dorigatti.github.io/math/deep%20learning/2023/06/25/diffusion.html\n",
    "# # https://github.com/tanelp/tiny-diffusion\n",
    "# # NOTE adapted from diffuSeq, which is adapted from https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9970be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformSampler():\n",
    "    \"\"\"\n",
    "    A distribution over timesteps in the diffusion process, intended to reduce\n",
    "    variance of the objective.\n",
    "\n",
    "    Sampler performs unbiased importance sampling, in which the\n",
    "    objective's mean is unchanged.\n",
    "    TODO confirm & update comment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, diffusion):\n",
    "        self.diffusion = diffusion\n",
    "        self._weights = np.ones([diffusion.num_timesteps])\n",
    "\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    def sample(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        Importance-sample timesteps for a batch.\n",
    "\n",
    "        :param batch_size: the number of timesteps.\n",
    "        :param device: the torch device to save to.\n",
    "        :return: a tuple (timesteps, weights):\n",
    "                 - timesteps: a tensor of timestep indices.\n",
    "                 - weights: a tensor of weights to scale the resulting losses.\n",
    "        \"\"\"\n",
    "        w = self.weights()\n",
    "        p = w / np.sum(w)\n",
    "        indices_np = np.random.choice(len(p), size=(batch_size,), p=p)\n",
    "        indices = th.from_numpy(indices_np).long()#.to(device)\n",
    "        weights_np = 1 / (len(p) * p[indices_np])\n",
    "        weights = th.from_numpy(weights_np).float()#.to(device)\n",
    "        return indices, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb59963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for training loop\n",
    "def update_ema(target_params, source_params, rate=0.99):\n",
    "    \"\"\"\n",
    "    Update target parameters to be closer to those of source parameters using\n",
    "    an exponential moving average.\n",
    "\n",
    "    :param target_params: the target parameter sequence.\n",
    "    :param source_params: the source parameter sequence.\n",
    "    :param rate: the EMA rate (closer to 1 means slower).\n",
    "    \"\"\"\n",
    "    for targ, src in zip(target_params, source_params):\n",
    "        targ.detach().mul_(rate).add_(src, alpha=1 - rate)\n",
    "\n",
    "def zero_grad(model_params):\n",
    "    for param in model_params:\n",
    "        # Taken from https://pytorch.org/docs/stable/_modules/torch/optim/optimizer.html#Optimizer.add_param_group\n",
    "        if param.grad is not None:\n",
    "            param.grad.detach_()\n",
    "            param.grad.zero_()\n",
    "\n",
    "def log_loss_dict(diffusion, ts, losses):\n",
    "    for key, values in losses.items():\n",
    "        # logger.logkv_mean(key, values.mean().item())\n",
    "        # Log the quantiles (four quartiles, in particular).\n",
    "        for sub_t, sub_loss in zip(ts.cpu().numpy(), values.detach().cpu().numpy()):\n",
    "            quartile = int(4 * sub_t / diffusion.num_timesteps)\n",
    "            # logger.logkv_mean(f\"{key}_q{quartile}\", sub_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28d18f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yun\\anaconda3\\envs\\AI4E\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### The parameter count is 110184634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|                                                                      | 0/2000 [00:00<?, ?it/s]C:\\Users\\Yun\\anaconda3\\envs\\AI4E\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Training Progress:   2%|█                                                            | 35/2000 [00:25<23:42,  1.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 144\u001b[0m\n\u001b[0;32m    141\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m infinite_data_loader(train_loader, device)  \u001b[38;5;66;03m# Ensure train_loader returns batches on the correct device\u001b[39;00m\n\u001b[0;32m    142\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m infinite_data_loader(valid_loader, device)  \u001b[38;5;66;03m# Ensure valid_loader returns batches on the correct device\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m \u001b[43mTrainLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mema_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_interval\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 108\u001b[0m, in \u001b[0;36mTrainLoop.run_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_steps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_steps:\n\u001b[0;32m    107\u001b[0m     batch, cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    110\u001b[0m         batch_eval, cond_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_data)\n",
      "Cell \u001b[1;32mIn[12], line 75\u001b[0m, in \u001b[0;36mTrainLoop.run_step\u001b[1;34m(self, batch, cond)\u001b[0m\n\u001b[0;32m     73\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     74\u001b[0m cond \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m cond\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_normal()\n",
      "Cell \u001b[1;32mIn[12], line 97\u001b[0m, in \u001b[0;36mTrainLoop.forward_backward\u001b[1;34m(self, batch, cond)\u001b[0m\n\u001b[0;32m     95\u001b[0m t, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschedule_sampler\u001b[38;5;241m.\u001b[39msample(micro\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], device)\n\u001b[0;32m     96\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Ensure weights is on GPU\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmicro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmicro_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m loss \u001b[38;5;241m=\u001b[39m (losses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m weights)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     99\u001b[0m log_loss_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion, t, {k: v \u001b[38;5;241m*\u001b[39m weights \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mitems()})\n",
      "File \u001b[1;32m~\\Desktop\\AI4EA3\\diffusion_model.py:59\u001b[0m, in \u001b[0;36mGaussianDiffusion.training_losses\u001b[1;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_losses\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_losses_seq2seq(model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\AI4EA3\\diffusion_model.py:435\u001b[0m, in \u001b[0;36mGaussianDiffusion.training_losses_seq2seq\u001b[1;34m(self, model, x_start, t, model_kwargs, noise)\u001b[0m\n\u001b[0;32m    432\u001b[0m model_output \u001b[38;5;241m=\u001b[39m model(x_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_timesteps(t), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    433\u001b[0m terms[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mean_flat((target \u001b[38;5;241m-\u001b[39m model_output) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 435\u001b[0m model_out_x_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x0_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_xstart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    436\u001b[0m t0_mask \u001b[38;5;241m=\u001b[39m (t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    437\u001b[0m t0_loss \u001b[38;5;241m=\u001b[39m mean_flat((x_start_mean \u001b[38;5;241m-\u001b[39m model_out_x_start) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\Desktop\\AI4EA3\\diffusion_model.py:407\u001b[0m, in \u001b[0;36mGaussianDiffusion._x0_helper\u001b[1;34m(self, model_output, x, t)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_x0_helper\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, x, t):\n\u001b[0;32m    406\u001b[0m     device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m--> 407\u001b[0m     pred_xstart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_xstart_from_eps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     pred_prev, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_posterior_mean_variance(x_start\u001b[38;5;241m=\u001b[39mpred_xstart, x_t\u001b[38;5;241m=\u001b[39mx, t\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_xprev\u001b[39m\u001b[38;5;124m'\u001b[39m: pred_prev, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_xstart\u001b[39m\u001b[38;5;124m'\u001b[39m: pred_xstart}\n",
      "File \u001b[1;32m~\\Desktop\\AI4EA3\\diffusion_model.py:65\u001b[0m, in \u001b[0;36mGaussianDiffusion._predict_xstart_from_eps\u001b[1;34m(self, x_t, t, eps)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x_t\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m eps\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     63\u001b[0m device \u001b[38;5;241m=\u001b[39m x_t\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 65\u001b[0m     \u001b[43m_extract_into_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt_recip_alphas_cumprod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x_t\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;241m-\u001b[39m _extract_into_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqrt_recipm1_alphas_cumprod, t, x_t\u001b[38;5;241m.\u001b[39mshape, device) \u001b[38;5;241m*\u001b[39m eps\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32m~\\Desktop\\AI4EA3\\diffusion_model.py:652\u001b[0m, in \u001b[0;36m_extract_into_tensor\u001b[1;34m(arr, timesteps, broadcast_shape, device)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_into_tensor\u001b[39m(arr, timesteps, broadcast_shape, device):\n\u001b[0;32m    642\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;124;03m    Extract values from a 1-D numpy array for a batch of indices.\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;124;03m    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[timesteps]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(broadcast_shape):\n\u001b[0;32m    654\u001b[0m         res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW  # Make sure to import AdamW optimizer\n",
    "\n",
    "# Define the noise schedule\n",
    "num_diffusion_timesteps = 2000  # Reduce timesteps for faster experiments\n",
    "scale = 1000 / num_diffusion_timesteps\n",
    "beta_start = scale * 0.0001\n",
    "beta_end = scale * 0.02\n",
    "betas = np.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64)\n",
    "\n",
    "# Instantiate the diffusion model & transformer\n",
    "diffusion = GaussianDiffusion(betas=betas)\n",
    "\n",
    "# Specify correct dimensions\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dims = 128\n",
    "model = TransformerNetModel(vocab_size=vocab_size, input_dims=embedding_dim, hidden_t_dim=hidden_dim, output_dims=output_dims).to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'### The parameter count is {pytorch_total_params}')\n",
    "\n",
    "class TrainLoop():\n",
    "    def __init__(self, model, diffusion, data, batch_size, lr, ema_rate, weight_decay=0.0, learning_steps=0, eval_data=None, eval_interval=-1):\n",
    "        self.model = model.to(device)\n",
    "        self.ddp_model = model\n",
    "        self.diffusion = diffusion\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.microbatch = batch_size\n",
    "        self.lr = lr\n",
    "        self.ema_rate = [ema_rate] if isinstance(ema_rate, float) else [float(x) for x in ema_rate.split(\",\")]\n",
    "        self.schedule_sampler = UniformSampler(diffusion)\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_steps = learning_steps\n",
    "        self.eval_data = eval_data\n",
    "        self.eval_interval = eval_interval\n",
    "        self.step = 0\n",
    "        self.model_params = list(self.model.parameters())\n",
    "        self.master_params = self.model_params\n",
    "        self.opt = AdamW(self.master_params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "        self.ema_params = [copy.deepcopy(self.master_params) for _ in range(len(self.ema_rate))]\n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "\n",
    "    def _log_grad_norm(self):\n",
    "        sqsum = 0.0\n",
    "        for p in self.master_params:\n",
    "            if p.grad is not None:\n",
    "                sqsum += (p.grad ** 2).sum().item()\n",
    "\n",
    "    def _anneal_lr(self):\n",
    "        if not self.learning_steps:\n",
    "            return\n",
    "        frac_done = self.step / self.learning_steps\n",
    "        lr = self.lr * (1 - frac_done)\n",
    "        for param_group in self.opt.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    def optimize_normal(self):\n",
    "        self._log_grad_norm()\n",
    "        self._anneal_lr()\n",
    "        self.opt.step()\n",
    "        for rate, params in zip(self.ema_rate, self.ema_params):\n",
    "            update_ema(params, self.master_params, rate=rate)\n",
    "\n",
    "    def run_step(self, batch, cond):\n",
    "        batch = batch.to(device)\n",
    "        cond = {k: v.to(device) for k, v in cond.items()}\n",
    "        self.forward_backward(batch, cond)\n",
    "        self.optimize_normal()\n",
    "\n",
    "    def forward_only(self, batch, cond):\n",
    "        with torch.no_grad():\n",
    "            zero_grad(self.model_params)\n",
    "            for i in range(0, batch.shape[0], self.microbatch):\n",
    "                micro = batch[i: i + self.microbatch].to(device)  # Move batch to GPU\n",
    "                micro_cond = {k: v[i: i + self.microbatch].to(device) for k, v in cond.items()}  # Move cond to GPU\n",
    "                t, weights = self.schedule_sampler.sample(micro.shape[0], device)\n",
    "                weights = weights.to(device)  # Ensure weights is on GPU\n",
    "                losses = self.diffusion.training_losses(self.ddp_model, micro, t, model_kwargs=micro_cond)\n",
    "                log_loss_dict(self.diffusion, t, {f\"eval_{k}\": v * weights for k, v in losses.items()})\n",
    "                self.eval_losses.append(losses['loss'].mean().item())\n",
    "\n",
    "    def forward_backward(self, batch, cond):\n",
    "        zero_grad(self.model_params)\n",
    "        for i in range(0, batch.shape[0], self.microbatch):\n",
    "            micro = batch[i: i + self.microbatch].to(device)  # Move batch to GPU\n",
    "            micro_cond = {k: v[i: i + self.microbatch].to(device) for k, v in cond.items()}  # Move cond to GPU\n",
    "            t, weights = self.schedule_sampler.sample(micro.shape[0], device)\n",
    "            weights = weights.to(device)  # Ensure weights is on GPU\n",
    "            losses = self.diffusion.training_losses(self.ddp_model, micro, t, model_kwargs=micro_cond)\n",
    "            loss = (losses[\"loss\"] * weights).mean()\n",
    "            log_loss_dict(self.diffusion, t, {k: v * weights for k, v in losses.items()})\n",
    "            loss.backward()\n",
    "            self.train_losses.append(loss.item())\n",
    "\n",
    "    def run_loop(self):\n",
    "        try:\n",
    "            with tqdm(total=self.learning_steps, desc=\"Training Progress\") as pbar:\n",
    "                while not self.learning_steps or self.step < self.learning_steps:\n",
    "                    batch, cond = next(self.data)\n",
    "                    self.run_step(batch, cond)\n",
    "                    if self.eval_data is not None and self.step % self.eval_interval == 0:\n",
    "                        batch_eval, cond_eval = next(self.eval_data)\n",
    "                        self.forward_only(batch_eval, cond_eval)\n",
    "                    self.step += 1\n",
    "                    pbar.update(1)\n",
    "        except StopIteration:\n",
    "            print(\"Data loader exhausted. Saving the model...\")\n",
    "\n",
    "        # Save the model after training is completed\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.makedirs('checkpoints')\n",
    "        torch.save(self.model.state_dict(), 'checkpoints/trained_model.pth')\n",
    "        print(\"Model saved successfully.\")\n",
    "        \n",
    "        # Plotting the training and validation losses\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        if self.eval_losses:\n",
    "            plt.plot(self.eval_losses, label='Validation Loss')\n",
    "        plt.xlabel('Steps')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss over Time')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Adjusting the learning steps and validation interval\n",
    "learning_steps = 2000\n",
    "eval_interval = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = infinite_data_loader(train_loader, device)  # Ensure train_loader returns batches on the correct device\n",
    "valid_loader = infinite_data_loader(valid_loader, device)  # Ensure valid_loader returns batches on the correct device\n",
    "\n",
    "TrainLoop(\n",
    "    model=model.to(device),\n",
    "    diffusion=diffusion,\n",
    "    data=iter(train_loader),\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    ema_rate=ema_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    learning_steps=learning_steps,\n",
    "    eval_data=iter(valid_loader),\n",
    "    eval_interval=eval_interval\n",
    ").run_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccaf606",
   "metadata": {},
   "source": [
    "Instantiate all the classes for training loop <br>\n",
    "Set parameters for training\n",
    "\n",
    "Note the implementation details in DiffuSeq (first version) is\n",
    "\"The maximum sequence length is 128, with embedding dimension d = 128, diffusion steps T = 2000\n",
    "and a square-root noise schedule.\"\n",
    "\n",
    "How is it different in v2 or other papers?\n",
    "\n",
    "We have reached StopIteration Exception. Training completed.\n",
    "\n",
    "Get sample output using the forward step of the trained model.\n",
    "\n",
    "## Inference step (sampling / generation part)\n",
    "\n",
    "Once the training completed, we can start the inference step and get cross validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Ensure the device is set correctly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerNetModel(\n",
    "    vocab_size=vocab_size, \n",
    "    input_dims=embedding_dim, \n",
    "    hidden_t_dim=hidden_dim, \n",
    "    output_dims=output_dims\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load('checkpoints/trained_model.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def temperature_sampling(logits, temperature):\n",
    "    logits = logits / temperature\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    return torch.multinomial(probabilities, num_samples=1)\n",
    "\n",
    "def generate_text(model, tokenizer, prompt, max_length=128, num_timesteps=2000, temperature=1.0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Tokenize the input prompt\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "        # Get the embeddings for the input prompt\n",
    "        input_embeds = model.word_embedding(input_ids).to(device)\n",
    "\n",
    "        # Initialize noise\n",
    "        noise = torch.randn_like(input_embeds).to(device)\n",
    "\n",
    "        # Set up the diffusion process\n",
    "        diffusion = GaussianDiffusion(betas=np.linspace(1e-4, 0.02, num_timesteps))\n",
    "\n",
    "        # Sample from the model using p_sample_loop\n",
    "        samples = diffusion.p_sample_loop(\n",
    "            model=model,\n",
    "            shape=input_embeds.shape,\n",
    "            noise=noise,\n",
    "            device=device,\n",
    "            progress=True,\n",
    "            clamp_step=None  # Set this to a specific value if needed\n",
    "        )\n",
    "\n",
    "        # Convert the generated embeddings back to tokens\n",
    "        generated_ids = model.lm_head(samples[-1].to(device))\n",
    "\n",
    "        # Apply temperature sampling\n",
    "        generated_ids = generated_ids.view(-1, generated_ids.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n",
    "        sampled_ids = temperature_sampling(generated_ids, temperature)\n",
    "        sampled_ids = sampled_ids.view(1, -1)  # Reshape back to (1, seq_len)\n",
    "        \n",
    "        generated_text = tokenizer.decode(sampled_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "        \n",
    "        # Print input IDs and output IDs\n",
    "        print(f\"Input IDs: {input_ids}\")\n",
    "        print(f\"Output IDs: {sampled_ids}\")\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of Australia?\"\n",
    "generated_response = generate_text(model, tokenizer, prompt, temperature=0.7)\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Generated Response: {generated_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ee3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
