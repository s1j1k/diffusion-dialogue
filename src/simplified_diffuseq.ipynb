{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model for Open Dialogue\n",
    "\n",
    "Simplified version\n",
    "\n",
    "References\n",
    "- DiffuSeq (cited below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from:\n",
    "\n",
    "[1] @inproceedings{gong2022diffuseq,\n",
    "  author = {Gong, Shansan and Li, Mukai and Feng, Jiangtao and Wu, Zhiyong and Kong, Lingpeng},\n",
    "  booktitle = {International Conference on Learning Representations, ICLR},\n",
    "  title = {{DiffuSeq}: Sequence to Sequence Text Generation with Diffusion Models},\n",
    "  year = 2023\n",
    "}\n",
    "\n",
    "[2] @article{gong2023diffuseqv2,\n",
    "  title={DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models},\n",
    "  author={Gong, Shansan and Li, Mukai and Feng, Jiangtao and Wu, Zhiyong and Kong, Lingpeng},\n",
    "  journal={arXiv preprint arXiv:2310.05793},\n",
    "  year={2023}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO adapt from other codes\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "- Use Commonsense Conversation dataset (from Reddit)\n",
    "\n",
    "\n",
    "in diffuseq text_datasets.py some steps to load the dataset itself\n",
    "\n",
    "- [ ] prepare datasets for training and validation in the format (stored as jsonl file?)\n",
    "```\n",
    "{\"src\": \"\", \"train\": \"\"}\n",
    "```\n",
    "\n",
    "- word embeddings (to be loaded?)\n",
    "- use a corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Note that, in DiffuSeq, a model file is created to store all training progress, configuration etc. (in bash format poitning to raw files?)\n",
    "\n",
    "- denoise rate ?\n",
    "- using updates in v2 diffuseq took it from 2 days -> 11 hr learning time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiffuSeq [1]\n",
    "12 layers of Transformer with 12 attention\n",
    "heads, where the time step embedding is plugged akin to the position embedding. \n",
    "The\n",
    "maximum sequence length is 128, with embedding dimension d = 128, diffusion steps T = 2;000\n",
    "and a square-root noise schedule. To reduce the out-of-vocabulary generation, we apply Byte Pair\n",
    "Encoding (Sennrich et al., 2016) to construct the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose embedding dimension = 128\n",
    "embedding_dim = 128\n",
    "\n",
    "# hidden size of time embedding\n",
    "hidden_dim = 128 \n",
    "\n",
    "# :param seq_len: the max sequence length (one-side).\n",
    "seq_len = 128 \n",
    "\n",
    "# TODO good value for this\n",
    "output_dims = 128\n",
    "\n",
    "# Same as diffuSeq\n",
    "num_diffusion_timesteps = 2000\n",
    "\n",
    "lr=1e-04\n",
    "\n",
    "# TODO figure out what are the right params to recreate diffuSeq\n",
    "batch_size = 20 \n",
    "lr = 0.001 # learning rate\n",
    "ema_rate = 0.999\n",
    "weight_decay = 0.01\n",
    "learning_steps = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# use GPU if available\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tokenizer & embeddings\n",
    "Get tokenizer from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "class myTokenizer():\n",
    "    \"\"\"\n",
    "    Load tokenizer from bert config \n",
    "    \"\"\"\n",
    "    ################################################\n",
    "    ### You can custome your own tokenizer here. ###\n",
    "    ################################################\n",
    "    def __init__(self, args):\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token_id = tokenizer.sep_token_id\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        # TODO save\n",
    "        # tokenizer.save_pretrained(args.checkpoint_path)\n",
    "                \n",
    "        self.vocab_size = len(self.tokenizer)\n",
    "        # args.vocab_size = self.vocab_size # update vocab size in args\n",
    "    \n",
    "    def encode_token(self, sentences):\n",
    "        input_ids = self.tokenizer(sentences, add_special_tokens=True)['input_ids']\n",
    "        return input_ids\n",
    "        \n",
    "    def decode_token(self, seq):\n",
    "        seq = seq.squeeze(-1).tolist()\n",
    "        while len(seq)>0 and seq[-1] == self.pad_token_id:\n",
    "            seq.pop()\n",
    "        tokens = self.tokenizer.decode(seq)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallykalumba/dev/diffusion-dialogue/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "# TODO have actual args\n",
    "# args = {\"vocab_size\": 0}\n",
    "tokenizer = myTokenizer(args)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding function $EMB(w)$ to map the discrete text $w$ into a continuous space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.8799, -1.0476, -0.5496,  ..., -0.0408,  1.3313,  0.2616],\n",
       "        [-0.3120,  0.2555, -0.0969,  ...,  0.0627, -0.3481,  1.4801],\n",
       "        [ 1.3775,  0.6762,  0.6025,  ...,  0.6886,  2.2067, -0.1571],\n",
       "        ...,\n",
       "        [ 1.3659, -0.0026, -1.2989,  ...,  0.0580,  0.0269,  0.3280],\n",
       "        [-1.0132,  0.7414,  0.4947,  ..., -0.8917,  0.5757, -1.0895],\n",
       "        [ 1.1187, -1.0189,  1.5840,  ...,  0.8912, -0.3734,  0.3581]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb = torch.nn.Embedding(tokenizer.vocab_size, embedding_dim)\n",
    "\n",
    "# initialize random embeddings\n",
    "torch.nn.init.normal_(model_emb.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sample text data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data in training data json file \n",
    "# TODO do this in a different way \n",
    "# TODO load actual dataset from Amazon\n",
    "\n",
    "import json\n",
    "\n",
    "data_dir = \"./datasets/sample\"\n",
    "path = f'{data_dir}/train.jsonl'\n",
    "\n",
    "sentence_lst = {'src':[], 'trg': []}\n",
    "with open(path, 'r') as f_reader:\n",
    "        for row in f_reader:\n",
    "            content = json.loads(row)\n",
    "            sentence_lst['src'].append(content['src'].strip())\n",
    "            sentence_lst['trg'].append(content['trg'].strip())\n",
    "\n",
    "# TODO use pandas to load faster? any other package can just load json directly rather than row by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this is my favorite story arc . ca n't wait to see how he does in the tourney ! the show is my guarantee smile for the week .\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_lst['src'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['src', 'trg'],\n",
       "    num_rows: 19\n",
       "})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "raw_datasets = Dataset.from_dict(sentence_lst)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': \"this is my favorite story arc . ca n't wait to see how he does in the tourney ! the show is my guarantee smile for the week .\",\n",
       " 'trg': \"yea it 's hard not to have a smile on your face the entire episode\"}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset (num_proc=4): 100%|██████████| 19/19 [00:00<00:00, 19.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "        input_id_x = tokenizer.encode_token(examples['src'])\n",
    "        input_id_y = tokenizer.encode_token(examples['trg'])\n",
    "        result_dict = {'input_id_x': input_id_x, 'input_id_y': input_id_y}\n",
    "        return result_dict\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=['src', 'trg'],\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_id_x', 'input_id_y'],\n",
       "    num_rows: 19\n",
       "})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets[\"input_id_x\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to collate the batch\n",
    "def _collate_batch_helper(examples, pad_token_id, max_length, return_mask=False):\n",
    "    result = torch.full([len(examples), max_length], pad_token_id, dtype=torch.int64).tolist()\n",
    "    mask_ = torch.full([len(examples), max_length], pad_token_id, dtype=torch.int64).tolist()\n",
    "    for i, example in enumerate(examples):\n",
    "        curr_len = min(len(example), max_length)\n",
    "        result[i][:curr_len] = example[:curr_len]\n",
    "        mask_[i][:curr_len] = [1] * curr_len\n",
    "    if return_mask:\n",
    "        return result, mask_\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "merge and mask: 100%|██████████| 19/19 [00:00<00:00, 675.01 examples/s]\n",
      "padding: 100%|██████████| 19/19 [00:00<00:00, 668.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def merge_and_mask(group_lst):\n",
    "        lst = []\n",
    "        mask = []\n",
    "        for i in range(len(group_lst['input_id_x'])):\n",
    "            end_token = group_lst['input_id_x'][i][-1]\n",
    "            src = group_lst['input_id_x'][i][:-1]\n",
    "            trg = group_lst['input_id_y'][i][:-1]\n",
    "            while len(src) + len(trg) > seq_len - 3:\n",
    "                if len(src)>len(trg):\n",
    "                    src.pop()\n",
    "                elif len(src)<len(trg):\n",
    "                    trg.pop()\n",
    "                else:\n",
    "                    src.pop()\n",
    "                    trg.pop()\n",
    "            src.append(end_token)\n",
    "            trg.append(end_token)\n",
    "\n",
    "            lst.append(src + [tokenizer.sep_token_id] + trg)\n",
    "            mask.append([0]*(len(src)+1))\n",
    "        group_lst['input_ids'] = lst\n",
    "        group_lst['input_mask'] = mask\n",
    "        return group_lst\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(\n",
    "        merge_and_mask,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        desc=f\"merge and mask\",\n",
    "    )\n",
    "    \n",
    "def pad_function(group_lst):\n",
    "    max_length = seq_len\n",
    "    group_lst['input_ids'] = _collate_batch_helper(group_lst['input_ids'], tokenizer.pad_token_id, max_length)\n",
    "    group_lst['input_mask'] = _collate_batch_helper(group_lst['input_mask'], 1, max_length)\n",
    "    return group_lst\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "        pad_function,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        desc=f\"padding\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 19\n",
      "}) padded dataset\n"
     ]
    }
   ],
   "source": [
    "print(lm_datasets, 'padded dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "raw_datasets = datasets.DatasetDict()\n",
    "raw_datasets['train'] = lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
       "        num_rows: 19\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
       "    num_rows: 19\n",
       "})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into iterable data variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch as th\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_datasets, model_emb=None):\n",
    "        super().__init__()\n",
    "        self.text_datasets = text_datasets\n",
    "        self.length = len(self.text_datasets['train'])\n",
    "        self.model_emb = model_emb\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            input_ids = self.text_datasets['train'][idx]['input_ids']\n",
    "            hidden_state = self.model_emb(torch.tensor(input_ids))\n",
    "\n",
    "            # obtain the input vectors, only used when word embedding is fixed (not trained end-to-end)\n",
    "            arr = np.array(hidden_state, dtype=np.float32)\n",
    "\n",
    "            out_kwargs = {}\n",
    "            out_kwargs['input_ids'] = np.array(self.text_datasets['train'][idx]['input_ids'])\n",
    "            out_kwargs['input_mask'] = np.array(self.text_datasets['train'][idx]['input_mask'])\n",
    "\n",
    "            return arr, out_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE we need to be able to decode the tokens back to text space, function is available for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "train_dataset = TextDataset(raw_datasets, model_emb=model_emb)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "data = iter(data_loader)\n",
    "\n",
    "# NOTE don't use next here since we only have 1 batch to use\n",
    "# next(data)\n",
    "# TODO load data for the validation, inference differently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE next() will get the next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.70015603, -0.5362382 , -0.17453256, ...,  0.42478082,\n",
       "         -1.2100865 , -1.0228456 ],\n",
       "        [ 0.96171385,  0.0127369 ,  0.30993783, ..., -0.5008502 ,\n",
       "         -1.0706804 ,  1.5289253 ],\n",
       "        [ 0.69762117, -0.14255983,  0.19132029, ..., -0.41612247,\n",
       "          0.6816389 , -0.5276403 ],\n",
       "        ...,\n",
       "        [ 0.8799339 , -1.0476243 , -0.54961586, ..., -0.0408201 ,\n",
       "          1.3312643 ,  0.26159418],\n",
       "        [ 0.8799339 , -1.0476243 , -0.54961586, ..., -0.0408201 ,\n",
       "          1.3312643 ,  0.26159418],\n",
       "        [ 0.8799339 , -1.0476243 , -0.54961586, ..., -0.0408201 ,\n",
       "          1.3312643 ,  0.26159418]], dtype=float32),\n",
       " {'input_ids': array([  101,  2023,  2003,  2026,  5440,  2466,  8115,  1012,  6187,\n",
       "          1050,  1005,  1056,  3524,  2000,  2156,  2129,  2002,  2515,\n",
       "          1999,  1996,  2778,  5420,   999,  1996,  2265,  2003,  2026,\n",
       "         11302,  2868,  2005,  1996,  2733,  1012,   102,   102,   101,\n",
       "          6300,  2050,  2009,  1005,  1055,  2524,  2025,  2000,  2031,\n",
       "          1037,  2868,  2006,  2115,  2227,  1996,  2972,  2792,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       "  'input_mask': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model = TransformerNetModel(\n",
    "#         input_dims=hidden_dim,\n",
    "#         output_dims=(hidden_dim if not learn_sigma else hidden_dim*2),\n",
    "#         hidden_t_dim=hidden_t_dim,\n",
    "#         dropout=dropout,\n",
    "#         config_name=config_name,\n",
    "#         vocab_size=vocab_size,\n",
    "#         init_pretrained=use_plm_init\n",
    "#     )\n",
    "\n",
    "#     betas = gd.get_named_beta_schedule(noise_schedule, diffusion_steps)\n",
    "\n",
    "#     if not timestep_respacing:\n",
    "#         timestep_respacing = [diffusion_steps]\n",
    "\n",
    "#     diffusion = SpacedDiffusion(\n",
    "#         use_timesteps=space_timesteps(diffusion_steps, timestep_respacing),\n",
    "#         betas=betas,\n",
    "#         rescale_timesteps=rescale_timesteps,\n",
    "#         predict_xstart=predict_xstart,\n",
    "#         learn_sigmas = learn_sigma,\n",
    "#         sigma_small = sigma_small,\n",
    "#         use_kl = use_kl,\n",
    "#         rescale_learned_sigmas=rescale_learned_sigmas\n",
    "#     )\n",
    "\n",
    "# FIXME need to implement a way to save the model progress so that\n",
    "# trained model can be loaded later for assessment purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import torch as th\n",
    "\n",
    "def timestep_embedding(timesteps, dim, max_period=10000):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "\n",
    "    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n",
    "                      These may be fractional.\n",
    "    :param dim: the dimension of the output.\n",
    "    :param max_period: controls the minimum frequency of the embeddings.\n",
    "    :return: an [N x dim] Tensor of positional embeddings.\n",
    "    \"\"\"\n",
    "    half = dim // 2\n",
    "    freqs = th.exp(\n",
    "        -math.log(max_period) * th.arange(start=0, end=half, dtype=th.float32) / half\n",
    "    )#.to(device=timesteps.device)\n",
    "    args = timesteps[:, None].float() * freqs[None]\n",
    "    embedding = th.cat([th.cos(args), th.sin(args)], dim=-1)\n",
    "    if dim % 2:\n",
    "        embedding = th.cat([embedding, th.zeros_like(embedding[:, :1])], dim=-1)\n",
    "\n",
    "\n",
    "    print(\"N x dim Tensor of positional embeddings\", embedding)\n",
    "    print(\"Size of embedding\", embedding.size())\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME need to define TransformerNetModel\n",
    "#  The full Transformer model with attention and timestep embedding.\n",
    "\n",
    "# Adapted from diffuSeq\n",
    "\n",
    "# TODO code the transformer from scratch\n",
    "# TODO design the transformer from scratch\n",
    "\n",
    "from transformers import BertConfig, BertModel\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "\n",
    "class TransformerNetModel(nn.Module):\n",
    "    def __init__(self, vocab_size, input_dims, hidden_t_dim, output_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "        # FIXME set to an actual value\n",
    "        config.hidden_dropout_prob = 0\n",
    "\n",
    "        self.input_dims = input_dims\n",
    "        self.hidden_t_dim = hidden_t_dim\n",
    "        self.output_dims = output_dims\n",
    "        # self.dropout = dropout\n",
    "        self.hidden_size = config.hidden_size\n",
    "        print(\"transformer self.hidden_size\", self.hidden_size)\n",
    "\n",
    "        self.word_embedding = nn.Embedding(vocab_size, self.input_dims)\n",
    "        # Generate logits for hidden representation\n",
    "        self.lm_head = nn.Linear(self.input_dims, vocab_size)\n",
    "        with th.no_grad():\n",
    "            self.lm_head.weight = self.word_embedding.weight\n",
    "\n",
    "        # Time embeddings\n",
    "        time_embed_dim = hidden_t_dim * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            # params as input features * output features\n",
    "            nn.Linear(hidden_t_dim, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, config.hidden_size),\n",
    "        )\n",
    "\n",
    "        # Function to deal with having a hidden size not equal to input size, project to hidden size (?)\n",
    "        if self.input_dims != config.hidden_size:\n",
    "            # NOTE input_dims = 128\n",
    "            # hidden_size = 768\n",
    "            # self.input_up_proj = nn.Sequential(nn.Linear(input_dims, config.hidden_size),\n",
    "            #                                 nn.Tanh(), nn.Linear(config.hidden_size, config.hidden_size))\n",
    "            # FIXME this is trying to convert to hidden size 768 why??? it's already in the hidden siz \n",
    "            # FIXME this actually doesn't seeem necessary to do????\n",
    "            self.input_up_proj = nn.Sequential(nn.Linear(config.hidden_size, input_dims),\n",
    "                                             nn.Tanh(), nn.Linear(input_dims, input_dims))\n",
    "\n",
    "        # FIXME why is this temporary \n",
    "        temp_bert = BertModel.from_pretrained('bert-base-uncased', config=config)\n",
    "        self.word_embedding = temp_bert.embeddings.word_embeddings\n",
    "       \n",
    "       # FIXME why do we do this 2 times????\n",
    "        with th.no_grad():\n",
    "            self.lm_head.weight = self.word_embedding.weight\n",
    "        # self.lm_head.weight.requires_grad = False\n",
    "        # self.word_embedding.weight.requires_grad = False\n",
    "            \n",
    "        # TODO explain what is happening\n",
    "        self.input_transformers = temp_bert.encoder\n",
    "        # TODO explain what is doing\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "        self.position_embeddings = temp_bert.embeddings.position_embeddings\n",
    "        self.LayerNorm = temp_bert.embeddings.LayerNorm\n",
    "     \n",
    "        del temp_bert.embeddings\n",
    "        del temp_bert.pooler\n",
    "\n",
    "        # FIXME When does this get used\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # FIXME what is happening here\n",
    "        if self.output_dims != config.hidden_size:\n",
    "            self.output_down_proj = nn.Sequential(nn.Linear(config.hidden_size, config.hidden_size),\n",
    "                                                nn.Tanh(), nn.Linear(config.hidden_size, self.output_dims))\n",
    "    \n",
    "    def get_embeds(self, input_ids):\n",
    "        return self.word_embedding(input_ids)\n",
    "\n",
    "    def get_logits(self, hidden_repr):\n",
    "    # NOTE we make a simplifying assumption get the logits from linear layer\n",
    "        return self.lm_head(hidden_repr)\n",
    "                \n",
    "\n",
    "    # FIXME what is the difference btween BertModel, BertConfig, BertTokenizer, maybe define it all in one place config for tokenizer + embeddings?\n",
    "\n",
    "\n",
    "    def forward(self, x, timesteps):\n",
    "        # FIXME update string comment\n",
    "        \"\"\"\n",
    "        Apply the model to an input batch.\n",
    "\n",
    "        :param x: an [N x C x ...] Tensor of inputs.\n",
    "        :param timesteps: a 1-D batch of timesteps.\n",
    "        :return: an [N x C x ...] Tensor of outputs.\n",
    "        \"\"\"\n",
    "        print(\"Forward step\")\n",
    "        \n",
    "        # print(\"timesteps: a 1-D batch of timesteps:\",timesteps)\n",
    "        # print(\"self.hidden_t_dim\", self.hidden_t_dim)\n",
    "\n",
    "        # Embedded timestep\n",
    "\n",
    "        # print(\"1D batch of timesteps\",timesteps,timesteps.size())\n",
    "        \n",
    "        # Note timestep_embedding returns an N * dim Tensor of positional embeddings\n",
    "        # Note it gives N*128 embeddings\n",
    "\n",
    "        # expects a 1D tensor as input, with the size of the input tensor being (hidden_t_dim,)\n",
    "        emb_t = self.time_embed(timestep_embedding(timesteps, self.hidden_t_dim))\n",
    "\n",
    "        print(\"x: an [N x C x ...] Tensor of inputs\",\"size:\",x.size())\n",
    "        # NOTE x is already of size 19x128x768, so don't need to expand\n",
    "        # FIXME why doesn't this work as expected?\n",
    "        # if self.input_dims != self.hidden_size:\n",
    "        #     # FIXME change this to convert to 19x128x768 to ...x128\n",
    "        #     emb_x = self.input_up_proj(x)\n",
    "        # else:\n",
    "        # FIXME do we want this to get pushed to the correct size?\n",
    "        emb_x = x\n",
    "\n",
    "        seq_length = x.size(1)\n",
    "        position_ids = self.position_ids[:, : seq_length ]\n",
    "        print(\"emb_x.shape, emb_t.shape, self.position_embeddings\")\n",
    "        print(emb_x.shape, emb_t.shape, self.position_embeddings)\n",
    "        emb_inputs = self.position_embeddings(position_ids) + emb_x + emb_t.unsqueeze(1).expand(-1, seq_length, -1)\n",
    "        emb_inputs = self.dropout(self.LayerNorm(emb_inputs))\n",
    "\n",
    "        input_trans_hidden_states = self.input_transformers(emb_inputs).last_hidden_state\n",
    "\n",
    "        print(\"input_trans_hideden_states.shape\", input_trans_hidden_states.shape)\n",
    "        \n",
    "        # if self.output_dims != self.hidden_size:\n",
    "        #     # FIXME this should allow the output to be projected down to 19x128x128 so that it's osame as input data\n",
    "        #     h = self.output_down_proj(input_trans_hidden_states)\n",
    "        #     print(\"transformed h.shape\", h.shape)\n",
    "        # else:\n",
    "        # FIXME why this transofmration not required, it seems the model output compared for mse calculation is also having end dimension x768\n",
    "        h = input_trans_hidden_states\n",
    "        h = h.type(x.dtype)\n",
    "\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO explore other simplistic sample code\n",
    "# https://github.com/lucidrains/denoising-diffusion-pytorch\n",
    "# https://e-dorigatti.github.io/math/deep%20learning/2023/06/25/diffusion.html\n",
    "# https://github.com/tanelp/tiny-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE adapted from diffuSeq, which is adapted from https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42\n",
    "\n",
    "class GaussianDiffusion():\n",
    "    def __init__(\n",
    "        self,\n",
    "        betas): \n",
    "\n",
    "        # TODO consider adding these other parameters, where are they used, are they required?\n",
    "    #     predict_xstart,\n",
    "    #     rescale_learned_sigmas,\n",
    "    #     learn_sigmas,\n",
    "    #     sigma_small,\n",
    "    #     use_kl,\n",
    "    #     rescale_timesteps=False,\n",
    "    # ):\n",
    "    #     self.rescale_timesteps = rescale_timesteps\n",
    "    #     self.predict_xstart = predict_xstart\n",
    "    #     self.rescale_learned_sigmas = rescale_learned_sigmas\n",
    "    #     self.learn_sigmas = learn_sigmas\n",
    "    #     self.sigma_small = sigma_small\n",
    "    #     self.use_kl = use_kl\n",
    "\n",
    "    #    :param rescale_timesteps: if True, pass floating point timesteps into the\n",
    "    #                           model so that they are always scaled like in the\n",
    "    #                           original paper (0 to 1000).\n",
    "        # Assume true\n",
    "        self.rescale_timesteps = True\n",
    "\n",
    "        # Use float64 for accuracy.\n",
    "        betas = np.array(betas, dtype=np.float64)\n",
    "        self.betas = betas\n",
    "        assert len(betas.shape) == 1, \"betas must be 1-D\"\n",
    "        assert (betas > 0).all() and (betas <= 1).all()\n",
    "\n",
    "        self.num_timesteps = int(betas.shape[0])\n",
    "\n",
    "        # FIXME what is alphas? why?\n",
    "        alphas = 1.0 - betas\n",
    "        self.alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = np.append(1.0, self.alphas_cumprod[:-1])\n",
    "        self.alphas_cumprod_next = np.append(self.alphas_cumprod[1:], 0.0)\n",
    "        assert self.alphas_cumprod_prev.shape == (self.num_timesteps,)\n",
    "\n",
    "        # FIXME copied directly\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = np.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = np.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.log_one_minus_alphas_cumprod = np.log(1.0 - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = np.sqrt(1.0 / self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = np.sqrt(1.0 / self.alphas_cumprod - 1)\n",
    "\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = (\n",
    "            betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        # log calculation clipped because the posterior variance is 0 at the\n",
    "        # beginning of the diffusion chain.\n",
    "        self.posterior_log_variance_clipped = np.log(\n",
    "            np.append(self.posterior_variance[1], self.posterior_variance[1:])\n",
    "        )\n",
    "        self.posterior_mean_coef1 = (\n",
    "            betas * np.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_mean_coef2 = (\n",
    "            (1.0 - self.alphas_cumprod_prev)\n",
    "            * np.sqrt(alphas)\n",
    "            / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "\n",
    "    # NOTE the below comments from diffuSeq\n",
    "    # self.mapping_func = None # implement in train main()\n",
    "    # self.add_mask_noise = False # TODO\n",
    "\n",
    "    # FIXME copied directly from diffuSeq\n",
    "    def training_losses(self, model, *args, **kwargs):\n",
    "        self.model = model\n",
    "        return self.training_losses_seq2seq(model, *args, **kwargs)\n",
    "    \n",
    "    def _predict_xstart_from_eps(self, x_t, t, eps):\n",
    "        assert x_t.shape == eps.shape\n",
    "        return (\n",
    "            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n",
    "            - _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * eps\n",
    "        )\n",
    "\n",
    "    def _predict_eps_from_xstart(self, x_t, t, pred_xstart):\n",
    "        return (\n",
    "            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n",
    "            - pred_xstart\n",
    "        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n",
    "\n",
    "    def _scale_timesteps(self, t):\n",
    "        if self.rescale_timesteps:\n",
    "            return t.float() * (1000.0 / self.num_timesteps)\n",
    "        return t\n",
    "    \n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        \"\"\"\n",
    "        Get the distribution q(x_t | x_0).\n",
    "\n",
    "        :param x_start: the [N x C x ...] tensor of noiseless inputs.\n",
    "        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n",
    "        :return: A tuple (mean, variance, log_variance), all of x_start's shape.\n",
    "        \"\"\"\n",
    "        mean = (\n",
    "            _extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        )\n",
    "        variance = _extract_into_tensor(1.0 - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = _extract_into_tensor(\n",
    "            self.log_one_minus_alphas_cumprod, t, x_start.shape\n",
    "        )\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None, mask=None):\n",
    "        \"\"\"\n",
    "        Diffuse the data for a given number of diffusion steps.\n",
    "\n",
    "        In other words, sample from q(x_t | x_0).\n",
    "\n",
    "        :param x_start: the initial data batch.\n",
    "        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n",
    "        :param noise: if specified, the split-out normal noise.\n",
    "        :param mask: anchoring masked position\n",
    "        :return: A noisy version of x_start.\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = th.randn_like(x_start)\n",
    "        assert noise.shape == x_start.shape\n",
    "        x_t = (\n",
    "            _extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "            + _extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "        # FIXME why this isn't working\n",
    "        # if mask == None:\n",
    "        #     return x_t\n",
    "        # else:\n",
    "        mask = th.broadcast_to(mask.unsqueeze(dim=-1), x_start.shape)\n",
    "        return th.where(mask==0, x_start, x_t)\n",
    "        \n",
    "\n",
    "    def q_posterior_mean_variance(self, x_start, x_t, t):\n",
    "        \"\"\"\n",
    "        Compute the mean and variance of the diffusion posterior: \n",
    "            q(x_{t-1} | x_t, x_0)\n",
    "\n",
    "        \"\"\"\n",
    "        assert x_start.shape == x_t.shape\n",
    "        posterior_mean = (\n",
    "            _extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape) * x_start\n",
    "            + _extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = _extract_into_tensor(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = _extract_into_tensor(\n",
    "            self.posterior_log_variance_clipped, t, x_t.shape\n",
    "        )\n",
    "        assert (\n",
    "            posterior_mean.shape[0]\n",
    "            == posterior_variance.shape[0]\n",
    "            == posterior_log_variance_clipped.shape[0]\n",
    "            == x_start.shape[0]\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(\n",
    "        self, model, x, t, clip_denoised=True, denoised_fn=None, model_kwargs=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Apply the model to get p(x_{t-1} | x_t), as well as a prediction of\n",
    "        the initial x, x_0.\n",
    "\n",
    "        :param model: the model, which takes a signal and a batch of timesteps\n",
    "                      as input.\n",
    "        :param x: the [N x C x ...] tensor at time t.\n",
    "        :param t: a 1-D Tensor of timesteps.\n",
    "        :param clip_denoised: if True, clip the denoised signal into [-1, 1].\n",
    "        :param denoised_fn: if not None, a function which applies to the\n",
    "            x_start prediction before it is used to sample. Applies before\n",
    "            clip_denoised.\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :return: a dict with the following keys:\n",
    "                 - 'mean': the model mean output.\n",
    "                 - 'variance': the model variance output.\n",
    "                 - 'log_variance': the log of 'variance'.\n",
    "                 - 'pred_xstart': the prediction for x_0.\n",
    "        \"\"\"\n",
    "        if model_kwargs is None:\n",
    "            model_kwargs = {}\n",
    "\n",
    "        B, C = x.size(0), x.size(-1)\n",
    "        assert t.shape == (B,)\n",
    "        # print(x.shape)\n",
    "        model_output = model(x, self._scale_timesteps(t), **model_kwargs)\n",
    "        \n",
    "        # for fixedlarge, we set the initial (log-)variance like so\n",
    "        # to get a better decoder log likelihood.\n",
    "        model_variance = np.append(self.posterior_variance[1], self.betas[1:])\n",
    "        model_log_variance = np.log(np.append(self.posterior_variance[1], self.betas[1:]))\n",
    "        \n",
    "        model_variance = _extract_into_tensor(model_variance, t, x.shape)\n",
    "        model_log_variance = _extract_into_tensor(model_log_variance, t, x.shape)\n",
    "\n",
    "        def process_xstart(x):\n",
    "            if denoised_fn is not None:\n",
    "                # print(denoised_fn)\n",
    "                x = denoised_fn(x, t)\n",
    "            if clip_denoised:\n",
    "                return x.clamp(-1, 1)\n",
    "            return x\n",
    "\n",
    "        # if self.predict_xstart:\n",
    "        #     pred_xstart = process_xstart(model_output)\n",
    "        # else:\n",
    "            ### model is used to predict eps\n",
    "        pred_xstart = process_xstart(\n",
    "            self._predict_xstart_from_eps(x_t=x, t=t, eps=model_output)\n",
    "        )\n",
    "\n",
    "        model_mean, _, _ = self.q_posterior_mean_variance(\n",
    "            x_start=pred_xstart, x_t=x, t=t\n",
    "        )\n",
    "\n",
    "        assert (\n",
    "            model_mean.shape == model_log_variance.shape == pred_xstart.shape == x.shape\n",
    "        )\n",
    "        return {\n",
    "            \"mean\": model_mean,\n",
    "            \"variance\": model_variance,\n",
    "            \"log_variance\": model_log_variance,\n",
    "            \"pred_xstart\": pred_xstart,\n",
    "        }\n",
    "\n",
    "    def p_sample(\n",
    "        self, model, x, t, clip_denoised=True, denoised_fn=None, model_kwargs=None,\n",
    "            top_p=None, mask=None, x_start=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Sample x_{t-1} from the model at the given timestep.\n",
    "\n",
    "        :param model: the model to sample from.\n",
    "        :param x: the current tensor at x_{t-1}.\n",
    "        :param t: the value of t, starting at 0 for the first diffusion step.\n",
    "        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].\n",
    "        :param denoised_fn: if not None, a function which applies to the\n",
    "            x_start prediction before it is used to sample.\n",
    "        :param mask: anchoring masked position to x_start\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :return: a dict containing the following keys:\n",
    "                 - 'sample': a random sample from the model.\n",
    "                 - 'pred_xstart': a prediction of x_0.\n",
    "        \"\"\"\n",
    "        out = self.p_mean_variance(\n",
    "            model,\n",
    "            x,\n",
    "            t,\n",
    "            clip_denoised=clip_denoised,\n",
    "            denoised_fn=denoised_fn,\n",
    "            model_kwargs=model_kwargs,\n",
    "        )\n",
    "        if top_p is not None and top_p > 0:\n",
    "            # print('top_p sampling')\n",
    "            noise = th.randn_like(x)\n",
    "            replace_mask = th.abs(noise) > top_p\n",
    "            while replace_mask.any():\n",
    "                noise[replace_mask] = th.randn_like(noise[replace_mask])\n",
    "                replace_mask = th.abs(noise) > top_p\n",
    "            assert (th.abs(noise) <= top_p).all()\n",
    "\n",
    "        else:\n",
    "            noise = th.randn_like(x)\n",
    "\n",
    "        nonzero_mask = (\n",
    "            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))\n",
    "        )  # no noise when t == 0\n",
    "        sample = out[\"mean\"] + nonzero_mask * th.exp(0.5 * out[\"log_variance\"]) * noise\n",
    "        if mask == None:\n",
    "            pass\n",
    "        else:\n",
    "            sample = th.where(mask==0, x_start, sample)\n",
    "\n",
    "        return {\n",
    "            \"sample\": sample, \n",
    "            \"pred_xstart\": out[\"pred_xstart\"],\n",
    "            \"greedy_mean\": out[\"mean\"], \n",
    "            \"out\": out\n",
    "        }\n",
    "\n",
    "    \n",
    "    def p_sample_loop(\n",
    "        self,\n",
    "        model,\n",
    "        shape,\n",
    "        noise=None,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        device=None,\n",
    "        progress=False,\n",
    "        top_p=None,\n",
    "        clamp_step=None,\n",
    "        clamp_first=None,\n",
    "        mask=None,\n",
    "        x_start=None,\n",
    "        gap=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate samples from the model.\n",
    "\n",
    "        :param model: the model module.\n",
    "        :param shape: the shape of the samples, (N, C, H, W).\n",
    "        :param noise: if specified, the noise from the encoder to sample.\n",
    "                      Should be of the same shape as `shape`.\n",
    "        :param clip_denoised: if True, clip x_start predictions to [-1, 1].\n",
    "        :param denoised_fn: if not None, a function which applies to the\n",
    "            x_start prediction before it is used to sample.\n",
    "        :param mask: anchoring masked position to x_start\n",
    "        :param clamp_step: in clamp_first mode, choose end clamp step, otherwise starting clamp step\n",
    "        :param clamp_first: bool, clamp_first mode\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :param device: if specified, the device to create the samples on.\n",
    "                       If not specified, use a model parameter's device.\n",
    "        :param progress: if True, show a tqdm progress bar.\n",
    "        :return: a non-differentiable batch of samples.\n",
    "        \"\"\"\n",
    "        final = []\n",
    "        for sample in self.p_sample_loop_progressive(\n",
    "            model,\n",
    "            shape,\n",
    "            noise=noise,\n",
    "            clip_denoised=clip_denoised,\n",
    "            denoised_fn=denoised_fn,\n",
    "            model_kwargs=model_kwargs,\n",
    "            device=device,\n",
    "            progress=progress,\n",
    "            top_p=top_p,\n",
    "            clamp_step=clamp_step,\n",
    "            clamp_first=clamp_first,\n",
    "            mask=mask,\n",
    "            x_start=x_start\n",
    "        ):\n",
    "            final.append(sample['sample'])\n",
    "        return final\n",
    "\n",
    "    def p_sample_loop_progressive(\n",
    "        self,\n",
    "        model,\n",
    "        shape,\n",
    "        noise=None,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        device=None,\n",
    "        progress=False,\n",
    "        top_p=None,\n",
    "        clamp_step=None,\n",
    "        clamp_first=None,\n",
    "        mask=None,\n",
    "        x_start=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate samples from the model and yield intermediate samples from\n",
    "        each timestep of diffusion.\n",
    "\n",
    "        Arguments are the same as p_sample_loop().\n",
    "        Returns a generator over dicts, where each dict is the return value of\n",
    "        p_sample().\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = next(model.parameters()).device\n",
    "        assert isinstance(shape, (tuple, list))\n",
    "        if noise is not None: # custom your the start point of x_0\n",
    "            sample_x = noise\n",
    "        else:\n",
    "            sample_x = th.randn(*shape, device=device)\n",
    "        indices = list(range(self.num_timesteps))[::-1]\n",
    "\n",
    "        if progress:\n",
    "            # Lazy import so that we don't depend on tqdm.\n",
    "            from tqdm.auto import tqdm\n",
    "            indices = tqdm(indices)\n",
    "\n",
    "        for i in indices: # from T to 0\n",
    "            t = th.tensor([i] * shape[0], device=device)\n",
    "            if not clamp_first:\n",
    "                if i > clamp_step:\n",
    "                    denoised_fn_cur = None\n",
    "                else:\n",
    "                    denoised_fn_cur = denoised_fn\n",
    "            else:\n",
    "                if i >= clamp_step:\n",
    "                    denoised_fn_cur = denoised_fn\n",
    "                else:\n",
    "                    denoised_fn_cur = None\n",
    "            with th.no_grad():\n",
    "                out = self.p_sample(\n",
    "                    model,\n",
    "                    sample_x,\n",
    "                    t,\n",
    "                    clip_denoised=clip_denoised,\n",
    "                    denoised_fn=denoised_fn_cur,\n",
    "                    model_kwargs=model_kwargs,\n",
    "                    top_p=top_p,\n",
    "                    mask=mask,\n",
    "                    x_start=x_start\n",
    "                )\n",
    "                yield out\n",
    "                sample_x = out[\"sample\"]\n",
    "\n",
    "\n",
    "    def _get_x_start(self, x_start_mean, std):\n",
    "        '''\n",
    "        Word embedding projection from {Emb(w)} to {x_0}\n",
    "        :param x_start_mean: word embedding\n",
    "        :return: x_0\n",
    "        '''\n",
    "        noise = th.randn_like(x_start_mean)\n",
    "        assert noise.shape == x_start_mean.shape\n",
    "        # print(x_start_mean.device, noise.device)\n",
    "        return (\n",
    "             x_start_mean + std * noise\n",
    "        )\n",
    "\n",
    "    def _token_discrete_loss(self, x_t, get_logits, input_ids, mask=None, truncate=False, t=None):\n",
    "        '''\n",
    "        the loss of -log p(w|z_0)\n",
    "        :param x_start_mean: word embedding\n",
    "        :return: x_0\n",
    "        '''\n",
    "        reshaped_x_t = x_t\n",
    "        logits = get_logits(reshaped_x_t)  # bsz, seqlen, vocab\n",
    "        # print(logits.shape)\n",
    "        loss_fct = th.nn.CrossEntropyLoss(reduction='none')\n",
    "        decoder_nll = loss_fct(logits.view(-1, logits.size(-1)), input_ids.view(-1)).view(input_ids.shape)\n",
    "        if mask != None:\n",
    "            decoder_nll *= mask\n",
    "        # print(decoder_nll.shape)\n",
    "        if mask != None:\n",
    "            decoder_nll = decoder_nll.sum(dim=-1)/mask.sum(dim=-1)\n",
    "        else:\n",
    "            decoder_nll = decoder_nll.mean(dim=-1)\n",
    "\n",
    "        return decoder_nll\n",
    "\n",
    "    def _x0_helper(self, model_output, x, t):\n",
    "\n",
    "        # if self.predict_xstart:\n",
    "        #     pred_xstart = model_output\n",
    "        #     pred_prev, _, _ = self.q_posterior_mean_variance(\n",
    "        #         x_start=pred_xstart, x_t=x, t=t\n",
    "        #     )\n",
    "\n",
    "        # else: # predict eps\n",
    "        pred_xstart = self._predict_xstart_from_eps(x_t=x, t=t, eps=model_output)\n",
    "    \n",
    "        pred_prev, _, _ = self.q_posterior_mean_variance(\n",
    "            x_start=pred_xstart, x_t=x, t=t\n",
    "        )\n",
    "\n",
    "        return {'pred_xprev':pred_prev, 'pred_xstart':pred_xstart}\n",
    "\n",
    "    def training_losses_seq2seq(self, model, x_start, t, model_kwargs=None, noise=None):\n",
    "        \"\"\"\n",
    "        Compute training losses for a single timestep.\n",
    "\n",
    "        :param model: the model to evaluate loss on.\n",
    "        :param x_start: the [N x C x ...] tensor of inputs. # not used unless fixing the input embeddings\n",
    "        :param t: a batch of timestep indices.\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :param noise: if specified, the specific Gaussian noise to try to remove.\n",
    "        :return: a dict with the key \"loss\" containing a tensor of shape [N].\n",
    "                 Some mean or variance settings may also have other keys.\n",
    "        \"\"\"\n",
    "        x_start_fix = x_start # save the orignal x_0\n",
    "\n",
    "        # Note this is size 19 x 128 x 128 \n",
    "        print(\"x_start size\", x_start.size())\n",
    "\n",
    "        assert 'input_ids' in model_kwargs\n",
    "        input_ids_x = model_kwargs.pop('input_ids')#.to(t.device)\n",
    "        input_ids_mask = model_kwargs.pop('input_mask')#.to(t.device)\n",
    "        x_start_mean = model.get_embeds(input_ids_x)\n",
    "\n",
    "        # 12 x 128 x 768 once you get the embeds \n",
    "        print(\"x_start_mean size\", x_start_mean.size())\n",
    "        \n",
    "        std = _extract_into_tensor(self.sqrt_one_minus_alphas_cumprod,\n",
    "                                   th.tensor([0]).to(x_start_mean.device),\n",
    "                                   x_start_mean.shape)\n",
    "        # print(std.shape, )\n",
    "        # x_start_log_var = 2 * th.log(std)\n",
    "        x_start = self._get_x_start(x_start_mean, std)\n",
    "        # print(x_start_mean.shape, x_start.shape)\n",
    "        if noise is None:\n",
    "            noise = th.randn_like(x_start)\n",
    "\n",
    "        # Diffuse the data in x_start (return a noisy version)\n",
    "        x_t = self.q_sample(x_start, t, noise=noise, mask=input_ids_mask) # reparametrization trick.\n",
    "\n",
    "        get_logits = model.get_logits\n",
    "\n",
    "        terms = {}\n",
    "\n",
    "        target = x_start\n",
    "        # FIXME try to fix dimensionality error\n",
    "        model_output = model(x_t, self._scale_timesteps(t), **model_kwargs)\n",
    "        # FIXME why these aren't the same shape, why is this asserted when the conversion shows moving to hidden dimension\n",
    "        # assert model_output.shape == target.shape == x_start.shape\n",
    "        terms[\"mse\"] = mean_flat((target - model_output) ** 2)\n",
    "\n",
    "        model_out_x_start = self._x0_helper(model_output, x_t, t)['pred_xstart'] # predicted_xstart = model_output\n",
    "        t0_mask = (t == 0)\n",
    "        t0_loss = mean_flat((x_start_mean - model_out_x_start) ** 2)\n",
    "        terms[\"mse\"] = th.where(t0_mask, t0_loss, terms[\"mse\"])\n",
    "\n",
    "        # tT_mask = (t == self.num_timesteps - 1)\n",
    "        out_mean, _, _ = self.q_mean_variance(x_start, th.LongTensor([self.num_timesteps - 1]).to(x_start.device))\n",
    "        tT_loss =  mean_flat(out_mean ** 2)\n",
    "\n",
    "        decoder_nll = self._token_discrete_loss(x_start, get_logits, input_ids_x) # embedding regularization\n",
    "        terms[\"nll\"] = self._token_discrete_loss(model_out_x_start, get_logits, input_ids_x, mask=input_ids_mask, truncate=True, t=t) # x_0->model_out_x_start\n",
    "        # assert (model.lm_head.weight == model.word_embedding.weight).all()\n",
    "\n",
    "        terms[\"loss\"] = terms[\"mse\"] + decoder_nll + tT_loss\n",
    "\n",
    "        return terms\n",
    "\n",
    "    def ddim_sample(\n",
    "        self,\n",
    "        model,\n",
    "        x,\n",
    "        t,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        eta=0.0,\n",
    "        langevin_fn=None,\n",
    "        mask=None,\n",
    "        x_start=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Sample x_{t-1} from the model using DDIM.\n",
    "\n",
    "        Same usage as p_sample().\n",
    "        \"\"\"\n",
    "        out = self.p_mean_variance(\n",
    "            model,\n",
    "            x,\n",
    "            t,\n",
    "            clip_denoised=clip_denoised,\n",
    "            denoised_fn=denoised_fn,\n",
    "            model_kwargs=model_kwargs,\n",
    "        )\n",
    "        # Usually our model outputs epsilon, but we re-derive it\n",
    "        # in case we used x_start or x_prev prediction.\n",
    "        eps = self._predict_eps_from_xstart(x, t, out[\"pred_xstart\"])\n",
    "        alpha_bar = _extract_into_tensor(self.alphas_cumprod, t, x.shape)\n",
    "        alpha_bar_prev = _extract_into_tensor(self.alphas_cumprod_prev, t, x.shape)\n",
    "        sigma = (\n",
    "            eta\n",
    "            * th.sqrt((1 - alpha_bar_prev) / (1 - alpha_bar))\n",
    "            * th.sqrt(1 - alpha_bar / alpha_bar_prev)\n",
    "        )\n",
    "        # Equation 12.\n",
    "        noise = th.randn_like(x)\n",
    "        mean_pred = (\n",
    "            out[\"pred_xstart\"] * th.sqrt(alpha_bar_prev)\n",
    "            + th.sqrt(1 - alpha_bar_prev - sigma ** 2) * eps\n",
    "        )\n",
    "        nonzero_mask = (\n",
    "            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))\n",
    "        )  # no noise when t == 0\n",
    "        # print(sigma.mean())\n",
    "        sample = mean_pred + nonzero_mask * sigma * noise\n",
    "        if langevin_fn:\n",
    "            print(t.shape)\n",
    "            sample=langevin_fn(sample, mean_pred, sigma, self.alphas_cumprod_prev[t[0]], t, x)\n",
    "        \n",
    "        if mask == None:\n",
    "            pass\n",
    "        else:\n",
    "            sample = th.where(mask==0, x_start, sample)\n",
    "        \n",
    "        return {\"sample\": sample, \"pred_xstart\": out[\"pred_xstart\"]}\n",
    "\n",
    "    def ddim_reverse_sample(\n",
    "        self,\n",
    "        model,\n",
    "        x,\n",
    "        t,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        eta=0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Sample x_{t+1} from the model using DDIM reverse ODE.\n",
    "        \"\"\"\n",
    "        assert eta == 0.0, \"Reverse ODE only for deterministic path\"\n",
    "        out = self.p_mean_variance(\n",
    "            model,\n",
    "            x,\n",
    "            t,\n",
    "            clip_denoised=clip_denoised,\n",
    "            denoised_fn=denoised_fn,\n",
    "            model_kwargs=model_kwargs,\n",
    "        )\n",
    "        # Usually our model outputs epsilon, but we re-derive it\n",
    "        # in case we used x_start or x_prev prediction.\n",
    "        eps = (\n",
    "            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x.shape) * x\n",
    "            - out[\"pred_xstart\"]\n",
    "        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x.shape)\n",
    "        alpha_bar_next = _extract_into_tensor(self.alphas_cumprod_next, t, x.shape)\n",
    "\n",
    "        # Equation 12. reversed\n",
    "        mean_pred = (\n",
    "            out[\"pred_xstart\"] * th.sqrt(alpha_bar_next)\n",
    "            + th.sqrt(1 - alpha_bar_next) * eps\n",
    "        )\n",
    "\n",
    "        return {\"sample\": mean_pred, \"pred_xstart\": out[\"pred_xstart\"]}\n",
    "\n",
    "    def ddim_sample_loop(\n",
    "        self,\n",
    "        model,\n",
    "        shape,\n",
    "        noise=None,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        device=None,\n",
    "        progress=False,\n",
    "        top_p=None,\n",
    "        clamp_step=None,\n",
    "        clamp_first=None,\n",
    "        mask=None,\n",
    "        x_start=None,\n",
    "        gap=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate samples from the model using DDIM.\n",
    "        :param gap: compute ddim sampling for each {gap} step\n",
    "\n",
    "        Same usage as p_sample_loop().\n",
    "        \"\"\"\n",
    "        final = []\n",
    "        for sample in self.ddim_sample_loop_progressive(\n",
    "            model,\n",
    "            shape,\n",
    "            noise=noise,\n",
    "            clip_denoised=clip_denoised,\n",
    "            denoised_fn=denoised_fn,\n",
    "            model_kwargs=model_kwargs,\n",
    "            device=device,\n",
    "            progress=progress,\n",
    "            mask=mask,\n",
    "            x_start=x_start,\n",
    "            gap = gap\n",
    "        ):\n",
    "            final.append(sample['sample'])\n",
    "        return final\n",
    "\n",
    "    def ddim_sample_loop_progressive(\n",
    "        self,\n",
    "        model,\n",
    "        shape,\n",
    "        noise=None,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        device=None,\n",
    "        progress=False,\n",
    "        eta=0.0,\n",
    "        langevin_fn=None,\n",
    "        mask=None,\n",
    "        x_start=None,\n",
    "        gap=1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Use DDIM to sample from the model and yield intermediate samples from\n",
    "        each timestep of DDIM.\n",
    "\n",
    "        Same usage as p_sample_loop_progressive().\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = next(model.parameters()).device\n",
    "        assert isinstance(shape, (tuple, list))\n",
    "        if noise is not None:\n",
    "            sample_x = noise\n",
    "        else:\n",
    "            sample_x = th.randn(*shape, device=device)\n",
    "        indices = list(range(self.num_timesteps))[::-1][::gap]\n",
    "\n",
    "        if progress:\n",
    "            # Lazy import so that we don't depend on tqdm.\n",
    "            from tqdm.auto import tqdm\n",
    "\n",
    "            indices = tqdm(indices)\n",
    "\n",
    "        for i in indices:\n",
    "            t = th.tensor([i] * shape[0], device=device)\n",
    "            with th.no_grad():\n",
    "                out = self.ddim_sample(\n",
    "                    model,\n",
    "                    sample_x,\n",
    "                    t,\n",
    "                    clip_denoised=clip_denoised,\n",
    "                    denoised_fn=denoised_fn,\n",
    "                    model_kwargs=model_kwargs,\n",
    "                    mask=mask,\n",
    "                    x_start=x_start\n",
    "                )\n",
    "                yield out\n",
    "                sample_x = out[\"sample\"]\n",
    "\n",
    "def _extract_into_tensor(arr, timesteps, broadcast_shape):\n",
    "    \"\"\"\n",
    "    Extract values from a 1-D numpy array for a batch of indices.\n",
    "\n",
    "    :param arr: the 1-D numpy array.\n",
    "    :param timesteps: a tensor of indices into the array to extract.\n",
    "    :param broadcast_shape: a larger shape of K dimensions with the batch\n",
    "                            dimension equal to the length of timesteps.\n",
    "    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\n",
    "    \"\"\"\n",
    "    res = th.from_numpy(arr).to(device=timesteps.device)[timesteps].float()\n",
    "    while len(res.shape) < len(broadcast_shape):\n",
    "        res = res[..., None]\n",
    "    return res.expand(broadcast_shape)\n",
    "\n",
    "def mean_flat(tensor):\n",
    "    \"\"\"\n",
    "    Take the mean over all non-batch dimensions.\n",
    "    \"\"\"\n",
    "    return tensor.mean(dim=list(range(1, len(tensor.shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformSampler():\n",
    "    \"\"\"\n",
    "    A distribution over timesteps in the diffusion process, intended to reduce\n",
    "    variance of the objective.\n",
    "\n",
    "    Sampler performs unbiased importance sampling, in which the\n",
    "    objective's mean is unchanged.\n",
    "    TODO confirm & update comment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, diffusion):\n",
    "        self.diffusion = diffusion\n",
    "        self._weights = np.ones([diffusion.num_timesteps])\n",
    "\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    def sample(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        Importance-sample timesteps for a batch.\n",
    "\n",
    "        :param batch_size: the number of timesteps.\n",
    "        :param device: the torch device to save to.\n",
    "        :return: a tuple (timesteps, weights):\n",
    "                 - timesteps: a tensor of timestep indices.\n",
    "                 - weights: a tensor of weights to scale the resulting losses.\n",
    "        \"\"\"\n",
    "        w = self.weights()\n",
    "        p = w / np.sum(w)\n",
    "        indices_np = np.random.choice(len(p), size=(batch_size,), p=p)\n",
    "        indices = th.from_numpy(indices_np).long()#.to(device)\n",
    "        weights_np = 1 / (len(p) * p[indices_np])\n",
    "        weights = th.from_numpy(weights_np).float()#.to(device)\n",
    "        return indices, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for training loop\n",
    "def update_ema(target_params, source_params, rate=0.99):\n",
    "    \"\"\"\n",
    "    Update target parameters to be closer to those of source parameters using\n",
    "    an exponential moving average.\n",
    "\n",
    "    :param target_params: the target parameter sequence.\n",
    "    :param source_params: the source parameter sequence.\n",
    "    :param rate: the EMA rate (closer to 1 means slower).\n",
    "    \"\"\"\n",
    "    for targ, src in zip(target_params, source_params):\n",
    "        targ.detach().mul_(rate).add_(src, alpha=1 - rate)\n",
    "\n",
    "def zero_grad(model_params):\n",
    "    for param in model_params:\n",
    "        # Taken from https://pytorch.org/docs/stable/_modules/torch/optim/optimizer.html#Optimizer.add_param_group\n",
    "        if param.grad is not None:\n",
    "            param.grad.detach_()\n",
    "            param.grad.zero_()\n",
    "\n",
    "def log_loss_dict(diffusion, ts, losses):\n",
    "    for key, values in losses.items():\n",
    "        # logger.logkv_mean(key, values.mean().item())\n",
    "        # Log the quantiles (four quartiles, in particular).\n",
    "        for sub_t, sub_loss in zip(ts.cpu().numpy(), values.detach().cpu().numpy()):\n",
    "            quartile = int(4 * sub_t / diffusion.num_timesteps)\n",
    "            # logger.logkv_mean(f\"{key}_q{quartile}\", sub_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "import copy\n",
    "\n",
    "class TrainLoop():\n",
    "    def __init__(\n",
    "        self,\n",
    "    #     *,\n",
    "        model,\n",
    "        diffusion,\n",
    "        data,\n",
    "        batch_size,\n",
    "    #     microbatch,\n",
    "        lr,\n",
    "        ema_rate,\n",
    "    #     log_interval,\n",
    "        #  schedule_sampler=None,\n",
    "        weight_decay=0.0,\n",
    "        learning_steps=0,\n",
    "    #     checkpoint_path='',\n",
    "    #     gradient_clipping=-1.,\n",
    "        eval_data=None,\n",
    "        eval_interval=-1,\n",
    "    ):\n",
    "          self.model = model\n",
    "          self.ddp_model = model # NOTE no distribution training\n",
    "          self.diffusion = diffusion\n",
    "          self.data = data\n",
    "          self.batch_size = batch_size\n",
    "        #   self.microbatch = microbatch if microbatch > 0 else batch_size\n",
    "          # Assume no microbatch\n",
    "          self.microbatch = batch_size\n",
    "\n",
    "          self.lr = lr\n",
    "          self.ema_rate = (\n",
    "            [ema_rate]\n",
    "            if isinstance(ema_rate, float)\n",
    "            else [float(x) for x in ema_rate.split(\",\")]\n",
    "            )\n",
    "          \n",
    "          # NOTE assuming uniform sampler\n",
    "          self.schedule_sampler = UniformSampler(diffusion)\n",
    "          self.weight_decay = weight_decay\n",
    "          self.learning_steps = learning_steps\n",
    "          self.eval_data = eval_data\n",
    "          self.eval_interval = eval_interval\n",
    "          \n",
    "          self.step = 0\n",
    "\n",
    "          # TODO check other initialization steps are covered\n",
    "\n",
    "          self.model_params = list(self.model.parameters())\n",
    "          self.master_params = self.model_params\n",
    "\n",
    "          # Optimizer\n",
    "          self.opt = AdamW(self.master_params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "          self.ema_params = [\n",
    "                copy.deepcopy(self.master_params) for _ in range(len(self.ema_rate))\n",
    "            ]\n",
    "\n",
    "    def _log_grad_norm(self):\n",
    "        sqsum = 0.0\n",
    "        for p in self.master_params:\n",
    "            if p.grad != None:\n",
    "                sqsum += (p.grad ** 2).sum().item()\n",
    "        # TODO implement logging\n",
    "        # logger.logkv_mean(\"grad_norm\", np.sqrt(sqsum))\n",
    "\n",
    "    def _anneal_lr(self):\n",
    "        if not self.learning_steps:\n",
    "            return\n",
    "        frac_done = (self.step) / self.learning_steps\n",
    "        lr = self.lr * (1 - frac_done)\n",
    "        for param_group in self.opt.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    \n",
    "    def optimize_normal(self):\n",
    "        # NOTE assuming no gradient clipping\n",
    "        self._log_grad_norm()\n",
    "        self._anneal_lr()\n",
    "        self.opt.step()\n",
    "        for rate, params in zip(self.ema_rate, self.ema_params):\n",
    "            update_ema(params, self.master_params, rate=rate)\n",
    "     \n",
    "\n",
    "    def run_step(self, batch, cond):\n",
    "        # TODO implement this fn\n",
    "        self.forward_backward(batch, cond)\n",
    "        # NOTE assuming not using fp16 optimization\n",
    "        self.optimize_normal()\n",
    "        # TODO do this fn - logging\n",
    "        # self.log_step()\n",
    "\n",
    "    def forward_only(self, batch, cond):\n",
    "        with th.no_grad():\n",
    "            zero_grad(self.model_params)\n",
    "            for i in range(0, batch.shape[0], self.microbatch):\n",
    "                micro = batch[i: i + self.microbatch]#.to(device)\n",
    "                micro_cond = {\n",
    "                    k: v[i: i + self.microbatch]#.to(device)\n",
    "                    for k, v in cond.items()\n",
    "                }\n",
    "                last_batch = (i + self.microbatch) >= batch.shape[0]\n",
    "                t, weights = self.schedule_sampler.sample(micro.shape[0], device)\n",
    "\n",
    "                compute_losses = self.diffusion.training_losses(self.ddp_model, micro, t, model_kwargs=micro_cond)\n",
    "\n",
    "                # NOTE not using ddp - distributed training\n",
    "                with self.ddp_model.no_sync():\n",
    "                        losses = compute_losses()\n",
    "\n",
    "                log_loss_dict(\n",
    "                    self.diffusion, t, {f\"eval_{k}\": v * weights for k, v in losses.items()}\n",
    "                )\n",
    "\n",
    "\n",
    "    def forward_backward(self, batch, cond):\n",
    "        print(\"batch size\", batch.size())\n",
    "        zero_grad(self.model_params)\n",
    "        for i in range(0, batch.shape[0], self.microbatch):\n",
    "            micro = batch[i : i + self.microbatch] #.to(dist_util.dev())\n",
    "            micro_cond = {\n",
    "                k: v[i : i + self.microbatch]#.to(dist_util.dev())\n",
    "                for k, v in cond.items()\n",
    "            }\n",
    "            last_batch = (i + self.microbatch) >= batch.shape[0]\n",
    "            t, weights = self.schedule_sampler.sample(micro.shape[0],torch.device)# dist_util.dev())\n",
    "            # print(micro_cond.keys())\n",
    "            losses = self.diffusion.training_losses(self.ddp_model, micro, t, model_kwargs=micro_cond)\n",
    "\n",
    "            # NOTE not using ddp - distributed training\n",
    "            # with self.ddp_model.no_sync():\n",
    "\n",
    "            # NOTE losses datatype a dict with the key \"loss\" containing a tensor of shape [N].\n",
    "                #  Some mean or variance settings may also have other keys.\n",
    "            # losses = compute_losses()\n",
    "\n",
    "            print(\"losses\", losses)\n",
    "\n",
    "            # if isinstance(self.schedule_sampler, LossAwareSampler):\n",
    "            #     self.schedule_sampler.update_with_local_losses(\n",
    "            #         t, losses[\"loss\"].detach()\n",
    "            #     )\n",
    "\n",
    "            loss = (losses[\"loss\"] * weights).mean()\n",
    "            log_loss_dict(\n",
    "                self.diffusion, t, {k: v * weights for k, v in losses.items()}\n",
    "            )\n",
    "            # NOTE not using fp16 optimization \n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "    # NOTE not going to implement capacity to resume training     \n",
    "    # NOTE removed saving checkpoints \n",
    "    # NOTE removed some logging\n",
    "    def run_loop(self):\n",
    "        while (\n",
    "            # FIXME check these defined correctly\n",
    "            not self.learning_steps\n",
    "            or self.step < self.learning_steps\n",
    "        ):\n",
    "            # NOTE check the loop runs\n",
    "            print(\"About to run next(self.data)\")\n",
    "            batch, cond = next(self.data)\n",
    "            print(\"Running loop!\")\n",
    "            # TODO add this fn\n",
    "            self.run_step(batch, cond)\n",
    "            if self.eval_data is not None and self.step % self.eval_interval == 0:\n",
    "                batch_eval, cond_eval = next(self.eval_data)\n",
    "                # TODO add this fn\n",
    "                self.forward_only(batch_eval, cond_eval)\n",
    "                print('eval on validation set')\n",
    "            self.step += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate all the classes for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer self.hidden_size 768\n",
      "### The parameter count is 110184634\n"
     ]
    }
   ],
   "source": [
    "# Define the noise schedule\n",
    "# TODO consider other noise schedules, here take the simplifying assumption that we use linear noise schedule \n",
    "# Linear schedule from Ho et al, extended to work for any number of\n",
    "# diffusion steps.\n",
    "\n",
    "scale = 1000 / num_diffusion_timesteps\n",
    "beta_start = scale * 0.0001\n",
    "beta_end = scale * 0.02\n",
    "betas = np.linspace(\n",
    "    beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
    ")\n",
    "\n",
    "# NOTE we assume NO timestep respacing \n",
    "# TODO instantiate the diffusion model & transformer and save it (?)\n",
    "\n",
    "diffusion = GaussianDiffusion(betas=betas)\n",
    "\n",
    "# TODO specify correct dimensions!\n",
    "# Note embedding size is 128\n",
    "model = TransformerNetModel(vocab_size=vocab_size, input_dims=embedding_dim, hidden_t_dim=hidden_dim, output_dims=output_dims)\n",
    "\n",
    "# model.to(device) \n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "# TODO add to logger\n",
    "print(f'### The parameter count is {pytorch_total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for training\n",
    "\n",
    "Note the implementation details in DiffuSeq (first version) is\n",
    "\"The maximum sequence length is 128, with embedding dimension d = 128, diffusion steps T = 2000\n",
    "and a square-root noise schedule.\"\n",
    "\n",
    "How is it different in v2 or other papers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to run next(self.data)\n",
      "\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Run training loop\n",
    "\n",
    "try:\n",
    "    TrainLoop(\n",
    "            model=model,\n",
    "            diffusion=diffusion,\n",
    "            data=data,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            ema_rate=ema_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            learning_steps=learning_steps,\n",
    "        ).run_loop()\n",
    "\n",
    "except StopIteration as e:\n",
    "    print(e)\n",
    "    print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reached StopIteration Exception. Training completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample output using the forward step of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Inference step (sampling / generation part) -->\n",
    "# Decoding\n",
    "\n",
    "Once the training completed, we can start the inference step and get cross validation accuracy.\n",
    "\n",
    "Not using diffuseq 2 (DPM Solver++ method), but original method.\n",
    "In this study we do not consider the time or space complexity of the inference step.\n",
    "\n",
    "(Adapted from sample_seq2seq.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO set up saving of the trained model & load it from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE normally need to load tokenizer & model_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.myTokenizer at 0x12eea93c0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE normally need to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficient_knn(model_emb, text_emb):\n",
    "    emb_norm = (model_emb**2).sum(-1).view(-1, 1) # vocab\n",
    "    text_emb_t = torch.transpose(text_emb.view(-1, text_emb.size(-1)), 0, 1) # d, bsz*seqlen\n",
    "    arr_norm = (text_emb ** 2).sum(-1).view(-1, 1) # bsz*seqlen, 1\n",
    "    # print(emb_norm.shape, arr_norm.shape)\n",
    "    dist = emb_norm + arr_norm.transpose(0, 1) - 2.0 * torch.mm(model_emb, text_emb_t) # (vocab, d) x (d, bsz*seqlen)\n",
    "    dist = torch.clamp(dist, 0.0, np.inf)\n",
    "    # print(dist.shape)\n",
    "    topk_out = torch.topk(-dist, k=1, dim=0)\n",
    "    return topk_out.values, topk_out.indices\n",
    "\n",
    "def denoised_fn_round(model, text_emb):\n",
    "    # print(text_emb.shape) # bsz, seqlen, dim\n",
    "    model_emb = model.weight  # input_embs\n",
    "    # print(t)\n",
    "    old_shape = text_emb.shape\n",
    "    old_device = text_emb.device\n",
    "\n",
    "    if len(text_emb.shape) > 2:\n",
    "        text_emb = text_emb.reshape(-1, text_emb.size(-1))\n",
    "    else:\n",
    "        text_emb = text_emb\n",
    "    # val, indices = get_knn(model_emb, text_emb.to(model_emb.device), dist=dist)\n",
    "    val, indices = get_efficient_knn(model_emb, text_emb.to(model_emb.device))\n",
    "    rounded_tokens = indices[0]\n",
    "    # print(rounded_tokens.shape)\n",
    "    new_embeds = model(rounded_tokens).view(old_shape).to(old_device)\n",
    "\n",
    "    return new_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### End of reading iteration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8900,  0.0225, -0.2468,  ...,  0.1533,  0.1329,  0.1152],\n",
      "        [ 0.8900,  0.0225, -0.2468,  ...,  0.1533,  0.1329,  0.1152],\n",
      "        [ 0.8900,  0.0225, -0.2468,  ...,  0.1533,  0.1329,  0.1152],\n",
      "        ...,\n",
      "        [ 0.8900,  0.0225, -0.2468,  ...,  0.1533,  0.1329,  0.1152],\n",
      "        [ 0.8900,  0.0225, -0.2468,  ...,  0.1533,  0.1329,  0.1152],\n",
      "        [ 0.8900,  0.0225, -0.2468,  ...,  0.1533,  0.1329,  0.1152]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9996, -0.3990,  0.1252,  ...,  0.1532,  0.1328,  0.1151],\n",
      "        [ 0.9996, -0.3990,  0.1252,  ...,  0.1532,  0.1328,  0.1151],\n",
      "        [ 0.9996, -0.3990,  0.1252,  ...,  0.1532,  0.1328,  0.1151],\n",
      "        ...,\n",
      "        [ 0.9996, -0.3990,  0.1252,  ...,  0.1532,  0.1328,  0.1151],\n",
      "        [ 0.9996, -0.3990,  0.1252,  ...,  0.1532,  0.1328,  0.1151],\n",
      "        [ 0.9996, -0.3990,  0.1252,  ...,  0.1532,  0.1328,  0.1151]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8646, -0.7469,  0.4799,  ...,  0.1532,  0.1328,  0.1150],\n",
      "        [ 0.8646, -0.7469,  0.4799,  ...,  0.1532,  0.1328,  0.1150],\n",
      "        [ 0.8646, -0.7469,  0.4799,  ...,  0.1532,  0.1328,  0.1150],\n",
      "        ...,\n",
      "        [ 0.8646, -0.7469,  0.4799,  ...,  0.1532,  0.1328,  0.1150],\n",
      "        [ 0.8646, -0.7469,  0.4799,  ...,  0.1532,  0.1328,  0.1150],\n",
      "        [ 0.8646, -0.7469,  0.4799,  ...,  0.1532,  0.1328,  0.1150]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5178, -0.9570,  0.7678,  ...,  0.1531,  0.1327,  0.1150],\n",
      "        [ 0.5178, -0.9570,  0.7678,  ...,  0.1531,  0.1327,  0.1150],\n",
      "        [ 0.5178, -0.9570,  0.7678,  ...,  0.1531,  0.1327,  0.1150],\n",
      "        ...,\n",
      "        [ 0.5178, -0.9570,  0.7678,  ...,  0.1531,  0.1327,  0.1150],\n",
      "        [ 0.5178, -0.9570,  0.7678,  ...,  0.1531,  0.1327,  0.1150],\n",
      "        [ 0.5178, -0.9570,  0.7678,  ...,  0.1531,  0.1327,  0.1150]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0443, -0.9904,  0.9491,  ...,  0.1530,  0.1326,  0.1149],\n",
      "        [ 0.0443, -0.9904,  0.9491,  ...,  0.1530,  0.1326,  0.1149],\n",
      "        [ 0.0443, -0.9904,  0.9491,  ...,  0.1530,  0.1326,  0.1149],\n",
      "        ...,\n",
      "        [ 0.0443, -0.9904,  0.9491,  ...,  0.1530,  0.1326,  0.1149],\n",
      "        [ 0.0443, -0.9904,  0.9491,  ...,  0.1530,  0.1326,  0.1149],\n",
      "        [ 0.0443, -0.9904,  0.9491,  ...,  0.1530,  0.1326,  0.1149]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4401, -0.8410,  0.9985,  ...,  0.1529,  0.1326,  0.1149],\n",
      "        [-0.4401, -0.8410,  0.9985,  ...,  0.1529,  0.1326,  0.1149],\n",
      "        [-0.4401, -0.8410,  0.9985,  ...,  0.1529,  0.1326,  0.1149],\n",
      "        ...,\n",
      "        [-0.4401, -0.8410,  0.9985,  ...,  0.1529,  0.1326,  0.1149],\n",
      "        [-0.4401, -0.8410,  0.9985,  ...,  0.1529,  0.1326,  0.1149],\n",
      "        [-0.4401, -0.8410,  0.9985,  ...,  0.1529,  0.1326,  0.1149]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8167, -0.5365,  0.9092,  ...,  0.1529,  0.1325,  0.1148],\n",
      "        [-0.8167, -0.5365,  0.9092,  ...,  0.1529,  0.1325,  0.1148],\n",
      "        [-0.8167, -0.5365,  0.9092,  ...,  0.1529,  0.1325,  0.1148],\n",
      "        ...,\n",
      "        [-0.8167, -0.5365,  0.9092,  ...,  0.1529,  0.1325,  0.1148],\n",
      "        [-0.8167, -0.5365,  0.9092,  ...,  0.1529,  0.1325,  0.1148],\n",
      "        [-0.8167, -0.5365,  0.9092,  ...,  0.1529,  0.1325,  0.1148]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9934, -0.1328,  0.6935,  ...,  0.1528,  0.1324,  0.1148],\n",
      "        [-0.9934, -0.1328,  0.6935,  ...,  0.1528,  0.1324,  0.1148],\n",
      "        [-0.9934, -0.1328,  0.6935,  ...,  0.1528,  0.1324,  0.1148],\n",
      "        ...,\n",
      "        [-0.9934, -0.1328,  0.6935,  ...,  0.1528,  0.1324,  0.1148],\n",
      "        [-0.9934, -0.1328,  0.6935,  ...,  0.1528,  0.1324,  0.1148],\n",
      "        [-0.9934, -0.1328,  0.6935,  ...,  0.1528,  0.1324,  0.1148]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9268,  0.2953,  0.3815,  ...,  0.1527,  0.1324,  0.1147],\n",
      "        [-0.9268,  0.2953,  0.3815,  ...,  0.1527,  0.1324,  0.1147],\n",
      "        [-0.9268,  0.2953,  0.3815,  ...,  0.1527,  0.1324,  0.1147],\n",
      "        ...,\n",
      "        [-0.9268,  0.2953,  0.3815,  ...,  0.1527,  0.1324,  0.1147],\n",
      "        [-0.9268,  0.2953,  0.3815,  ...,  0.1527,  0.1324,  0.1147],\n",
      "        [-0.9268,  0.2953,  0.3815,  ...,  0.1527,  0.1324,  0.1147]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6334,  0.6689,  0.0165,  ...,  0.1526,  0.1323,  0.1146],\n",
      "        [-0.6334,  0.6689,  0.0165,  ...,  0.1526,  0.1323,  0.1146],\n",
      "        [-0.6334,  0.6689,  0.0165,  ...,  0.1526,  0.1323,  0.1146],\n",
      "        ...,\n",
      "        [-0.6334,  0.6689,  0.0165,  ...,  0.1526,  0.1323,  0.1146],\n",
      "        [-0.6334,  0.6689,  0.0165,  ...,  0.1526,  0.1323,  0.1146],\n",
      "        [-0.6334,  0.6689,  0.0165,  ...,  0.1526,  0.1323,  0.1146]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1849,  0.9191, -0.3509,  ...,  0.1525,  0.1322,  0.1146],\n",
      "        [-0.1849,  0.9191, -0.3509,  ...,  0.1525,  0.1322,  0.1146],\n",
      "        [-0.1849,  0.9191, -0.3509,  ...,  0.1525,  0.1322,  0.1146],\n",
      "        ...,\n",
      "        [-0.1849,  0.9191, -0.3509,  ...,  0.1525,  0.1322,  0.1146],\n",
      "        [-0.1849,  0.9191, -0.3509,  ...,  0.1525,  0.1322,  0.1146],\n",
      "        [-0.1849,  0.9191, -0.3509,  ...,  0.1525,  0.1322,  0.1146]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3089,  0.9996, -0.6694,  ...,  0.1525,  0.1322,  0.1145],\n",
      "        [ 0.3089,  0.9996, -0.6694,  ...,  0.1525,  0.1322,  0.1145],\n",
      "        [ 0.3089,  0.9996, -0.6694,  ...,  0.1525,  0.1322,  0.1145],\n",
      "        ...,\n",
      "        [ 0.3089,  0.9996, -0.6694,  ...,  0.1525,  0.1322,  0.1145],\n",
      "        [ 0.3089,  0.9996, -0.6694,  ...,  0.1525,  0.1322,  0.1145],\n",
      "        [ 0.3089,  0.9996, -0.6694,  ...,  0.1525,  0.1322,  0.1145]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7271,  0.8957, -0.8950,  ...,  0.1524,  0.1321,  0.1145],\n",
      "        [ 0.7271,  0.8957, -0.8950,  ...,  0.1524,  0.1321,  0.1145],\n",
      "        [ 0.7271,  0.8957, -0.8950,  ...,  0.1524,  0.1321,  0.1145],\n",
      "        ...,\n",
      "        [ 0.7271,  0.8957, -0.8950,  ...,  0.1524,  0.1321,  0.1145],\n",
      "        [ 0.7271,  0.8957, -0.8950,  ...,  0.1524,  0.1321,  0.1145],\n",
      "        [ 0.7271,  0.8957, -0.8950,  ...,  0.1524,  0.1321,  0.1145]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9672,  0.6264, -0.9962,  ...,  0.1523,  0.1320,  0.1144],\n",
      "        [ 0.9672,  0.6264, -0.9962,  ...,  0.1523,  0.1320,  0.1144],\n",
      "        [ 0.9672,  0.6264, -0.9962,  ...,  0.1523,  0.1320,  0.1144],\n",
      "        ...,\n",
      "        [ 0.9672,  0.6264, -0.9962,  ...,  0.1523,  0.1320,  0.1144],\n",
      "        [ 0.9672,  0.6264, -0.9962,  ...,  0.1523,  0.1320,  0.1144],\n",
      "        [ 0.9672,  0.6264, -0.9962,  ...,  0.1523,  0.1320,  0.1144]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9706,  0.2415, -0.9590,  ...,  0.1522,  0.1320,  0.1144],\n",
      "        [ 0.9706,  0.2415, -0.9590,  ...,  0.1522,  0.1320,  0.1144],\n",
      "        [ 0.9706,  0.2415, -0.9590,  ...,  0.1522,  0.1320,  0.1144],\n",
      "        ...,\n",
      "        [ 0.9706,  0.2415, -0.9590,  ...,  0.1522,  0.1320,  0.1144],\n",
      "        [ 0.9706,  0.2415, -0.9590,  ...,  0.1522,  0.1320,  0.1144],\n",
      "        [ 0.9706,  0.2415, -0.9590,  ...,  0.1522,  0.1320,  0.1144]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7363, -0.1879, -0.7885,  ...,  0.1522,  0.1319,  0.1143],\n",
      "        [ 0.7363, -0.1879, -0.7885,  ...,  0.1522,  0.1319,  0.1143],\n",
      "        [ 0.7363, -0.1879, -0.7885,  ...,  0.1522,  0.1319,  0.1143],\n",
      "        ...,\n",
      "        [ 0.7363, -0.1879, -0.7885,  ...,  0.1522,  0.1319,  0.1143],\n",
      "        [ 0.7363, -0.1879, -0.7885,  ...,  0.1522,  0.1319,  0.1143],\n",
      "        [ 0.7363, -0.1879, -0.7885,  ...,  0.1522,  0.1319,  0.1143]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3217, -0.5827, -0.5085,  ...,  0.1521,  0.1318,  0.1142],\n",
      "        [ 0.3217, -0.5827, -0.5085,  ...,  0.1521,  0.1318,  0.1142],\n",
      "        [ 0.3217, -0.5827, -0.5085,  ...,  0.1521,  0.1318,  0.1142],\n",
      "        ...,\n",
      "        [ 0.3217, -0.5827, -0.5085,  ...,  0.1521,  0.1318,  0.1142],\n",
      "        [ 0.3217, -0.5827, -0.5085,  ...,  0.1521,  0.1318,  0.1142],\n",
      "        [ 0.3217, -0.5827, -0.5085,  ...,  0.1521,  0.1318,  0.1142]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1716, -0.8699, -0.1578,  ...,  0.1520,  0.1318,  0.1142],\n",
      "        [-0.1716, -0.8699, -0.1578,  ...,  0.1520,  0.1318,  0.1142],\n",
      "        [-0.1716, -0.8699, -0.1578,  ...,  0.1520,  0.1318,  0.1142],\n",
      "        ...,\n",
      "        [-0.1716, -0.8699, -0.1578,  ...,  0.1520,  0.1318,  0.1142],\n",
      "        [-0.1716, -0.8699, -0.1578,  ...,  0.1520,  0.1318,  0.1142],\n",
      "        [-0.1716, -0.8699, -0.1578,  ...,  0.1520,  0.1318,  0.1142]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6229, -0.9966,  0.2148,  ...,  0.1519,  0.1317,  0.1141],\n",
      "        [-0.6229, -0.9966,  0.2148,  ...,  0.1519,  0.1317,  0.1141],\n",
      "        [-0.6229, -0.9966,  0.2148,  ...,  0.1519,  0.1317,  0.1141],\n",
      "        ...,\n",
      "        [-0.6229, -0.9966,  0.2148,  ...,  0.1519,  0.1317,  0.1141],\n",
      "        [-0.6229, -0.9966,  0.2148,  ...,  0.1519,  0.1317,  0.1141],\n",
      "        [-0.6229, -0.9966,  0.2148,  ...,  0.1519,  0.1317,  0.1141]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9217, -0.9393,  0.5575,  ...,  0.1519,  0.1316,  0.1141],\n",
      "        [-0.9217, -0.9393,  0.5575,  ...,  0.1519,  0.1316,  0.1141],\n",
      "        [-0.9217, -0.9393,  0.5575,  ...,  0.1519,  0.1316,  0.1141],\n",
      "        ...,\n",
      "        [-0.9217, -0.9393,  0.5575,  ...,  0.1519,  0.1316,  0.1141],\n",
      "        [-0.9217, -0.9393,  0.5575,  ...,  0.1519,  0.1316,  0.1141],\n",
      "        [-0.9217, -0.9393,  0.5575,  ...,  0.1519,  0.1316,  0.1141]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9948, -0.7087,  0.8228,  ...,  0.1518,  0.1316,  0.1140],\n",
      "        [-0.9948, -0.7087,  0.8228,  ...,  0.1518,  0.1316,  0.1140],\n",
      "        [-0.9948, -0.7087,  0.8228,  ...,  0.1518,  0.1316,  0.1140],\n",
      "        ...,\n",
      "        [-0.9948, -0.7087,  0.8228,  ...,  0.1518,  0.1316,  0.1140],\n",
      "        [-0.9948, -0.7087,  0.8228,  ...,  0.1518,  0.1316,  0.1140],\n",
      "        [-0.9948, -0.7087,  0.8228,  ...,  0.1518,  0.1316,  0.1140]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8244, -0.3473,  0.9738,  ...,  0.1517,  0.1315,  0.1140],\n",
      "        [-0.8244, -0.3473,  0.9738,  ...,  0.1517,  0.1315,  0.1140],\n",
      "        [-0.8244, -0.3473,  0.9738,  ...,  0.1517,  0.1315,  0.1140],\n",
      "        ...,\n",
      "        [-0.8244, -0.3473,  0.9738,  ...,  0.1517,  0.1315,  0.1140],\n",
      "        [-0.8244, -0.3473,  0.9738,  ...,  0.1517,  0.1315,  0.1140],\n",
      "        [-0.8244, -0.3473,  0.9738,  ...,  0.1517,  0.1315,  0.1140]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4521,  0.0782,  0.9894,  ...,  0.1516,  0.1314,  0.1139],\n",
      "        [-0.4521,  0.0782,  0.9894,  ...,  0.1516,  0.1314,  0.1139],\n",
      "        [-0.4521,  0.0782,  0.9894,  ...,  0.1516,  0.1314,  0.1139],\n",
      "        ...,\n",
      "        [-0.4521,  0.0782,  0.9894,  ...,  0.1516,  0.1314,  0.1139],\n",
      "        [-0.4521,  0.0782,  0.9894,  ...,  0.1516,  0.1314,  0.1139],\n",
      "        [-0.4521,  0.0782,  0.9894,  ...,  0.1516,  0.1314,  0.1139]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.0309, 0.4893, 0.8676,  ..., 0.1516, 0.1314, 0.1138],\n",
      "        [0.0309, 0.4893, 0.8676,  ..., 0.1516, 0.1314, 0.1138],\n",
      "        [0.0309, 0.4893, 0.8676,  ..., 0.1516, 0.1314, 0.1138],\n",
      "        ...,\n",
      "        [0.0309, 0.4893, 0.8676,  ..., 0.1516, 0.1314, 0.1138],\n",
      "        [0.0309, 0.4893, 0.8676,  ..., 0.1516, 0.1314, 0.1138],\n",
      "        [0.0309, 0.4893, 0.8676,  ..., 0.1516, 0.1314, 0.1138]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.5063, 0.8101, 0.6252,  ..., 0.1515, 0.1313, 0.1138],\n",
      "        [0.5063, 0.8101, 0.6252,  ..., 0.1515, 0.1313, 0.1138],\n",
      "        [0.5063, 0.8101, 0.6252,  ..., 0.1515, 0.1313, 0.1138],\n",
      "        ...,\n",
      "        [0.5063, 0.8101, 0.6252,  ..., 0.1515, 0.1313, 0.1138],\n",
      "        [0.5063, 0.8101, 0.6252,  ..., 0.1515, 0.1313, 0.1138],\n",
      "        [0.5063, 0.8101, 0.6252,  ..., 0.1515, 0.1313, 0.1138]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8578, 0.9813, 0.2960,  ..., 0.1514, 0.1312, 0.1137],\n",
      "        [0.8578, 0.9813, 0.2960,  ..., 0.1514, 0.1312, 0.1137],\n",
      "        [0.8578, 0.9813, 0.2960,  ..., 0.1514, 0.1312, 0.1137],\n",
      "        ...,\n",
      "        [0.8578, 0.9813, 0.2960,  ..., 0.1514, 0.1312, 0.1137],\n",
      "        [0.8578, 0.9813, 0.2960,  ..., 0.1514, 0.1312, 0.1137],\n",
      "        [0.8578, 0.9813, 0.2960,  ..., 0.1514, 0.1312, 0.1137]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9992,  0.9715, -0.0744,  ...,  0.1513,  0.1312,  0.1137],\n",
      "        [ 0.9992,  0.9715, -0.0744,  ...,  0.1513,  0.1312,  0.1137],\n",
      "        [ 0.9992,  0.9715, -0.0744,  ...,  0.1513,  0.1312,  0.1137],\n",
      "        ...,\n",
      "        [ 0.9992,  0.9715, -0.0744,  ...,  0.1513,  0.1312,  0.1137],\n",
      "        [ 0.9992,  0.9715, -0.0744,  ...,  0.1513,  0.1312,  0.1137],\n",
      "        [ 0.9992,  0.9715, -0.0744,  ...,  0.1513,  0.1312,  0.1137]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8960,  0.7823, -0.4344,  ...,  0.1513,  0.1311,  0.1136],\n",
      "        [ 0.8960,  0.7823, -0.4344,  ...,  0.1513,  0.1311,  0.1136],\n",
      "        [ 0.8960,  0.7823, -0.4344,  ...,  0.1513,  0.1311,  0.1136],\n",
      "        ...,\n",
      "        [ 0.8960,  0.7823, -0.4344,  ...,  0.1513,  0.1311,  0.1136],\n",
      "        [ 0.8960,  0.7823, -0.4344,  ...,  0.1513,  0.1311,  0.1136],\n",
      "        [ 0.8960,  0.7823, -0.4344,  ...,  0.1513,  0.1311,  0.1136]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5734,  0.4488, -0.7341,  ...,  0.1512,  0.1310,  0.1136],\n",
      "        [ 0.5734,  0.4488, -0.7341,  ...,  0.1512,  0.1310,  0.1136],\n",
      "        [ 0.5734,  0.4488, -0.7341,  ...,  0.1512,  0.1310,  0.1136],\n",
      "        ...,\n",
      "        [ 0.5734,  0.4488, -0.7341,  ...,  0.1512,  0.1310,  0.1136],\n",
      "        [ 0.5734,  0.4488, -0.7341,  ...,  0.1512,  0.1310,  0.1136],\n",
      "        [ 0.5734,  0.4488, -0.7341,  ...,  0.1512,  0.1310,  0.1136]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1105,  0.0324, -0.9318,  ...,  0.1511,  0.1310,  0.1135],\n",
      "        [ 0.1105,  0.0324, -0.9318,  ...,  0.1511,  0.1310,  0.1135],\n",
      "        [ 0.1105,  0.0324, -0.9318,  ...,  0.1511,  0.1310,  0.1135],\n",
      "        ...,\n",
      "        [ 0.1105,  0.0324, -0.9318,  ...,  0.1511,  0.1310,  0.1135],\n",
      "        [ 0.1105,  0.0324, -0.9318,  ...,  0.1511,  0.1310,  0.1135],\n",
      "        [ 0.1105,  0.0324, -0.9318,  ...,  0.1511,  0.1310,  0.1135]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3795, -0.3899, -1.0000,  ...,  0.1510,  0.1309,  0.1134],\n",
      "        [-0.3795, -0.3899, -1.0000,  ...,  0.1510,  0.1309,  0.1134],\n",
      "        [-0.3795, -0.3899, -1.0000,  ...,  0.1510,  0.1309,  0.1134],\n",
      "        ...,\n",
      "        [-0.3795, -0.3899, -1.0000,  ...,  0.1510,  0.1309,  0.1134],\n",
      "        [-0.3795, -0.3899, -1.0000,  ...,  0.1510,  0.1309,  0.1134],\n",
      "        [-0.3795, -0.3899, -1.0000,  ...,  0.1510,  0.1309,  0.1134]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7766, -0.7403, -0.9293,  ...,  0.1509,  0.1308,  0.1134],\n",
      "        [-0.7766, -0.7403, -0.9293,  ...,  0.1509,  0.1308,  0.1134],\n",
      "        [-0.7766, -0.7403, -0.9293,  ...,  0.1509,  0.1308,  0.1134],\n",
      "        ...,\n",
      "        [-0.7766, -0.7403, -0.9293,  ...,  0.1509,  0.1308,  0.1134],\n",
      "        [-0.7766, -0.7403, -0.9293,  ...,  0.1509,  0.1308,  0.1134],\n",
      "        [-0.7766, -0.7403, -0.9293,  ...,  0.1509,  0.1308,  0.1134]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9836, -0.9541, -0.7294,  ...,  0.1509,  0.1308,  0.1133],\n",
      "        [-0.9836, -0.9541, -0.7294,  ...,  0.1509,  0.1308,  0.1133],\n",
      "        [-0.9836, -0.9541, -0.7294,  ...,  0.1509,  0.1308,  0.1133],\n",
      "        ...,\n",
      "        [-0.9836, -0.9541, -0.7294,  ...,  0.1509,  0.1308,  0.1133],\n",
      "        [-0.9836, -0.9541, -0.7294,  ...,  0.1509,  0.1308,  0.1133],\n",
      "        [-0.9836, -0.9541, -0.7294,  ...,  0.1509,  0.1308,  0.1133]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9497, -0.9917, -0.4282,  ...,  0.1508,  0.1307,  0.1133],\n",
      "        [-0.9497, -0.9917, -0.4282,  ...,  0.1508,  0.1307,  0.1133],\n",
      "        [-0.9497, -0.9917, -0.4282,  ...,  0.1508,  0.1307,  0.1133],\n",
      "        ...,\n",
      "        [-0.9497, -0.9917, -0.4282,  ...,  0.1508,  0.1307,  0.1133],\n",
      "        [-0.9497, -0.9917, -0.4282,  ...,  0.1508,  0.1307,  0.1133],\n",
      "        [-0.9497, -0.9917, -0.4282,  ...,  0.1508,  0.1307,  0.1133]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6833, -0.8464, -0.0675,  ...,  0.1507,  0.1306,  0.1132],\n",
      "        [-0.6833, -0.8464, -0.0675,  ...,  0.1507,  0.1306,  0.1132],\n",
      "        [-0.6833, -0.8464, -0.0675,  ...,  0.1507,  0.1306,  0.1132],\n",
      "        ...,\n",
      "        [-0.6833, -0.8464, -0.0675,  ...,  0.1507,  0.1306,  0.1132],\n",
      "        [-0.6833, -0.8464, -0.0675,  ...,  0.1507,  0.1306,  0.1132],\n",
      "        [-0.6833, -0.8464, -0.0675,  ...,  0.1507,  0.1306,  0.1132]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2496, -0.5448,  0.3025,  ...,  0.1506,  0.1306,  0.1132],\n",
      "        [-0.2496, -0.5448,  0.3025,  ...,  0.1506,  0.1306,  0.1132],\n",
      "        [-0.2496, -0.5448,  0.3025,  ...,  0.1506,  0.1306,  0.1132],\n",
      "        ...,\n",
      "        [-0.2496, -0.5448,  0.3025,  ...,  0.1506,  0.1306,  0.1132],\n",
      "        [-0.2496, -0.5448,  0.3025,  ...,  0.1506,  0.1306,  0.1132],\n",
      "        [-0.2496, -0.5448,  0.3025,  ...,  0.1506,  0.1306,  0.1132]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2452, -0.1427,  0.6306,  ...,  0.1506,  0.1305,  0.1131],\n",
      "        [ 0.2452, -0.1427,  0.6306,  ...,  0.1506,  0.1305,  0.1131],\n",
      "        [ 0.2452, -0.1427,  0.6306,  ...,  0.1506,  0.1305,  0.1131],\n",
      "        ...,\n",
      "        [ 0.2452, -0.1427,  0.6306,  ...,  0.1506,  0.1305,  0.1131],\n",
      "        [ 0.2452, -0.1427,  0.6306,  ...,  0.1506,  0.1305,  0.1131],\n",
      "        [ 0.2452, -0.1427,  0.6306,  ...,  0.1506,  0.1305,  0.1131]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.6800, 0.2858, 0.8710,  ..., 0.1505, 0.1304, 0.1130],\n",
      "        [0.6800, 0.2858, 0.8710,  ..., 0.1505, 0.1304, 0.1130],\n",
      "        [0.6800, 0.2858, 0.8710,  ..., 0.1505, 0.1304, 0.1130],\n",
      "        ...,\n",
      "        [0.6800, 0.2858, 0.8710,  ..., 0.1505, 0.1304, 0.1130],\n",
      "        [0.6800, 0.2858, 0.8710,  ..., 0.1505, 0.1304, 0.1130],\n",
      "        [0.6800, 0.2858, 0.8710,  ..., 0.1505, 0.1304, 0.1130]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9483, 0.6615, 0.9904,  ..., 0.1504, 0.1304, 0.1130],\n",
      "        [0.9483, 0.6615, 0.9904,  ..., 0.1504, 0.1304, 0.1130],\n",
      "        [0.9483, 0.6615, 0.9904,  ..., 0.1504, 0.1304, 0.1130],\n",
      "        ...,\n",
      "        [0.9483, 0.6615, 0.9904,  ..., 0.1504, 0.1304, 0.1130],\n",
      "        [0.9483, 0.6615, 0.9904,  ..., 0.1504, 0.1304, 0.1130],\n",
      "        [0.9483, 0.6615, 0.9904,  ..., 0.1504, 0.1304, 0.1130]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9844, 0.9151, 0.9722,  ..., 0.1503, 0.1303, 0.1129],\n",
      "        [0.9844, 0.9151, 0.9722,  ..., 0.1503, 0.1303, 0.1129],\n",
      "        [0.9844, 0.9151, 0.9722,  ..., 0.1503, 0.1303, 0.1129],\n",
      "        ...,\n",
      "        [0.9844, 0.9151, 0.9722,  ..., 0.1503, 0.1303, 0.1129],\n",
      "        [0.9844, 0.9151, 0.9722,  ..., 0.1503, 0.1303, 0.1129],\n",
      "        [0.9844, 0.9151, 0.9722,  ..., 0.1503, 0.1303, 0.1129]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.7795, 0.9998, 0.8189,  ..., 0.1503, 0.1302, 0.1129],\n",
      "        [0.7795, 0.9998, 0.8189,  ..., 0.1503, 0.1302, 0.1129],\n",
      "        [0.7795, 0.9998, 0.8189,  ..., 0.1503, 0.1302, 0.1129],\n",
      "        ...,\n",
      "        [0.7795, 0.9998, 0.8189,  ..., 0.1503, 0.1302, 0.1129],\n",
      "        [0.7795, 0.9998, 0.8189,  ..., 0.1503, 0.1302, 0.1129],\n",
      "        [0.7795, 0.9998, 0.8189,  ..., 0.1503, 0.1302, 0.1129]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.3838, 0.9000, 0.5518,  ..., 0.1502, 0.1302, 0.1128],\n",
      "        [0.3838, 0.9000, 0.5518,  ..., 0.1502, 0.1302, 0.1128],\n",
      "        [0.3838, 0.9000, 0.5518,  ..., 0.1502, 0.1302, 0.1128],\n",
      "        ...,\n",
      "        [0.3838, 0.9000, 0.5518,  ..., 0.1502, 0.1302, 0.1128],\n",
      "        [0.3838, 0.9000, 0.5518,  ..., 0.1502, 0.1302, 0.1128],\n",
      "        [0.3838, 0.9000, 0.5518,  ..., 0.1502, 0.1302, 0.1128]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1059,  0.6341,  0.2081,  ...,  0.1501,  0.1301,  0.1128],\n",
      "        [-0.1059,  0.6341,  0.2081,  ...,  0.1501,  0.1301,  0.1128],\n",
      "        [-0.1059,  0.6341,  0.2081,  ...,  0.1501,  0.1301,  0.1128],\n",
      "        ...,\n",
      "        [-0.1059,  0.6341,  0.2081,  ...,  0.1501,  0.1301,  0.1128],\n",
      "        [-0.1059,  0.6341,  0.2081,  ...,  0.1501,  0.1301,  0.1128],\n",
      "        [-0.1059,  0.6341,  0.2081,  ...,  0.1501,  0.1301,  0.1128]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5697,  0.2511, -0.1646,  ...,  0.1500,  0.1300,  0.1127],\n",
      "        [-0.5697,  0.2511, -0.1646,  ...,  0.1500,  0.1300,  0.1127],\n",
      "        [-0.5697,  0.2511, -0.1646,  ...,  0.1500,  0.1300,  0.1127],\n",
      "        ...,\n",
      "        [-0.5697,  0.2511, -0.1646,  ...,  0.1500,  0.1300,  0.1127],\n",
      "        [-0.5697,  0.2511, -0.1646,  ...,  0.1500,  0.1300,  0.1127],\n",
      "        [-0.5697,  0.2511, -0.1646,  ...,  0.1500,  0.1300,  0.1127]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8940, -0.1782, -0.5144,  ...,  0.1500,  0.1300,  0.1126],\n",
      "        [-0.8940, -0.1782, -0.5144,  ...,  0.1500,  0.1300,  0.1126],\n",
      "        [-0.8940, -0.1782, -0.5144,  ...,  0.1500,  0.1300,  0.1126],\n",
      "        ...,\n",
      "        [-0.8940, -0.1782, -0.5144,  ...,  0.1500,  0.1300,  0.1126],\n",
      "        [-0.8940, -0.1782, -0.5144,  ...,  0.1500,  0.1300,  0.1126],\n",
      "        [-0.8940, -0.1782, -0.5144,  ...,  0.1500,  0.1300,  0.1126]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9994, -0.5746, -0.7927,  ...,  0.1499,  0.1299,  0.1126],\n",
      "        [-0.9994, -0.5746, -0.7927,  ...,  0.1499,  0.1299,  0.1126],\n",
      "        [-0.9994, -0.5746, -0.7927,  ...,  0.1499,  0.1299,  0.1126],\n",
      "        ...,\n",
      "        [-0.9994, -0.5746, -0.7927,  ...,  0.1499,  0.1299,  0.1126],\n",
      "        [-0.9994, -0.5746, -0.7927,  ...,  0.1499,  0.1299,  0.1126],\n",
      "        [-0.9994, -0.5746, -0.7927,  ...,  0.1499,  0.1299,  0.1126]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8601, -0.8650, -0.9609,  ...,  0.1498,  0.1299,  0.1125],\n",
      "        [-0.8601, -0.8650, -0.9609,  ...,  0.1498,  0.1299,  0.1125],\n",
      "        [-0.8601, -0.8650, -0.9609,  ...,  0.1498,  0.1299,  0.1125],\n",
      "        ...,\n",
      "        [-0.8601, -0.8650, -0.9609,  ...,  0.1498,  0.1299,  0.1125],\n",
      "        [-0.8601, -0.8650, -0.9609,  ...,  0.1498,  0.1299,  0.1125],\n",
      "        [-0.8601, -0.8650, -0.9609,  ...,  0.1498,  0.1299,  0.1125]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5103, -0.9957, -0.9956,  ...,  0.1497,  0.1298,  0.1125],\n",
      "        [-0.5103, -0.9957, -0.9956,  ...,  0.1497,  0.1298,  0.1125],\n",
      "        [-0.5103, -0.9957, -0.9956,  ...,  0.1497,  0.1298,  0.1125],\n",
      "        ...,\n",
      "        [-0.5103, -0.9957, -0.9956,  ...,  0.1497,  0.1298,  0.1125],\n",
      "        [-0.5103, -0.9957, -0.9956,  ...,  0.1497,  0.1298,  0.1125],\n",
      "        [-0.5103, -0.9957, -0.9956,  ...,  0.1497,  0.1298,  0.1125]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0355, -0.9427, -0.8919,  ...,  0.1497,  0.1297,  0.1124],\n",
      "        [-0.0355, -0.9427, -0.8919,  ...,  0.1497,  0.1297,  0.1124],\n",
      "        [-0.0355, -0.9427, -0.8919,  ...,  0.1497,  0.1297,  0.1124],\n",
      "        ...,\n",
      "        [-0.0355, -0.9427, -0.8919,  ...,  0.1497,  0.1297,  0.1124],\n",
      "        [-0.0355, -0.9427, -0.8919,  ...,  0.1497,  0.1297,  0.1124],\n",
      "        [-0.0355, -0.9427, -0.8919,  ...,  0.1497,  0.1297,  0.1124]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4480, -0.7157, -0.6643,  ...,  0.1496,  0.1297,  0.1124],\n",
      "        [ 0.4480, -0.7157, -0.6643,  ...,  0.1496,  0.1297,  0.1124],\n",
      "        [ 0.4480, -0.7157, -0.6643,  ...,  0.1496,  0.1297,  0.1124],\n",
      "        ...,\n",
      "        [ 0.4480, -0.7157, -0.6643,  ...,  0.1496,  0.1297,  0.1124],\n",
      "        [ 0.4480, -0.7157, -0.6643,  ...,  0.1496,  0.1297,  0.1124],\n",
      "        [ 0.4480, -0.7157, -0.6643,  ...,  0.1496,  0.1297,  0.1124]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8218, -0.3566, -0.3444,  ...,  0.1495,  0.1296,  0.1123],\n",
      "        [ 0.8218, -0.3566, -0.3444,  ...,  0.1495,  0.1296,  0.1123],\n",
      "        [ 0.8218, -0.3566, -0.3444,  ...,  0.1495,  0.1296,  0.1123],\n",
      "        ...,\n",
      "        [ 0.8218, -0.3566, -0.3444,  ...,  0.1495,  0.1296,  0.1123],\n",
      "        [ 0.8218, -0.3566, -0.3444,  ...,  0.1495,  0.1296,  0.1123],\n",
      "        [ 0.8218, -0.3566, -0.3444,  ...,  0.1495,  0.1296,  0.1123]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9944, 0.0684, 0.0233,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9944, 0.0684, 0.0233,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9944, 0.0684, 0.0233,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        ...,\n",
      "        [0.9944, 0.0684, 0.0233,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9944, 0.0684, 0.0233,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9944, 0.0684, 0.0233,  ..., 0.1494, 0.1295, 0.1122]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9235, 0.4806, 0.3878,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9235, 0.4806, 0.3878,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9235, 0.4806, 0.3878,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        ...,\n",
      "        [0.9235, 0.4806, 0.3878,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9235, 0.4806, 0.3878,  ..., 0.1494, 0.1295, 0.1122],\n",
      "        [0.9235, 0.4806, 0.3878,  ..., 0.1494, 0.1295, 0.1122]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.6265, 0.8042, 0.6985,  ..., 0.1493, 0.1294, 0.1121],\n",
      "        [0.6265, 0.8042, 0.6985,  ..., 0.1493, 0.1294, 0.1121],\n",
      "        [0.6265, 0.8042, 0.6985,  ..., 0.1493, 0.1294, 0.1121],\n",
      "        ...,\n",
      "        [0.6265, 0.8042, 0.6985,  ..., 0.1493, 0.1294, 0.1121],\n",
      "        [0.6265, 0.8042, 0.6985,  ..., 0.1493, 0.1294, 0.1121],\n",
      "        [0.6265, 0.8042, 0.6985,  ..., 0.1493, 0.1294, 0.1121]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.1761, 0.9794, 0.9120,  ..., 0.1492, 0.1293, 0.1121],\n",
      "        [0.1761, 0.9794, 0.9120,  ..., 0.1492, 0.1293, 0.1121],\n",
      "        [0.1761, 0.9794, 0.9120,  ..., 0.1492, 0.1293, 0.1121],\n",
      "        ...,\n",
      "        [0.1761, 0.9794, 0.9120,  ..., 0.1492, 0.1293, 0.1121],\n",
      "        [0.1761, 0.9794, 0.9120,  ..., 0.1492, 0.1293, 0.1121],\n",
      "        [0.1761, 0.9794, 0.9120,  ..., 0.1492, 0.1293, 0.1121]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3173,  0.9738,  0.9989,  ...,  0.1491,  0.1293,  0.1120],\n",
      "        [-0.3173,  0.9738,  0.9989,  ...,  0.1491,  0.1293,  0.1120],\n",
      "        [-0.3173,  0.9738,  0.9989,  ...,  0.1491,  0.1293,  0.1120],\n",
      "        ...,\n",
      "        [-0.3173,  0.9738,  0.9989,  ...,  0.1491,  0.1293,  0.1120],\n",
      "        [-0.3173,  0.9738,  0.9989,  ...,  0.1491,  0.1293,  0.1120],\n",
      "        [-0.3173,  0.9738,  0.9989,  ...,  0.1491,  0.1293,  0.1120]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7331,  0.7884,  0.9469,  ...,  0.1490,  0.1292,  0.1120],\n",
      "        [-0.7331,  0.7884,  0.9469,  ...,  0.1490,  0.1292,  0.1120],\n",
      "        [-0.7331,  0.7884,  0.9469,  ...,  0.1490,  0.1292,  0.1120],\n",
      "        ...,\n",
      "        [-0.7331,  0.7884,  0.9469,  ...,  0.1490,  0.1292,  0.1120],\n",
      "        [-0.7331,  0.7884,  0.9469,  ...,  0.1490,  0.1292,  0.1120],\n",
      "        [-0.7331,  0.7884,  0.9469,  ...,  0.1490,  0.1292,  0.1120]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9694,  0.4576,  0.7634,  ...,  0.1490,  0.1291,  0.1119],\n",
      "        [-0.9694,  0.4576,  0.7634,  ...,  0.1490,  0.1291,  0.1119],\n",
      "        [-0.9694,  0.4576,  0.7634,  ...,  0.1490,  0.1291,  0.1119],\n",
      "        ...,\n",
      "        [-0.9694,  0.4576,  0.7634,  ...,  0.1490,  0.1291,  0.1119],\n",
      "        [-0.9694,  0.4576,  0.7634,  ...,  0.1490,  0.1291,  0.1119],\n",
      "        [-0.9694,  0.4576,  0.7634,  ...,  0.1490,  0.1291,  0.1119]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9684,  0.0423,  0.4738,  ...,  0.1489,  0.1291,  0.1118],\n",
      "        [-0.9684,  0.0423,  0.4738,  ...,  0.1489,  0.1291,  0.1118],\n",
      "        [-0.9684,  0.0423,  0.4738,  ...,  0.1489,  0.1291,  0.1118],\n",
      "        ...,\n",
      "        [-0.9684,  0.0423,  0.4738,  ...,  0.1489,  0.1291,  0.1118],\n",
      "        [-0.9684,  0.0423,  0.4738,  ...,  0.1489,  0.1291,  0.1118],\n",
      "        [-0.9684,  0.0423,  0.4738,  ...,  0.1489,  0.1291,  0.1118]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7302, -0.3808,  0.1184,  ...,  0.1488,  0.1290,  0.1118],\n",
      "        [-0.7302, -0.3808,  0.1184,  ...,  0.1488,  0.1290,  0.1118],\n",
      "        [-0.7302, -0.3808,  0.1184,  ...,  0.1488,  0.1290,  0.1118],\n",
      "        ...,\n",
      "        [-0.7302, -0.3808,  0.1184,  ...,  0.1488,  0.1290,  0.1118],\n",
      "        [-0.7302, -0.3808,  0.1184,  ...,  0.1488,  0.1290,  0.1118],\n",
      "        [-0.7302, -0.3808,  0.1184,  ...,  0.1488,  0.1290,  0.1118]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3133, -0.7336, -0.2535,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [-0.3133, -0.7336, -0.2535,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [-0.3133, -0.7336, -0.2535,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        ...,\n",
      "        [-0.3133, -0.7336, -0.2535,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [-0.3133, -0.7336, -0.2535,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [-0.3133, -0.7336, -0.2535,  ...,  0.1487,  0.1289,  0.1117]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1803, -0.9511, -0.5901,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [ 0.1803, -0.9511, -0.5901,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [ 0.1803, -0.9511, -0.5901,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        ...,\n",
      "        [ 0.1803, -0.9511, -0.5901,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [ 0.1803, -0.9511, -0.5901,  ...,  0.1487,  0.1289,  0.1117],\n",
      "        [ 0.1803, -0.9511, -0.5901,  ...,  0.1487,  0.1289,  0.1117]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6298, -0.9929, -0.8448,  ...,  0.1486,  0.1288,  0.1116],\n",
      "        [ 0.6298, -0.9929, -0.8448,  ...,  0.1486,  0.1288,  0.1116],\n",
      "        [ 0.6298, -0.9929, -0.8448,  ...,  0.1486,  0.1288,  0.1116],\n",
      "        ...,\n",
      "        [ 0.6298, -0.9929, -0.8448,  ...,  0.1486,  0.1288,  0.1116],\n",
      "        [ 0.6298, -0.9929, -0.8448,  ...,  0.1486,  0.1288,  0.1116],\n",
      "        [ 0.6298, -0.9929, -0.8448,  ...,  0.1486,  0.1288,  0.1116]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9251, -0.8516, -0.9821,  ...,  0.1485,  0.1287,  0.1116],\n",
      "        [ 0.9251, -0.8516, -0.9821,  ...,  0.1485,  0.1287,  0.1116],\n",
      "        [ 0.9251, -0.8516, -0.9821,  ...,  0.1485,  0.1287,  0.1116],\n",
      "        ...,\n",
      "        [ 0.9251, -0.8516, -0.9821,  ...,  0.1485,  0.1287,  0.1116],\n",
      "        [ 0.9251, -0.8516, -0.9821,  ...,  0.1485,  0.1287,  0.1116],\n",
      "        [ 0.9251, -0.8516, -0.9821,  ...,  0.1485,  0.1287,  0.1116]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9939, -0.5530, -0.9829,  ...,  0.1484,  0.1287,  0.1115],\n",
      "        [ 0.9939, -0.5530, -0.9829,  ...,  0.1484,  0.1287,  0.1115],\n",
      "        [ 0.9939, -0.5530, -0.9829,  ...,  0.1484,  0.1287,  0.1115],\n",
      "        ...,\n",
      "        [ 0.9939, -0.5530, -0.9829,  ...,  0.1484,  0.1287,  0.1115],\n",
      "        [ 0.9939, -0.5530, -0.9829,  ...,  0.1484,  0.1287,  0.1115],\n",
      "        [ 0.9939, -0.5530, -0.9829,  ...,  0.1484,  0.1287,  0.1115]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8193, -0.1524, -0.8471,  ...,  0.1484,  0.1286,  0.1114],\n",
      "        [ 0.8193, -0.1524, -0.8471,  ...,  0.1484,  0.1286,  0.1114],\n",
      "        [ 0.8193, -0.1524, -0.8471,  ...,  0.1484,  0.1286,  0.1114],\n",
      "        ...,\n",
      "        [ 0.8193, -0.1524, -0.8471,  ...,  0.1484,  0.1286,  0.1114],\n",
      "        [ 0.8193, -0.1524, -0.8471,  ...,  0.1484,  0.1286,  0.1114],\n",
      "        [ 0.8193, -0.1524, -0.8471,  ...,  0.1484,  0.1286,  0.1114]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4442,  0.2763, -0.5937,  ...,  0.1483,  0.1285,  0.1114],\n",
      "        [ 0.4442,  0.2763, -0.5937,  ...,  0.1483,  0.1285,  0.1114],\n",
      "        [ 0.4442,  0.2763, -0.5937,  ...,  0.1483,  0.1285,  0.1114],\n",
      "        ...,\n",
      "        [ 0.4442,  0.2763, -0.5937,  ...,  0.1483,  0.1285,  0.1114],\n",
      "        [ 0.4442,  0.2763, -0.5937,  ...,  0.1483,  0.1285,  0.1114],\n",
      "        [ 0.4442,  0.2763, -0.5937,  ...,  0.1483,  0.1285,  0.1114]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0397,  0.6541, -0.2578,  ...,  0.1482,  0.1285,  0.1113],\n",
      "        [-0.0397,  0.6541, -0.2578,  ...,  0.1482,  0.1285,  0.1113],\n",
      "        [-0.0397,  0.6541, -0.2578,  ...,  0.1482,  0.1285,  0.1113],\n",
      "        ...,\n",
      "        [-0.0397,  0.6541, -0.2578,  ...,  0.1482,  0.1285,  0.1113],\n",
      "        [-0.0397,  0.6541, -0.2578,  ...,  0.1482,  0.1285,  0.1113],\n",
      "        [-0.0397,  0.6541, -0.2578,  ...,  0.1482,  0.1285,  0.1113]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5139,  0.9111,  0.1140,  ...,  0.1481,  0.1284,  0.1113],\n",
      "        [-0.5139,  0.9111,  0.1140,  ...,  0.1481,  0.1284,  0.1113],\n",
      "        [-0.5139,  0.9111,  0.1140,  ...,  0.1481,  0.1284,  0.1113],\n",
      "        ...,\n",
      "        [-0.5139,  0.9111,  0.1140,  ...,  0.1481,  0.1284,  0.1113],\n",
      "        [-0.5139,  0.9111,  0.1140,  ...,  0.1481,  0.1284,  0.1113],\n",
      "        [-0.5139,  0.9111,  0.1140,  ...,  0.1481,  0.1284,  0.1113]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8623,  1.0000,  0.4699,  ...,  0.1481,  0.1283,  0.1112],\n",
      "        [-0.8623,  1.0000,  0.4699,  ...,  0.1481,  0.1283,  0.1112],\n",
      "        [-0.8623,  1.0000,  0.4699,  ...,  0.1481,  0.1283,  0.1112],\n",
      "        ...,\n",
      "        [-0.8623,  1.0000,  0.4699,  ...,  0.1481,  0.1283,  0.1112],\n",
      "        [-0.8623,  1.0000,  0.4699,  ...,  0.1481,  0.1283,  0.1112],\n",
      "        [-0.8623,  1.0000,  0.4699,  ...,  0.1481,  0.1283,  0.1112]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9995,  0.9043,  0.7605,  ...,  0.1480,  0.1283,  0.1111],\n",
      "        [-0.9995,  0.9043,  0.7605,  ...,  0.1480,  0.1283,  0.1111],\n",
      "        [-0.9995,  0.9043,  0.7605,  ...,  0.1480,  0.1283,  0.1111],\n",
      "        ...,\n",
      "        [-0.9995,  0.9043,  0.7605,  ...,  0.1480,  0.1283,  0.1111],\n",
      "        [-0.9995,  0.9043,  0.7605,  ...,  0.1480,  0.1283,  0.1111],\n",
      "        [-0.9995,  0.9043,  0.7605,  ...,  0.1480,  0.1283,  0.1111]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8920,  0.6417,  0.9455,  ...,  0.1479,  0.1282,  0.1111],\n",
      "        [-0.8920,  0.6417,  0.9455,  ...,  0.1479,  0.1282,  0.1111],\n",
      "        [-0.8920,  0.6417,  0.9455,  ...,  0.1479,  0.1282,  0.1111],\n",
      "        ...,\n",
      "        [-0.8920,  0.6417,  0.9455,  ...,  0.1479,  0.1282,  0.1111],\n",
      "        [-0.8920,  0.6417,  0.9455,  ...,  0.1479,  0.1282,  0.1111],\n",
      "        [-0.8920,  0.6417,  0.9455,  ...,  0.1479,  0.1282,  0.1111]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5662,  0.2607,  0.9991,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.5662,  0.2607,  0.9991,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.5662,  0.2607,  0.9991,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        ...,\n",
      "        [-0.5662,  0.2607,  0.9991,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.5662,  0.2607,  0.9991,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.5662,  0.2607,  0.9991,  ...,  0.1478,  0.1281,  0.1110]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1017, -0.1684,  0.9138,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.1017, -0.1684,  0.9138,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.1017, -0.1684,  0.9138,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        ...,\n",
      "        [-0.1017, -0.1684,  0.9138,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.1017, -0.1684,  0.9138,  ...,  0.1478,  0.1281,  0.1110],\n",
      "        [-0.1017, -0.1684,  0.9138,  ...,  0.1478,  0.1281,  0.1110]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3877, -0.5664,  0.7016,  ...,  0.1477,  0.1280,  0.1109],\n",
      "        [ 0.3877, -0.5664,  0.7016,  ...,  0.1477,  0.1280,  0.1109],\n",
      "        [ 0.3877, -0.5664,  0.7016,  ...,  0.1477,  0.1280,  0.1109],\n",
      "        ...,\n",
      "        [ 0.3877, -0.5664,  0.7016,  ...,  0.1477,  0.1280,  0.1109],\n",
      "        [ 0.3877, -0.5664,  0.7016,  ...,  0.1477,  0.1280,  0.1109],\n",
      "        [ 0.3877, -0.5664,  0.7016,  ...,  0.1477,  0.1280,  0.1109]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7822, -0.8599,  0.3919,  ...,  0.1476,  0.1279,  0.1109],\n",
      "        [ 0.7822, -0.8599,  0.3919,  ...,  0.1476,  0.1279,  0.1109],\n",
      "        [ 0.7822, -0.8599,  0.3919,  ...,  0.1476,  0.1279,  0.1109],\n",
      "        ...,\n",
      "        [ 0.7822, -0.8599,  0.3919,  ...,  0.1476,  0.1279,  0.1109],\n",
      "        [ 0.7822, -0.8599,  0.3919,  ...,  0.1476,  0.1279,  0.1109],\n",
      "        [ 0.7822, -0.8599,  0.3919,  ...,  0.1476,  0.1279,  0.1109]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9851, -0.9947,  0.0277,  ...,  0.1475,  0.1279,  0.1108],\n",
      "        [ 0.9851, -0.9947,  0.0277,  ...,  0.1475,  0.1279,  0.1108],\n",
      "        [ 0.9851, -0.9947,  0.0277,  ...,  0.1475,  0.1279,  0.1108],\n",
      "        ...,\n",
      "        [ 0.9851, -0.9947,  0.0277,  ...,  0.1475,  0.1279,  0.1108],\n",
      "        [ 0.9851, -0.9947,  0.0277,  ...,  0.1475,  0.1279,  0.1108],\n",
      "        [ 0.9851, -0.9947,  0.0277,  ...,  0.1475,  0.1279,  0.1108]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9469, -0.9459, -0.3403,  ...,  0.1474,  0.1278,  0.1107],\n",
      "        [ 0.9469, -0.9459, -0.3403,  ...,  0.1474,  0.1278,  0.1107],\n",
      "        [ 0.9469, -0.9459, -0.3403,  ...,  0.1474,  0.1278,  0.1107],\n",
      "        ...,\n",
      "        [ 0.9469, -0.9459, -0.3403,  ...,  0.1474,  0.1278,  0.1107],\n",
      "        [ 0.9469, -0.9459, -0.3403,  ...,  0.1474,  0.1278,  0.1107],\n",
      "        [ 0.9469, -0.9459, -0.3403,  ...,  0.1474,  0.1278,  0.1107]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6768, -0.7225, -0.6610,  ...,  0.1474,  0.1277,  0.1107],\n",
      "        [ 0.6768, -0.7225, -0.6610,  ...,  0.1474,  0.1277,  0.1107],\n",
      "        [ 0.6768, -0.7225, -0.6610,  ...,  0.1474,  0.1277,  0.1107],\n",
      "        ...,\n",
      "        [ 0.6768, -0.7225, -0.6610,  ...,  0.1474,  0.1277,  0.1107],\n",
      "        [ 0.6768, -0.7225, -0.6610,  ...,  0.1474,  0.1277,  0.1107],\n",
      "        [ 0.6768, -0.7225, -0.6610,  ...,  0.1474,  0.1277,  0.1107]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2410, -0.3658, -0.8899,  ...,  0.1473,  0.1277,  0.1106],\n",
      "        [ 0.2410, -0.3658, -0.8899,  ...,  0.1473,  0.1277,  0.1106],\n",
      "        [ 0.2410, -0.3658, -0.8899,  ...,  0.1473,  0.1277,  0.1106],\n",
      "        ...,\n",
      "        [ 0.2410, -0.3658, -0.8899,  ...,  0.1473,  0.1277,  0.1106],\n",
      "        [ 0.2410, -0.3658, -0.8899,  ...,  0.1473,  0.1277,  0.1106],\n",
      "        [ 0.2410, -0.3658, -0.8899,  ...,  0.1473,  0.1277,  0.1106]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2538,  0.0585, -0.9951,  ...,  0.1472,  0.1276,  0.1106],\n",
      "        [-0.2538,  0.0585, -0.9951,  ...,  0.1472,  0.1276,  0.1106],\n",
      "        [-0.2538,  0.0585, -0.9951,  ...,  0.1472,  0.1276,  0.1106],\n",
      "        ...,\n",
      "        [-0.2538,  0.0585, -0.9951,  ...,  0.1472,  0.1276,  0.1106],\n",
      "        [-0.2538,  0.0585, -0.9951,  ...,  0.1472,  0.1276,  0.1106],\n",
      "        [-0.2538,  0.0585, -0.9951,  ...,  0.1472,  0.1276,  0.1106]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6864,  0.4719, -0.9621,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.6864,  0.4719, -0.9621,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.6864,  0.4719, -0.9621,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        ...,\n",
      "        [-0.6864,  0.4719, -0.9621,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.6864,  0.4719, -0.9621,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.6864,  0.4719, -0.9621,  ...,  0.1471,  0.1275,  0.1105]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9510,  0.7983, -0.7954,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.9510,  0.7983, -0.7954,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.9510,  0.7983, -0.7954,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        ...,\n",
      "        [-0.9510,  0.7983, -0.7954,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.9510,  0.7983, -0.7954,  ...,  0.1471,  0.1275,  0.1105],\n",
      "        [-0.9510,  0.7983, -0.7954,  ...,  0.1471,  0.1275,  0.1105]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9828,  0.9773, -0.5182,  ...,  0.1470,  0.1274,  0.1104],\n",
      "        [-0.9828,  0.9773, -0.5182,  ...,  0.1470,  0.1274,  0.1104],\n",
      "        [-0.9828,  0.9773, -0.5182,  ...,  0.1470,  0.1274,  0.1104],\n",
      "        ...,\n",
      "        [-0.9828,  0.9773, -0.5182,  ...,  0.1470,  0.1274,  0.1104],\n",
      "        [-0.9828,  0.9773, -0.5182,  ...,  0.1470,  0.1274,  0.1104],\n",
      "        [-0.9828,  0.9773, -0.5182,  ...,  0.1470,  0.1274,  0.1104]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7739,  0.9760, -0.1689,  ...,  0.1469,  0.1273,  0.1103],\n",
      "        [-0.7739,  0.9760, -0.1689,  ...,  0.1469,  0.1273,  0.1103],\n",
      "        [-0.7739,  0.9760, -0.1689,  ...,  0.1469,  0.1273,  0.1103],\n",
      "        ...,\n",
      "        [-0.7739,  0.9760, -0.1689,  ...,  0.1469,  0.1273,  0.1103],\n",
      "        [-0.7739,  0.9760, -0.1689,  ...,  0.1469,  0.1273,  0.1103],\n",
      "        [-0.7739,  0.9760, -0.1689,  ...,  0.1469,  0.1273,  0.1103]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3756,  0.7945,  0.2037,  ...,  0.1468,  0.1273,  0.1103],\n",
      "        [-0.3756,  0.7945,  0.2037,  ...,  0.1468,  0.1273,  0.1103],\n",
      "        [-0.3756,  0.7945,  0.2037,  ...,  0.1468,  0.1273,  0.1103],\n",
      "        ...,\n",
      "        [-0.3756,  0.7945,  0.2037,  ...,  0.1468,  0.1273,  0.1103],\n",
      "        [-0.3756,  0.7945,  0.2037,  ...,  0.1468,  0.1273,  0.1103],\n",
      "        [-0.3756,  0.7945,  0.2037,  ...,  0.1468,  0.1273,  0.1103]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.1147, 0.4664, 0.5481,  ..., 0.1468, 0.1272, 0.1102],\n",
      "        [0.1147, 0.4664, 0.5481,  ..., 0.1468, 0.1272, 0.1102],\n",
      "        [0.1147, 0.4664, 0.5481,  ..., 0.1468, 0.1272, 0.1102],\n",
      "        ...,\n",
      "        [0.1147, 0.4664, 0.5481,  ..., 0.1468, 0.1272, 0.1102],\n",
      "        [0.1147, 0.4664, 0.5481,  ..., 0.1468, 0.1272, 0.1102],\n",
      "        [0.1147, 0.4664, 0.5481,  ..., 0.1468, 0.1272, 0.1102]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.5769, 0.0522, 0.8163,  ..., 0.1467, 0.1271, 0.1102],\n",
      "        [0.5769, 0.0522, 0.8163,  ..., 0.1467, 0.1271, 0.1102],\n",
      "        [0.5769, 0.0522, 0.8163,  ..., 0.1467, 0.1271, 0.1102],\n",
      "        ...,\n",
      "        [0.5769, 0.0522, 0.8163,  ..., 0.1467, 0.1271, 0.1102],\n",
      "        [0.5769, 0.0522, 0.8163,  ..., 0.1467, 0.1271, 0.1102],\n",
      "        [0.5769, 0.0522, 0.8163,  ..., 0.1467, 0.1271, 0.1102]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8979, -0.3716,  0.9711,  ...,  0.1466,  0.1271,  0.1101],\n",
      "        [ 0.8979, -0.3716,  0.9711,  ...,  0.1466,  0.1271,  0.1101],\n",
      "        [ 0.8979, -0.3716,  0.9711,  ...,  0.1466,  0.1271,  0.1101],\n",
      "        ...,\n",
      "        [ 0.8979, -0.3716,  0.9711,  ...,  0.1466,  0.1271,  0.1101],\n",
      "        [ 0.8979, -0.3716,  0.9711,  ...,  0.1466,  0.1271,  0.1101],\n",
      "        [ 0.8979, -0.3716,  0.9711,  ...,  0.1466,  0.1271,  0.1101]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9990, -0.7269,  0.9910,  ...,  0.1465,  0.1270,  0.1101],\n",
      "        [ 0.9990, -0.7269,  0.9910,  ...,  0.1465,  0.1270,  0.1101],\n",
      "        [ 0.9990, -0.7269,  0.9910,  ...,  0.1465,  0.1270,  0.1101],\n",
      "        ...,\n",
      "        [ 0.9990, -0.7269,  0.9910,  ...,  0.1465,  0.1270,  0.1101],\n",
      "        [ 0.9990, -0.7269,  0.9910,  ...,  0.1465,  0.1270,  0.1101],\n",
      "        [ 0.9990, -0.7269,  0.9910,  ...,  0.1465,  0.1270,  0.1101]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8556, -0.9480,  0.8732,  ...,  0.1465,  0.1269,  0.1100],\n",
      "        [ 0.8556, -0.9480,  0.8732,  ...,  0.1465,  0.1269,  0.1100],\n",
      "        [ 0.8556, -0.9480,  0.8732,  ...,  0.1465,  0.1269,  0.1100],\n",
      "        ...,\n",
      "        [ 0.8556, -0.9480,  0.8732,  ...,  0.1465,  0.1269,  0.1100],\n",
      "        [ 0.8556, -0.9480,  0.8732,  ...,  0.1465,  0.1269,  0.1100],\n",
      "        [ 0.8556, -0.9480,  0.8732,  ...,  0.1465,  0.1269,  0.1100]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5026, -0.9941,  0.6340,  ...,  0.1464,  0.1269,  0.1099],\n",
      "        [ 0.5026, -0.9941,  0.6340,  ...,  0.1464,  0.1269,  0.1099],\n",
      "        [ 0.5026, -0.9941,  0.6340,  ...,  0.1464,  0.1269,  0.1099],\n",
      "        ...,\n",
      "        [ 0.5026, -0.9941,  0.6340,  ...,  0.1464,  0.1269,  0.1099],\n",
      "        [ 0.5026, -0.9941,  0.6340,  ...,  0.1464,  0.1269,  0.1099],\n",
      "        [ 0.5026, -0.9941,  0.6340,  ...,  0.1464,  0.1269,  0.1099]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0266, -0.8567,  0.3068,  ...,  0.1463,  0.1268,  0.1099],\n",
      "        [ 0.0266, -0.8567,  0.3068,  ...,  0.1463,  0.1268,  0.1099],\n",
      "        [ 0.0266, -0.8567,  0.3068,  ...,  0.1463,  0.1268,  0.1099],\n",
      "        ...,\n",
      "        [ 0.0266, -0.8567,  0.3068,  ...,  0.1463,  0.1268,  0.1099],\n",
      "        [ 0.0266, -0.8567,  0.3068,  ...,  0.1463,  0.1268,  0.1099],\n",
      "        [ 0.0266, -0.8567,  0.3068,  ...,  0.1463,  0.1268,  0.1099]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4559, -0.5613, -0.0631,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.4559, -0.5613, -0.0631,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.4559, -0.5613, -0.0631,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        ...,\n",
      "        [-0.4559, -0.5613, -0.0631,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.4559, -0.5613, -0.0631,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.4559, -0.5613, -0.0631,  ...,  0.1462,  0.1267,  0.1098]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8268, -0.1622, -0.4242,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.8268, -0.1622, -0.4242,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.8268, -0.1622, -0.4242,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        ...,\n",
      "        [-0.8268, -0.1622, -0.4242,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.8268, -0.1622, -0.4242,  ...,  0.1462,  0.1267,  0.1098],\n",
      "        [-0.8268, -0.1622, -0.4242,  ...,  0.1462,  0.1267,  0.1098]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9953,  0.2668, -0.7264,  ...,  0.1461,  0.1266,  0.1097],\n",
      "        [-0.9953,  0.2668, -0.7264,  ...,  0.1461,  0.1266,  0.1097],\n",
      "        [-0.9953,  0.2668, -0.7264,  ...,  0.1461,  0.1266,  0.1097],\n",
      "        ...,\n",
      "        [-0.9953,  0.2668, -0.7264,  ...,  0.1461,  0.1266,  0.1097],\n",
      "        [-0.9953,  0.2668, -0.7264,  ...,  0.1461,  0.1266,  0.1097],\n",
      "        [-0.9953,  0.2668, -0.7264,  ...,  0.1461,  0.1266,  0.1097]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9201,  0.6465, -0.9276,  ...,  0.1460,  0.1265,  0.1097],\n",
      "        [-0.9201,  0.6465, -0.9276,  ...,  0.1460,  0.1265,  0.1097],\n",
      "        [-0.9201,  0.6465, -0.9276,  ...,  0.1460,  0.1265,  0.1097],\n",
      "        ...,\n",
      "        [-0.9201,  0.6465, -0.9276,  ...,  0.1460,  0.1265,  0.1097],\n",
      "        [-0.9201,  0.6465, -0.9276,  ...,  0.1460,  0.1265,  0.1097],\n",
      "        [-0.9201,  0.6465, -0.9276,  ...,  0.1460,  0.1265,  0.1097]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6196,  0.9070, -1.0000,  ...,  0.1459,  0.1265,  0.1096],\n",
      "        [-0.6196,  0.9070, -1.0000,  ...,  0.1459,  0.1265,  0.1096],\n",
      "        [-0.6196,  0.9070, -1.0000,  ...,  0.1459,  0.1265,  0.1096],\n",
      "        ...,\n",
      "        [-0.6196,  0.9070, -1.0000,  ...,  0.1459,  0.1265,  0.1096],\n",
      "        [-0.6196,  0.9070, -1.0000,  ...,  0.1459,  0.1265,  0.1096],\n",
      "        [-0.6196,  0.9070, -1.0000,  ...,  0.1459,  0.1265,  0.1096]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1674,  1.0000, -0.9334,  ...,  0.1458,  0.1264,  0.1095],\n",
      "        [-0.1674,  1.0000, -0.9334,  ...,  0.1458,  0.1264,  0.1095],\n",
      "        [-0.1674,  1.0000, -0.9334,  ...,  0.1458,  0.1264,  0.1095],\n",
      "        ...,\n",
      "        [-0.1674,  1.0000, -0.9334,  ...,  0.1458,  0.1264,  0.1095],\n",
      "        [-0.1674,  1.0000, -0.9334,  ...,  0.1458,  0.1264,  0.1095],\n",
      "        [-0.1674,  1.0000, -0.9334,  ...,  0.1458,  0.1264,  0.1095]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3257,  0.9085, -0.7371,  ...,  0.1458,  0.1263,  0.1095],\n",
      "        [ 0.3257,  0.9085, -0.7371,  ...,  0.1458,  0.1263,  0.1095],\n",
      "        [ 0.3257,  0.9085, -0.7371,  ...,  0.1458,  0.1263,  0.1095],\n",
      "        ...,\n",
      "        [ 0.3257,  0.9085, -0.7371,  ...,  0.1458,  0.1263,  0.1095],\n",
      "        [ 0.3257,  0.9085, -0.7371,  ...,  0.1458,  0.1263,  0.1095],\n",
      "        [ 0.3257,  0.9085, -0.7371,  ...,  0.1458,  0.1263,  0.1095]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7391,  0.6493, -0.4384,  ...,  0.1457,  0.1263,  0.1094],\n",
      "        [ 0.7391,  0.6493, -0.4384,  ...,  0.1457,  0.1263,  0.1094],\n",
      "        [ 0.7391,  0.6493, -0.4384,  ...,  0.1457,  0.1263,  0.1094],\n",
      "        ...,\n",
      "        [ 0.7391,  0.6493, -0.4384,  ...,  0.1457,  0.1263,  0.1094],\n",
      "        [ 0.7391,  0.6493, -0.4384,  ...,  0.1457,  0.1263,  0.1094],\n",
      "        [ 0.7391,  0.6493, -0.4384,  ...,  0.1457,  0.1263,  0.1094]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9716,  0.2702, -0.0788,  ...,  0.1456,  0.1262,  0.1094],\n",
      "        [ 0.9716,  0.2702, -0.0788,  ...,  0.1456,  0.1262,  0.1094],\n",
      "        [ 0.9716,  0.2702, -0.0788,  ...,  0.1456,  0.1262,  0.1094],\n",
      "        ...,\n",
      "        [ 0.9716,  0.2702, -0.0788,  ...,  0.1456,  0.1262,  0.1094],\n",
      "        [ 0.9716,  0.2702, -0.0788,  ...,  0.1456,  0.1262,  0.1094],\n",
      "        [ 0.9716,  0.2702, -0.0788,  ...,  0.1456,  0.1262,  0.1094]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9661, -0.1587,  0.2918,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.9661, -0.1587,  0.2918,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.9661, -0.1587,  0.2918,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        ...,\n",
      "        [ 0.9661, -0.1587,  0.2918,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.9661, -0.1587,  0.2918,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.9661, -0.1587,  0.2918,  ...,  0.1455,  0.1261,  0.1093]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7242, -0.5583,  0.6218,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.7242, -0.5583,  0.6218,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.7242, -0.5583,  0.6218,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        ...,\n",
      "        [ 0.7242, -0.5583,  0.6218,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.7242, -0.5583,  0.6218,  ...,  0.1455,  0.1261,  0.1093],\n",
      "        [ 0.7242, -0.5583,  0.6218,  ...,  0.1455,  0.1261,  0.1093]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3049, -0.8549,  0.8654,  ...,  0.1454,  0.1260,  0.1092],\n",
      "        [ 0.3049, -0.8549,  0.8654,  ...,  0.1454,  0.1260,  0.1092],\n",
      "        [ 0.3049, -0.8549,  0.8654,  ...,  0.1454,  0.1260,  0.1092],\n",
      "        ...,\n",
      "        [ 0.3049, -0.8549,  0.8654,  ...,  0.1454,  0.1260,  0.1092],\n",
      "        [ 0.3049, -0.8549,  0.8654,  ...,  0.1454,  0.1260,  0.1092],\n",
      "        [ 0.3049, -0.8549,  0.8654,  ...,  0.1454,  0.1260,  0.1092]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1890, -0.9937,  0.9888,  ...,  0.1453,  0.1259,  0.1091],\n",
      "        [-0.1890, -0.9937,  0.9888,  ...,  0.1453,  0.1259,  0.1091],\n",
      "        [-0.1890, -0.9937,  0.9888,  ...,  0.1453,  0.1259,  0.1091],\n",
      "        ...,\n",
      "        [-0.1890, -0.9937,  0.9888,  ...,  0.1453,  0.1259,  0.1091],\n",
      "        [-0.1890, -0.9937,  0.9888,  ...,  0.1453,  0.1259,  0.1091],\n",
      "        [-0.1890, -0.9937,  0.9888,  ...,  0.1453,  0.1259,  0.1091]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6367, -0.9491,  0.9748,  ...,  0.1452,  0.1259,  0.1091],\n",
      "        [-0.6367, -0.9491,  0.9748,  ...,  0.1452,  0.1259,  0.1091],\n",
      "        [-0.6367, -0.9491,  0.9748,  ...,  0.1452,  0.1259,  0.1091],\n",
      "        ...,\n",
      "        [-0.6367, -0.9491,  0.9748,  ...,  0.1452,  0.1259,  0.1091],\n",
      "        [-0.6367, -0.9491,  0.9748,  ...,  0.1452,  0.1259,  0.1091],\n",
      "        [-0.6367, -0.9491,  0.9748,  ...,  0.1452,  0.1259,  0.1091]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9284, -0.7293,  0.8253,  ...,  0.1452,  0.1258,  0.1090],\n",
      "        [-0.9284, -0.7293,  0.8253,  ...,  0.1452,  0.1258,  0.1090],\n",
      "        [-0.9284, -0.7293,  0.8253,  ...,  0.1452,  0.1258,  0.1090],\n",
      "        ...,\n",
      "        [-0.9284, -0.7293,  0.8253,  ...,  0.1452,  0.1258,  0.1090],\n",
      "        [-0.9284, -0.7293,  0.8253,  ...,  0.1452,  0.1258,  0.1090],\n",
      "        [-0.9284, -0.7293,  0.8253,  ...,  0.1452,  0.1258,  0.1090]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9929, -0.3749,  0.5612,  ...,  0.1451,  0.1258,  0.1090],\n",
      "        [-0.9929, -0.3749,  0.5612,  ...,  0.1451,  0.1258,  0.1090],\n",
      "        [-0.9929, -0.3749,  0.5612,  ...,  0.1451,  0.1258,  0.1090],\n",
      "        ...,\n",
      "        [-0.9929, -0.3749,  0.5612,  ...,  0.1451,  0.1258,  0.1090],\n",
      "        [-0.9929, -0.3749,  0.5612,  ...,  0.1451,  0.1258,  0.1090],\n",
      "        [-0.9929, -0.3749,  0.5612,  ...,  0.1451,  0.1258,  0.1090]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8142,  0.0486,  0.2191,  ...,  0.1450,  0.1257,  0.1089],\n",
      "        [-0.8142,  0.0486,  0.2191,  ...,  0.1450,  0.1257,  0.1089],\n",
      "        [-0.8142,  0.0486,  0.2191,  ...,  0.1450,  0.1257,  0.1089],\n",
      "        ...,\n",
      "        [-0.8142,  0.0486,  0.2191,  ...,  0.1450,  0.1257,  0.1089],\n",
      "        [-0.8142,  0.0486,  0.2191,  ...,  0.1450,  0.1257,  0.1089],\n",
      "        [-0.8142,  0.0486,  0.2191,  ...,  0.1450,  0.1257,  0.1089]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4362,  0.4632, -0.1534,  ...,  0.1449,  0.1256,  0.1089],\n",
      "        [-0.4362,  0.4632, -0.1534,  ...,  0.1449,  0.1256,  0.1089],\n",
      "        [-0.4362,  0.4632, -0.1534,  ...,  0.1449,  0.1256,  0.1089],\n",
      "        ...,\n",
      "        [-0.4362,  0.4632, -0.1534,  ...,  0.1449,  0.1256,  0.1089],\n",
      "        [-0.4362,  0.4632, -0.1534,  ...,  0.1449,  0.1256,  0.1089],\n",
      "        [-0.4362,  0.4632, -0.1534,  ...,  0.1449,  0.1256,  0.1089]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0486,  0.7923, -0.5047,  ...,  0.1449,  0.1256,  0.1088],\n",
      "        [ 0.0486,  0.7923, -0.5047,  ...,  0.1449,  0.1256,  0.1088],\n",
      "        [ 0.0486,  0.7923, -0.5047,  ...,  0.1449,  0.1256,  0.1088],\n",
      "        ...,\n",
      "        [ 0.0486,  0.7923, -0.5047,  ...,  0.1449,  0.1256,  0.1088],\n",
      "        [ 0.0486,  0.7923, -0.5047,  ...,  0.1449,  0.1256,  0.1088],\n",
      "        [ 0.0486,  0.7923, -0.5047,  ...,  0.1449,  0.1256,  0.1088]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5215,  0.9752, -0.7858,  ...,  0.1448,  0.1255,  0.1087],\n",
      "        [ 0.5215,  0.9752, -0.7858,  ...,  0.1448,  0.1255,  0.1087],\n",
      "        [ 0.5215,  0.9752, -0.7858,  ...,  0.1448,  0.1255,  0.1087],\n",
      "        ...,\n",
      "        [ 0.5215,  0.9752, -0.7858,  ...,  0.1448,  0.1255,  0.1087],\n",
      "        [ 0.5215,  0.9752, -0.7858,  ...,  0.1448,  0.1255,  0.1087],\n",
      "        [ 0.5215,  0.9752, -0.7858,  ...,  0.1448,  0.1255,  0.1087]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8667,  0.9781, -0.9577,  ...,  0.1447,  0.1254,  0.1087],\n",
      "        [ 0.8667,  0.9781, -0.9577,  ...,  0.1447,  0.1254,  0.1087],\n",
      "        [ 0.8667,  0.9781, -0.9577,  ...,  0.1447,  0.1254,  0.1087],\n",
      "        ...,\n",
      "        [ 0.8667,  0.9781, -0.9577,  ...,  0.1447,  0.1254,  0.1087],\n",
      "        [ 0.8667,  0.9781, -0.9577,  ...,  0.1447,  0.1254,  0.1087],\n",
      "        [ 0.8667,  0.9781, -0.9577,  ...,  0.1447,  0.1254,  0.1087]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9998,  0.8004, -0.9966,  ...,  0.1446,  0.1254,  0.1086],\n",
      "        [ 0.9998,  0.8004, -0.9966,  ...,  0.1446,  0.1254,  0.1086],\n",
      "        [ 0.9998,  0.8004, -0.9966,  ...,  0.1446,  0.1254,  0.1086],\n",
      "        ...,\n",
      "        [ 0.9998,  0.8004, -0.9966,  ...,  0.1446,  0.1254,  0.1086],\n",
      "        [ 0.9998,  0.8004, -0.9966,  ...,  0.1446,  0.1254,  0.1086],\n",
      "        [ 0.9998,  0.8004, -0.9966,  ...,  0.1446,  0.1254,  0.1086]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8880,  0.4751, -0.8969,  ...,  0.1446,  0.1253,  0.1086],\n",
      "        [ 0.8880,  0.4751, -0.8969,  ...,  0.1446,  0.1253,  0.1086],\n",
      "        [ 0.8880,  0.4751, -0.8969,  ...,  0.1446,  0.1253,  0.1086],\n",
      "        ...,\n",
      "        [ 0.8880,  0.4751, -0.8969,  ...,  0.1446,  0.1253,  0.1086],\n",
      "        [ 0.8880,  0.4751, -0.8969,  ...,  0.1446,  0.1253,  0.1086],\n",
      "        [ 0.8880,  0.4751, -0.8969,  ...,  0.1446,  0.1253,  0.1086]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5589,  0.0620, -0.6727,  ...,  0.1445,  0.1252,  0.1085],\n",
      "        [ 0.5589,  0.0620, -0.6727,  ...,  0.1445,  0.1252,  0.1085],\n",
      "        [ 0.5589,  0.0620, -0.6727,  ...,  0.1445,  0.1252,  0.1085],\n",
      "        ...,\n",
      "        [ 0.5589,  0.0620, -0.6727,  ...,  0.1445,  0.1252,  0.1085],\n",
      "        [ 0.5589,  0.0620, -0.6727,  ...,  0.1445,  0.1252,  0.1085],\n",
      "        [ 0.5589,  0.0620, -0.6727,  ...,  0.1445,  0.1252,  0.1085]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0929, -0.3625, -0.3550,  ...,  0.1444,  0.1252,  0.1085],\n",
      "        [ 0.0929, -0.3625, -0.3550,  ...,  0.1444,  0.1252,  0.1085],\n",
      "        [ 0.0929, -0.3625, -0.3550,  ...,  0.1444,  0.1252,  0.1085],\n",
      "        ...,\n",
      "        [ 0.0929, -0.3625, -0.3550,  ...,  0.1444,  0.1252,  0.1085],\n",
      "        [ 0.0929, -0.3625, -0.3550,  ...,  0.1444,  0.1252,  0.1085],\n",
      "        [ 0.0929, -0.3625, -0.3550,  ...,  0.1444,  0.1252,  0.1085]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3959, -0.7201,  0.0120,  ...,  0.1443,  0.1251,  0.1084],\n",
      "        [-0.3959, -0.7201,  0.0120,  ...,  0.1443,  0.1251,  0.1084],\n",
      "        [-0.3959, -0.7201,  0.0120,  ...,  0.1443,  0.1251,  0.1084],\n",
      "        ...,\n",
      "        [-0.3959, -0.7201,  0.0120,  ...,  0.1443,  0.1251,  0.1084],\n",
      "        [-0.3959, -0.7201,  0.0120,  ...,  0.1443,  0.1251,  0.1084],\n",
      "        [-0.3959, -0.7201,  0.0120,  ...,  0.1443,  0.1251,  0.1084]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7877, -0.9448,  0.3774,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.7877, -0.9448,  0.3774,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.7877, -0.9448,  0.3774,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        ...,\n",
      "        [-0.7877, -0.9448,  0.3774,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.7877, -0.9448,  0.3774,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.7877, -0.9448,  0.3774,  ...,  0.1442,  0.1250,  0.1083]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9866, -0.9951,  0.6904,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.9866, -0.9951,  0.6904,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.9866, -0.9951,  0.6904,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        ...,\n",
      "        [-0.9866, -0.9951,  0.6904,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.9866, -0.9951,  0.6904,  ...,  0.1442,  0.1250,  0.1083],\n",
      "        [-0.9866, -0.9951,  0.6904,  ...,  0.1442,  0.1250,  0.1083]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9440, -0.8618,  0.9073,  ...,  0.1441,  0.1249,  0.1082],\n",
      "        [-0.9440, -0.8618,  0.9073,  ...,  0.1441,  0.1249,  0.1082],\n",
      "        [-0.9440, -0.8618,  0.9073,  ...,  0.1441,  0.1249,  0.1082],\n",
      "        ...,\n",
      "        [-0.9440, -0.8618,  0.9073,  ...,  0.1441,  0.1249,  0.1082],\n",
      "        [-0.9440, -0.8618,  0.9073,  ...,  0.1441,  0.1249,  0.1082],\n",
      "        [-0.9440, -0.8618,  0.9073,  ...,  0.1441,  0.1249,  0.1082]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6703, -0.5694,  0.9983,  ...,  0.1440,  0.1248,  0.1082],\n",
      "        [-0.6703, -0.5694,  0.9983,  ...,  0.1440,  0.1248,  0.1082],\n",
      "        [-0.6703, -0.5694,  0.9983,  ...,  0.1440,  0.1248,  0.1082],\n",
      "        ...,\n",
      "        [-0.6703, -0.5694,  0.9983,  ...,  0.1440,  0.1248,  0.1082],\n",
      "        [-0.6703, -0.5694,  0.9983,  ...,  0.1440,  0.1248,  0.1082],\n",
      "        [-0.6703, -0.5694,  0.9983,  ...,  0.1440,  0.1248,  0.1082]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2324, -0.1720,  0.9505,  ...,  0.1439,  0.1248,  0.1081],\n",
      "        [-0.2324, -0.1720,  0.9505,  ...,  0.1439,  0.1248,  0.1081],\n",
      "        [-0.2324, -0.1720,  0.9505,  ...,  0.1439,  0.1248,  0.1081],\n",
      "        ...,\n",
      "        [-0.2324, -0.1720,  0.9505,  ...,  0.1439,  0.1248,  0.1081],\n",
      "        [-0.2324, -0.1720,  0.9505,  ...,  0.1439,  0.1248,  0.1081],\n",
      "        [-0.2324, -0.1720,  0.9505,  ...,  0.1439,  0.1248,  0.1081]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.2623, 0.2572, 0.7706,  ..., 0.1439, 0.1247, 0.1080],\n",
      "        [0.2623, 0.2572, 0.7706,  ..., 0.1439, 0.1247, 0.1080],\n",
      "        [0.2623, 0.2572, 0.7706,  ..., 0.1439, 0.1247, 0.1080],\n",
      "        ...,\n",
      "        [0.2623, 0.2572, 0.7706,  ..., 0.1439, 0.1247, 0.1080],\n",
      "        [0.2623, 0.2572, 0.7706,  ..., 0.1439, 0.1247, 0.1080],\n",
      "        [0.2623, 0.2572, 0.7706,  ..., 0.1439, 0.1247, 0.1080]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.6928, 0.6389, 0.4837,  ..., 0.1438, 0.1246, 0.1080],\n",
      "        [0.6928, 0.6389, 0.4837,  ..., 0.1438, 0.1246, 0.1080],\n",
      "        [0.6928, 0.6389, 0.4837,  ..., 0.1438, 0.1246, 0.1080],\n",
      "        ...,\n",
      "        [0.6928, 0.6389, 0.4837,  ..., 0.1438, 0.1246, 0.1080],\n",
      "        [0.6928, 0.6389, 0.4837,  ..., 0.1438, 0.1246, 0.1080],\n",
      "        [0.6928, 0.6389, 0.4837,  ..., 0.1438, 0.1246, 0.1080]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9537, 0.9027, 0.1296,  ..., 0.1437, 0.1246, 0.1079],\n",
      "        [0.9537, 0.9027, 0.1296,  ..., 0.1437, 0.1246, 0.1079],\n",
      "        [0.9537, 0.9027, 0.1296,  ..., 0.1437, 0.1246, 0.1079],\n",
      "        ...,\n",
      "        [0.9537, 0.9027, 0.1296,  ..., 0.1437, 0.1246, 0.1079],\n",
      "        [0.9537, 0.9027, 0.1296,  ..., 0.1437, 0.1246, 0.1079],\n",
      "        [0.9537, 0.9027, 0.1296,  ..., 0.1437, 0.1246, 0.1079]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9811,  0.9999, -0.2425,  ...,  0.1436,  0.1245,  0.1079],\n",
      "        [ 0.9811,  0.9999, -0.2425,  ...,  0.1436,  0.1245,  0.1079],\n",
      "        [ 0.9811,  0.9999, -0.2425,  ...,  0.1436,  0.1245,  0.1079],\n",
      "        ...,\n",
      "        [ 0.9811,  0.9999, -0.2425,  ...,  0.1436,  0.1245,  0.1079],\n",
      "        [ 0.9811,  0.9999, -0.2425,  ...,  0.1436,  0.1245,  0.1079],\n",
      "        [ 0.9811,  0.9999, -0.2425,  ...,  0.1436,  0.1245,  0.1079]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7683,  0.9126, -0.5810,  ...,  0.1436,  0.1244,  0.1078],\n",
      "        [ 0.7683,  0.9126, -0.5810,  ...,  0.1436,  0.1244,  0.1078],\n",
      "        [ 0.7683,  0.9126, -0.5810,  ...,  0.1436,  0.1244,  0.1078],\n",
      "        ...,\n",
      "        [ 0.7683,  0.9126, -0.5810,  ...,  0.1436,  0.1244,  0.1078],\n",
      "        [ 0.7683,  0.9126, -0.5810,  ...,  0.1436,  0.1244,  0.1078],\n",
      "        [ 0.7683,  0.9126, -0.5810,  ...,  0.1436,  0.1244,  0.1078]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3674,  0.6568, -0.8387,  ...,  0.1435,  0.1244,  0.1078],\n",
      "        [ 0.3674,  0.6568, -0.8387,  ...,  0.1435,  0.1244,  0.1078],\n",
      "        [ 0.3674,  0.6568, -0.8387,  ...,  0.1435,  0.1244,  0.1078],\n",
      "        ...,\n",
      "        [ 0.3674,  0.6568, -0.8387,  ...,  0.1435,  0.1244,  0.1078],\n",
      "        [ 0.3674,  0.6568, -0.8387,  ...,  0.1435,  0.1244,  0.1078],\n",
      "        [ 0.3674,  0.6568, -0.8387,  ...,  0.1435,  0.1244,  0.1078]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1235,  0.2798, -0.9799,  ...,  0.1434,  0.1243,  0.1077],\n",
      "        [-0.1235,  0.2798, -0.9799,  ...,  0.1434,  0.1243,  0.1077],\n",
      "        [-0.1235,  0.2798, -0.9799,  ...,  0.1434,  0.1243,  0.1077],\n",
      "        ...,\n",
      "        [-0.1235,  0.2798, -0.9799,  ...,  0.1434,  0.1243,  0.1077],\n",
      "        [-0.1235,  0.2798, -0.9799,  ...,  0.1434,  0.1243,  0.1077],\n",
      "        [-0.1235,  0.2798, -0.9799,  ...,  0.1434,  0.1243,  0.1077]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5841, -0.1489, -0.9849,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.5841, -0.1489, -0.9849,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.5841, -0.1489, -0.9849,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        ...,\n",
      "        [-0.5841, -0.1489, -0.9849,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.5841, -0.1489, -0.9849,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.5841, -0.1489, -0.9849,  ...,  0.1433,  0.1242,  0.1076]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9018, -0.5500, -0.8531,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.9018, -0.5500, -0.8531,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.9018, -0.5500, -0.8531,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        ...,\n",
      "        [-0.9018, -0.5500, -0.8531,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.9018, -0.5500, -0.8531,  ...,  0.1433,  0.1242,  0.1076],\n",
      "        [-0.9018, -0.5500, -0.8531,  ...,  0.1433,  0.1242,  0.1076]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9986, -0.8497, -0.6027,  ...,  0.1432,  0.1241,  0.1075],\n",
      "        [-0.9986, -0.8497, -0.6027,  ...,  0.1432,  0.1241,  0.1075],\n",
      "        [-0.9986, -0.8497, -0.6027,  ...,  0.1432,  0.1241,  0.1075],\n",
      "        ...,\n",
      "        [-0.9986, -0.8497, -0.6027,  ...,  0.1432,  0.1241,  0.1075],\n",
      "        [-0.9986, -0.8497, -0.6027,  ...,  0.1432,  0.1241,  0.1075],\n",
      "        [-0.9986, -0.8497, -0.6027,  ...,  0.1432,  0.1241,  0.1075]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8509, -0.9925, -0.2687,  ...,  0.1431,  0.1240,  0.1075],\n",
      "        [-0.8509, -0.9925, -0.2687,  ...,  0.1431,  0.1240,  0.1075],\n",
      "        [-0.8509, -0.9925, -0.2687,  ...,  0.1431,  0.1240,  0.1075],\n",
      "        ...,\n",
      "        [-0.8509, -0.9925, -0.2687,  ...,  0.1431,  0.1240,  0.1075],\n",
      "        [-0.8509, -0.9925, -0.2687,  ...,  0.1431,  0.1240,  0.1075],\n",
      "        [-0.8509, -0.9925, -0.2687,  ...,  0.1431,  0.1240,  0.1075]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4950, -0.9522,  0.1028,  ...,  0.1430,  0.1240,  0.1074],\n",
      "        [-0.4950, -0.9522,  0.1028,  ...,  0.1430,  0.1240,  0.1074],\n",
      "        [-0.4950, -0.9522,  0.1028,  ...,  0.1430,  0.1240,  0.1074],\n",
      "        ...,\n",
      "        [-0.4950, -0.9522,  0.1028,  ...,  0.1430,  0.1240,  0.1074],\n",
      "        [-0.4950, -0.9522,  0.1028,  ...,  0.1430,  0.1240,  0.1074],\n",
      "        [-0.4950, -0.9522,  0.1028,  ...,  0.1430,  0.1240,  0.1074]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0178, -0.7361,  0.4599,  ...,  0.1430,  0.1239,  0.1074],\n",
      "        [-0.0178, -0.7361,  0.4599,  ...,  0.1430,  0.1239,  0.1074],\n",
      "        [-0.0178, -0.7361,  0.4599,  ...,  0.1430,  0.1239,  0.1074],\n",
      "        ...,\n",
      "        [-0.0178, -0.7361,  0.4599,  ...,  0.1430,  0.1239,  0.1074],\n",
      "        [-0.0178, -0.7361,  0.4599,  ...,  0.1430,  0.1239,  0.1074],\n",
      "        [-0.0178, -0.7361,  0.4599,  ...,  0.1430,  0.1239,  0.1074]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4637, -0.3841,  0.7532,  ...,  0.1429,  0.1238,  0.1073],\n",
      "        [ 0.4637, -0.3841,  0.7532,  ...,  0.1429,  0.1238,  0.1073],\n",
      "        [ 0.4637, -0.3841,  0.7532,  ...,  0.1429,  0.1238,  0.1073],\n",
      "        ...,\n",
      "        [ 0.4637, -0.3841,  0.7532,  ...,  0.1429,  0.1238,  0.1073],\n",
      "        [ 0.4637, -0.3841,  0.7532,  ...,  0.1429,  0.1238,  0.1073],\n",
      "        [ 0.4637, -0.3841,  0.7532,  ...,  0.1429,  0.1238,  0.1073]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8317, 0.0387, 0.9418,  ..., 0.1428, 0.1238, 0.1072],\n",
      "        [0.8317, 0.0387, 0.9418,  ..., 0.1428, 0.1238, 0.1072],\n",
      "        [0.8317, 0.0387, 0.9418,  ..., 0.1428, 0.1238, 0.1072],\n",
      "        ...,\n",
      "        [0.8317, 0.0387, 0.9418,  ..., 0.1428, 0.1238, 0.1072],\n",
      "        [0.8317, 0.0387, 0.9418,  ..., 0.1428, 0.1238, 0.1072],\n",
      "        [0.8317, 0.0387, 0.9418,  ..., 0.1428, 0.1238, 0.1072]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9961, 0.4544, 0.9995,  ..., 0.1427, 0.1237, 0.1072],\n",
      "        [0.9961, 0.4544, 0.9995,  ..., 0.1427, 0.1237, 0.1072],\n",
      "        [0.9961, 0.4544, 0.9995,  ..., 0.1427, 0.1237, 0.1072],\n",
      "        ...,\n",
      "        [0.9961, 0.4544, 0.9995,  ..., 0.1427, 0.1237, 0.1072],\n",
      "        [0.9961, 0.4544, 0.9995,  ..., 0.1427, 0.1237, 0.1072],\n",
      "        [0.9961, 0.4544, 0.9995,  ..., 0.1427, 0.1237, 0.1072]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9166, 0.7862, 0.9184,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.9166, 0.7862, 0.9184,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.9166, 0.7862, 0.9184,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        ...,\n",
      "        [0.9166, 0.7862, 0.9184,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.9166, 0.7862, 0.9184,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.9166, 0.7862, 0.9184,  ..., 0.1426, 0.1236, 0.1071]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.6126, 0.9730, 0.7096,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.6126, 0.9730, 0.7096,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.6126, 0.9730, 0.7096,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        ...,\n",
      "        [0.6126, 0.9730, 0.7096,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.6126, 0.9730, 0.7096,  ..., 0.1426, 0.1236, 0.1071],\n",
      "        [0.6126, 0.9730, 0.7096,  ..., 0.1426, 0.1236, 0.1071]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.1587, 0.9801, 0.4023,  ..., 0.1425, 0.1235, 0.1070],\n",
      "        [0.1587, 0.9801, 0.4023,  ..., 0.1425, 0.1235, 0.1070],\n",
      "        [0.1587, 0.9801, 0.4023,  ..., 0.1425, 0.1235, 0.1070],\n",
      "        ...,\n",
      "        [0.1587, 0.9801, 0.4023,  ..., 0.1425, 0.1235, 0.1070],\n",
      "        [0.1587, 0.9801, 0.4023,  ..., 0.1425, 0.1235, 0.1070],\n",
      "        [0.1587, 0.9801, 0.4023,  ..., 0.1425, 0.1235, 0.1070]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3341,  0.8063,  0.0390,  ...,  0.1424,  0.1234,  0.1070],\n",
      "        [-0.3341,  0.8063,  0.0390,  ...,  0.1424,  0.1234,  0.1070],\n",
      "        [-0.3341,  0.8063,  0.0390,  ...,  0.1424,  0.1234,  0.1070],\n",
      "        ...,\n",
      "        [-0.3341,  0.8063,  0.0390,  ...,  0.1424,  0.1234,  0.1070],\n",
      "        [-0.3341,  0.8063,  0.0390,  ...,  0.1424,  0.1234,  0.1070],\n",
      "        [-0.3341,  0.8063,  0.0390,  ...,  0.1424,  0.1234,  0.1070]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7451,  0.4838, -0.3296,  ...,  0.1423,  0.1234,  0.1069],\n",
      "        [-0.7451,  0.4838, -0.3296,  ...,  0.1423,  0.1234,  0.1069],\n",
      "        [-0.7451,  0.4838, -0.3296,  ...,  0.1423,  0.1234,  0.1069],\n",
      "        ...,\n",
      "        [-0.7451,  0.4838, -0.3296,  ...,  0.1423,  0.1234,  0.1069],\n",
      "        [-0.7451,  0.4838, -0.3296,  ...,  0.1423,  0.1234,  0.1069],\n",
      "        [-0.7451,  0.4838, -0.3296,  ...,  0.1423,  0.1234,  0.1069]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9736,  0.0719, -0.6525,  ...,  0.1423,  0.1233,  0.1068],\n",
      "        [-0.9736,  0.0719, -0.6525,  ...,  0.1423,  0.1233,  0.1068],\n",
      "        [-0.9736,  0.0719, -0.6525,  ...,  0.1423,  0.1233,  0.1068],\n",
      "        ...,\n",
      "        [-0.9736,  0.0719, -0.6525,  ...,  0.1423,  0.1233,  0.1068],\n",
      "        [-0.9736,  0.0719, -0.6525,  ...,  0.1423,  0.1233,  0.1068],\n",
      "        [-0.9736,  0.0719, -0.6525,  ...,  0.1423,  0.1233,  0.1068]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9638, -0.3532, -0.8847,  ...,  0.1422,  0.1232,  0.1068],\n",
      "        [-0.9638, -0.3532, -0.8847,  ...,  0.1422,  0.1232,  0.1068],\n",
      "        [-0.9638, -0.3532, -0.8847,  ...,  0.1422,  0.1232,  0.1068],\n",
      "        ...,\n",
      "        [-0.9638, -0.3532, -0.8847,  ...,  0.1422,  0.1232,  0.1068],\n",
      "        [-0.9638, -0.3532, -0.8847,  ...,  0.1422,  0.1232,  0.1068],\n",
      "        [-0.9638, -0.3532, -0.8847,  ...,  0.1422,  0.1232,  0.1068]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7180, -0.7132, -0.9939,  ...,  0.1421,  0.1232,  0.1067],\n",
      "        [-0.7180, -0.7132, -0.9939,  ...,  0.1421,  0.1232,  0.1067],\n",
      "        [-0.7180, -0.7132, -0.9939,  ...,  0.1421,  0.1232,  0.1067],\n",
      "        ...,\n",
      "        [-0.7180, -0.7132, -0.9939,  ...,  0.1421,  0.1232,  0.1067],\n",
      "        [-0.7180, -0.7132, -0.9939,  ...,  0.1421,  0.1232,  0.1067],\n",
      "        [-0.7180, -0.7132, -0.9939,  ...,  0.1421,  0.1232,  0.1067]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2964, -0.9415, -0.9651,  ...,  0.1420,  0.1231,  0.1067],\n",
      "        [-0.2964, -0.9415, -0.9651,  ...,  0.1420,  0.1231,  0.1067],\n",
      "        [-0.2964, -0.9415, -0.9651,  ...,  0.1420,  0.1231,  0.1067],\n",
      "        ...,\n",
      "        [-0.2964, -0.9415, -0.9651,  ...,  0.1420,  0.1231,  0.1067],\n",
      "        [-0.2964, -0.9415, -0.9651,  ...,  0.1420,  0.1231,  0.1067],\n",
      "        [-0.2964, -0.9415, -0.9651,  ...,  0.1420,  0.1231,  0.1067]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1977, -0.9960, -0.8022,  ...,  0.1420,  0.1230,  0.1066],\n",
      "        [ 0.1977, -0.9960, -0.8022,  ...,  0.1420,  0.1230,  0.1066],\n",
      "        [ 0.1977, -0.9960, -0.8022,  ...,  0.1420,  0.1230,  0.1066],\n",
      "        ...,\n",
      "        [ 0.1977, -0.9960, -0.8022,  ...,  0.1420,  0.1230,  0.1066],\n",
      "        [ 0.1977, -0.9960, -0.8022,  ...,  0.1420,  0.1230,  0.1066],\n",
      "        [ 0.1977, -0.9960, -0.8022,  ...,  0.1420,  0.1230,  0.1066]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6435, -0.8668, -0.5278,  ...,  0.1419,  0.1230,  0.1066],\n",
      "        [ 0.6435, -0.8668, -0.5278,  ...,  0.1419,  0.1230,  0.1066],\n",
      "        [ 0.6435, -0.8668, -0.5278,  ...,  0.1419,  0.1230,  0.1066],\n",
      "        ...,\n",
      "        [ 0.6435, -0.8668, -0.5278,  ...,  0.1419,  0.1230,  0.1066],\n",
      "        [ 0.6435, -0.8668, -0.5278,  ...,  0.1419,  0.1230,  0.1066],\n",
      "        [ 0.6435, -0.8668, -0.5278,  ...,  0.1419,  0.1230,  0.1066]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9317, -0.5775, -0.1801,  ...,  0.1418,  0.1229,  0.1065],\n",
      "        [ 0.9317, -0.5775, -0.1801,  ...,  0.1418,  0.1229,  0.1065],\n",
      "        [ 0.9317, -0.5775, -0.1801,  ...,  0.1418,  0.1229,  0.1065],\n",
      "        ...,\n",
      "        [ 0.9317, -0.5775, -0.1801,  ...,  0.1418,  0.1229,  0.1065],\n",
      "        [ 0.9317, -0.5775, -0.1801,  ...,  0.1418,  0.1229,  0.1065],\n",
      "        [ 0.9317, -0.5775, -0.1801,  ...,  0.1418,  0.1229,  0.1065]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9918, -0.1817,  0.1927,  ...,  0.1417,  0.1228,  0.1064],\n",
      "        [ 0.9918, -0.1817,  0.1927,  ...,  0.1417,  0.1228,  0.1064],\n",
      "        [ 0.9918, -0.1817,  0.1927,  ...,  0.1417,  0.1228,  0.1064],\n",
      "        ...,\n",
      "        [ 0.9918, -0.1817,  0.1927,  ...,  0.1417,  0.1228,  0.1064],\n",
      "        [ 0.9918, -0.1817,  0.1927,  ...,  0.1417,  0.1228,  0.1064],\n",
      "        [ 0.9918, -0.1817,  0.1927,  ...,  0.1417,  0.1228,  0.1064]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8091, 0.2477, 0.5387,  ..., 0.1417, 0.1228, 0.1064],\n",
      "        [0.8091, 0.2477, 0.5387,  ..., 0.1417, 0.1228, 0.1064],\n",
      "        [0.8091, 0.2477, 0.5387,  ..., 0.1417, 0.1228, 0.1064],\n",
      "        ...,\n",
      "        [0.8091, 0.2477, 0.5387,  ..., 0.1417, 0.1228, 0.1064],\n",
      "        [0.8091, 0.2477, 0.5387,  ..., 0.1417, 0.1228, 0.1064],\n",
      "        [0.8091, 0.2477, 0.5387,  ..., 0.1417, 0.1228, 0.1064]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.4283, 0.6313, 0.8098,  ..., 0.1416, 0.1227, 0.1063],\n",
      "        [0.4283, 0.6313, 0.8098,  ..., 0.1416, 0.1227, 0.1063],\n",
      "        [0.4283, 0.6313, 0.8098,  ..., 0.1416, 0.1227, 0.1063],\n",
      "        ...,\n",
      "        [0.4283, 0.6313, 0.8098,  ..., 0.1416, 0.1227, 0.1063],\n",
      "        [0.4283, 0.6313, 0.8098,  ..., 0.1416, 0.1227, 0.1063],\n",
      "        [0.4283, 0.6313, 0.8098,  ..., 0.1416, 0.1227, 0.1063]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0574,  0.8985,  0.9684,  ...,  0.1415,  0.1226,  0.1063],\n",
      "        [-0.0574,  0.8985,  0.9684,  ...,  0.1415,  0.1226,  0.1063],\n",
      "        [-0.0574,  0.8985,  0.9684,  ...,  0.1415,  0.1226,  0.1063],\n",
      "        ...,\n",
      "        [-0.0574,  0.8985,  0.9684,  ...,  0.1415,  0.1226,  0.1063],\n",
      "        [-0.0574,  0.8985,  0.9684,  ...,  0.1415,  0.1226,  0.1063],\n",
      "        [-0.0574,  0.8985,  0.9684,  ...,  0.1415,  0.1226,  0.1063]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5290,  0.9998,  0.9925,  ...,  0.1414,  0.1226,  0.1062],\n",
      "        [-0.5290,  0.9998,  0.9925,  ...,  0.1414,  0.1226,  0.1062],\n",
      "        [-0.5290,  0.9998,  0.9925,  ...,  0.1414,  0.1226,  0.1062],\n",
      "        ...,\n",
      "        [-0.5290,  0.9998,  0.9925,  ...,  0.1414,  0.1226,  0.1062],\n",
      "        [-0.5290,  0.9998,  0.9925,  ...,  0.1414,  0.1226,  0.1062],\n",
      "        [-0.5290,  0.9998,  0.9925,  ...,  0.1414,  0.1226,  0.1062]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8711,  0.9165,  0.8786,  ...,  0.1414,  0.1225,  0.1062],\n",
      "        [-0.8711,  0.9165,  0.8786,  ...,  0.1414,  0.1225,  0.1062],\n",
      "        [-0.8711,  0.9165,  0.8786,  ...,  0.1414,  0.1225,  0.1062],\n",
      "        ...,\n",
      "        [-0.8711,  0.9165,  0.8786,  ...,  0.1414,  0.1225,  0.1062],\n",
      "        [-0.8711,  0.9165,  0.8786,  ...,  0.1414,  0.1225,  0.1062],\n",
      "        [-0.8711,  0.9165,  0.8786,  ...,  0.1414,  0.1225,  0.1062]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9999,  0.6642,  0.6427,  ...,  0.1413,  0.1224,  0.1061],\n",
      "        [-0.9999,  0.6642,  0.6427,  ...,  0.1413,  0.1224,  0.1061],\n",
      "        [-0.9999,  0.6642,  0.6427,  ...,  0.1413,  0.1224,  0.1061],\n",
      "        ...,\n",
      "        [-0.9999,  0.6642,  0.6427,  ...,  0.1413,  0.1224,  0.1061],\n",
      "        [-0.9999,  0.6642,  0.6427,  ...,  0.1413,  0.1224,  0.1061],\n",
      "        [-0.9999,  0.6642,  0.6427,  ...,  0.1413,  0.1224,  0.1061]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8839,  0.2892,  0.3175,  ...,  0.1412,  0.1224,  0.1060],\n",
      "        [-0.8839,  0.2892,  0.3175,  ...,  0.1412,  0.1224,  0.1060],\n",
      "        [-0.8839,  0.2892,  0.3175,  ...,  0.1412,  0.1224,  0.1060],\n",
      "        ...,\n",
      "        [-0.8839,  0.2892,  0.3175,  ...,  0.1412,  0.1224,  0.1060],\n",
      "        [-0.8839,  0.2892,  0.3175,  ...,  0.1412,  0.1224,  0.1060],\n",
      "        [-0.8839,  0.2892,  0.3175,  ...,  0.1412,  0.1224,  0.1060]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5515, -0.1391, -0.0519,  ...,  0.1411,  0.1223,  0.1060],\n",
      "        [-0.5515, -0.1391, -0.0519,  ...,  0.1411,  0.1223,  0.1060],\n",
      "        [-0.5515, -0.1391, -0.0519,  ...,  0.1411,  0.1223,  0.1060],\n",
      "        ...,\n",
      "        [-0.5515, -0.1391, -0.0519,  ...,  0.1411,  0.1223,  0.1060],\n",
      "        [-0.5515, -0.1391, -0.0519,  ...,  0.1411,  0.1223,  0.1060],\n",
      "        [-0.5515, -0.1391, -0.0519,  ...,  0.1411,  0.1223,  0.1060]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0840, -0.5418, -0.4140,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [-0.0840, -0.5418, -0.4140,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [-0.0840, -0.5418, -0.4140,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        ...,\n",
      "        [-0.0840, -0.5418, -0.4140,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [-0.0840, -0.5418, -0.4140,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [-0.0840, -0.5418, -0.4140,  ...,  0.1410,  0.1222,  0.1059]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4040, -0.8445, -0.7186,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [ 0.4040, -0.8445, -0.7186,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [ 0.4040, -0.8445, -0.7186,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        ...,\n",
      "        [ 0.4040, -0.8445, -0.7186,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [ 0.4040, -0.8445, -0.7186,  ...,  0.1410,  0.1222,  0.1059],\n",
      "        [ 0.4040, -0.8445, -0.7186,  ...,  0.1410,  0.1222,  0.1059]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7931, -0.9913, -0.9233,  ...,  0.1409,  0.1221,  0.1058],\n",
      "        [ 0.7931, -0.9913, -0.9233,  ...,  0.1409,  0.1221,  0.1058],\n",
      "        [ 0.7931, -0.9913, -0.9233,  ...,  0.1409,  0.1221,  0.1058],\n",
      "        ...,\n",
      "        [ 0.7931, -0.9913, -0.9233,  ...,  0.1409,  0.1221,  0.1058],\n",
      "        [ 0.7931, -0.9913, -0.9233,  ...,  0.1409,  0.1221,  0.1058],\n",
      "        [ 0.7931, -0.9913, -0.9233,  ...,  0.1409,  0.1221,  0.1058]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9880, -0.9551, -0.9998,  ...,  0.1408,  0.1220,  0.1058],\n",
      "        [ 0.9880, -0.9551, -0.9998,  ...,  0.1408,  0.1220,  0.1058],\n",
      "        [ 0.9880, -0.9551, -0.9998,  ...,  0.1408,  0.1220,  0.1058],\n",
      "        ...,\n",
      "        [ 0.9880, -0.9551, -0.9998,  ...,  0.1408,  0.1220,  0.1058],\n",
      "        [ 0.9880, -0.9551, -0.9998,  ...,  0.1408,  0.1220,  0.1058],\n",
      "        [ 0.9880, -0.9551, -0.9998,  ...,  0.1408,  0.1220,  0.1058]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9411, -0.7427, -0.9374,  ...,  0.1407,  0.1220,  0.1057],\n",
      "        [ 0.9411, -0.7427, -0.9374,  ...,  0.1407,  0.1220,  0.1057],\n",
      "        [ 0.9411, -0.7427, -0.9374,  ...,  0.1407,  0.1220,  0.1057],\n",
      "        ...,\n",
      "        [ 0.9411, -0.7427, -0.9374,  ...,  0.1407,  0.1220,  0.1057],\n",
      "        [ 0.9411, -0.7427, -0.9374,  ...,  0.1407,  0.1220,  0.1057],\n",
      "        [ 0.9411, -0.7427, -0.9374,  ...,  0.1407,  0.1220,  0.1057]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6637, -0.3932, -0.7447,  ...,  0.1407,  0.1219,  0.1056],\n",
      "        [ 0.6637, -0.3932, -0.7447,  ...,  0.1407,  0.1219,  0.1056],\n",
      "        [ 0.6637, -0.3932, -0.7447,  ...,  0.1407,  0.1219,  0.1056],\n",
      "        ...,\n",
      "        [ 0.6637, -0.3932, -0.7447,  ...,  0.1407,  0.1219,  0.1056],\n",
      "        [ 0.6637, -0.3932, -0.7447,  ...,  0.1407,  0.1219,  0.1056],\n",
      "        [ 0.6637, -0.3932, -0.7447,  ...,  0.1407,  0.1219,  0.1056]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2238,  0.0289, -0.4485,  ...,  0.1406,  0.1218,  0.1056],\n",
      "        [ 0.2238,  0.0289, -0.4485,  ...,  0.1406,  0.1218,  0.1056],\n",
      "        [ 0.2238,  0.0289, -0.4485,  ...,  0.1406,  0.1218,  0.1056],\n",
      "        ...,\n",
      "        [ 0.2238,  0.0289, -0.4485,  ...,  0.1406,  0.1218,  0.1056],\n",
      "        [ 0.2238,  0.0289, -0.4485,  ...,  0.1406,  0.1218,  0.1056],\n",
      "        [ 0.2238,  0.0289, -0.4485,  ...,  0.1406,  0.1218,  0.1056]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2708,  0.4456, -0.0900,  ...,  0.1405,  0.1218,  0.1055],\n",
      "        [-0.2708,  0.4456, -0.0900,  ...,  0.1405,  0.1218,  0.1055],\n",
      "        [-0.2708,  0.4456, -0.0900,  ...,  0.1405,  0.1218,  0.1055],\n",
      "        ...,\n",
      "        [-0.2708,  0.4456, -0.0900,  ...,  0.1405,  0.1218,  0.1055],\n",
      "        [-0.2708,  0.4456, -0.0900,  ...,  0.1405,  0.1218,  0.1055],\n",
      "        [-0.2708,  0.4456, -0.0900,  ...,  0.1405,  0.1218,  0.1055]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6992,  0.7801,  0.2810,  ...,  0.1404,  0.1217,  0.1055],\n",
      "        [-0.6992,  0.7801,  0.2810,  ...,  0.1404,  0.1217,  0.1055],\n",
      "        [-0.6992,  0.7801,  0.2810,  ...,  0.1404,  0.1217,  0.1055],\n",
      "        ...,\n",
      "        [-0.6992,  0.7801,  0.2810,  ...,  0.1404,  0.1217,  0.1055],\n",
      "        [-0.6992,  0.7801,  0.2810,  ...,  0.1404,  0.1217,  0.1055],\n",
      "        [-0.6992,  0.7801,  0.2810,  ...,  0.1404,  0.1217,  0.1055]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9564,  0.9706,  0.6129,  ...,  0.1404,  0.1216,  0.1054],\n",
      "        [-0.9564,  0.9706,  0.6129,  ...,  0.1404,  0.1216,  0.1054],\n",
      "        [-0.9564,  0.9706,  0.6129,  ...,  0.1404,  0.1216,  0.1054],\n",
      "        ...,\n",
      "        [-0.9564,  0.9706,  0.6129,  ...,  0.1404,  0.1216,  0.1054],\n",
      "        [-0.9564,  0.9706,  0.6129,  ...,  0.1404,  0.1216,  0.1054],\n",
      "        [-0.9564,  0.9706,  0.6129,  ...,  0.1404,  0.1216,  0.1054]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9794,  0.9820,  0.8597,  ...,  0.1403,  0.1216,  0.1054],\n",
      "        [-0.9794,  0.9820,  0.8597,  ...,  0.1403,  0.1216,  0.1054],\n",
      "        [-0.9794,  0.9820,  0.8597,  ...,  0.1403,  0.1216,  0.1054],\n",
      "        ...,\n",
      "        [-0.9794,  0.9820,  0.8597,  ...,  0.1403,  0.1216,  0.1054],\n",
      "        [-0.9794,  0.9820,  0.8597,  ...,  0.1403,  0.1216,  0.1054],\n",
      "        [-0.9794,  0.9820,  0.8597,  ...,  0.1403,  0.1216,  0.1054]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7626,  0.8122,  0.9870,  ...,  0.1402,  0.1215,  0.1053],\n",
      "        [-0.7626,  0.8122,  0.9870,  ...,  0.1402,  0.1215,  0.1053],\n",
      "        [-0.7626,  0.8122,  0.9870,  ...,  0.1402,  0.1215,  0.1053],\n",
      "        ...,\n",
      "        [-0.7626,  0.8122,  0.9870,  ...,  0.1402,  0.1215,  0.1053],\n",
      "        [-0.7626,  0.8122,  0.9870,  ...,  0.1402,  0.1215,  0.1053],\n",
      "        [-0.7626,  0.8122,  0.9870,  ...,  0.1402,  0.1215,  0.1053]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3591,  0.4924,  0.9772,  ...,  0.1401,  0.1214,  0.1052],\n",
      "        [-0.3591,  0.4924,  0.9772,  ...,  0.1401,  0.1214,  0.1052],\n",
      "        [-0.3591,  0.4924,  0.9772,  ...,  0.1401,  0.1214,  0.1052],\n",
      "        ...,\n",
      "        [-0.3591,  0.4924,  0.9772,  ...,  0.1401,  0.1214,  0.1052],\n",
      "        [-0.3591,  0.4924,  0.9772,  ...,  0.1401,  0.1214,  0.1052],\n",
      "        [-0.3591,  0.4924,  0.9772,  ...,  0.1401,  0.1214,  0.1052]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.1323, 0.0818, 0.8316,  ..., 0.1401, 0.1214, 0.1052],\n",
      "        [0.1323, 0.0818, 0.8316,  ..., 0.1401, 0.1214, 0.1052],\n",
      "        [0.1323, 0.0818, 0.8316,  ..., 0.1401, 0.1214, 0.1052],\n",
      "        ...,\n",
      "        [0.1323, 0.0818, 0.8316,  ..., 0.1401, 0.1214, 0.1052],\n",
      "        [0.1323, 0.0818, 0.8316,  ..., 0.1401, 0.1214, 0.1052],\n",
      "        [0.1323, 0.0818, 0.8316,  ..., 0.1401, 0.1214, 0.1052]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5913, -0.3439,  0.5705,  ...,  0.1400,  0.1213,  0.1051],\n",
      "        [ 0.5913, -0.3439,  0.5705,  ...,  0.1400,  0.1213,  0.1051],\n",
      "        [ 0.5913, -0.3439,  0.5705,  ...,  0.1400,  0.1213,  0.1051],\n",
      "        ...,\n",
      "        [ 0.5913, -0.3439,  0.5705,  ...,  0.1400,  0.1213,  0.1051],\n",
      "        [ 0.5913, -0.3439,  0.5705,  ...,  0.1400,  0.1213,  0.1051],\n",
      "        [ 0.5913, -0.3439,  0.5705,  ...,  0.1400,  0.1213,  0.1051]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9055, -0.7062,  0.2301,  ...,  0.1399,  0.1213,  0.1051],\n",
      "        [ 0.9055, -0.7062,  0.2301,  ...,  0.1399,  0.1213,  0.1051],\n",
      "        [ 0.9055, -0.7062,  0.2301,  ...,  0.1399,  0.1213,  0.1051],\n",
      "        ...,\n",
      "        [ 0.9055, -0.7062,  0.2301,  ...,  0.1399,  0.1213,  0.1051],\n",
      "        [ 0.9055, -0.7062,  0.2301,  ...,  0.1399,  0.1213,  0.1051],\n",
      "        [ 0.9055, -0.7062,  0.2301,  ...,  0.1399,  0.1213,  0.1051]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9981, -0.9381, -0.1423,  ...,  0.1398,  0.1212,  0.1050],\n",
      "        [ 0.9981, -0.9381, -0.1423,  ...,  0.1398,  0.1212,  0.1050],\n",
      "        [ 0.9981, -0.9381, -0.1423,  ...,  0.1398,  0.1212,  0.1050],\n",
      "        ...,\n",
      "        [ 0.9981, -0.9381, -0.1423,  ...,  0.1398,  0.1212,  0.1050],\n",
      "        [ 0.9981, -0.9381, -0.1423,  ...,  0.1398,  0.1212,  0.1050],\n",
      "        [ 0.9981, -0.9381, -0.1423,  ...,  0.1398,  0.1212,  0.1050]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8463, -0.9969, -0.4949,  ...,  0.1398,  0.1211,  0.1049],\n",
      "        [ 0.8463, -0.9969, -0.4949,  ...,  0.1398,  0.1211,  0.1049],\n",
      "        [ 0.8463, -0.9969, -0.4949,  ...,  0.1398,  0.1211,  0.1049],\n",
      "        ...,\n",
      "        [ 0.8463, -0.9969, -0.4949,  ...,  0.1398,  0.1211,  0.1049],\n",
      "        [ 0.8463, -0.9969, -0.4949,  ...,  0.1398,  0.1211,  0.1049],\n",
      "        [ 0.8463, -0.9969, -0.4949,  ...,  0.1398,  0.1211,  0.1049]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4872, -0.8717, -0.7787,  ...,  0.1397,  0.1211,  0.1049],\n",
      "        [ 0.4872, -0.8717, -0.7787,  ...,  0.1397,  0.1211,  0.1049],\n",
      "        [ 0.4872, -0.8717, -0.7787,  ...,  0.1397,  0.1211,  0.1049],\n",
      "        ...,\n",
      "        [ 0.4872, -0.8717, -0.7787,  ...,  0.1397,  0.1211,  0.1049],\n",
      "        [ 0.4872, -0.8717, -0.7787,  ...,  0.1397,  0.1211,  0.1049],\n",
      "        [ 0.4872, -0.8717, -0.7787,  ...,  0.1397,  0.1211,  0.1049]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0089, -0.5856, -0.9544,  ...,  0.1396,  0.1210,  0.1048],\n",
      "        [ 0.0089, -0.5856, -0.9544,  ...,  0.1396,  0.1210,  0.1048],\n",
      "        [ 0.0089, -0.5856, -0.9544,  ...,  0.1396,  0.1210,  0.1048],\n",
      "        ...,\n",
      "        [ 0.0089, -0.5856, -0.9544,  ...,  0.1396,  0.1210,  0.1048],\n",
      "        [ 0.0089, -0.5856, -0.9544,  ...,  0.1396,  0.1210,  0.1048],\n",
      "        [ 0.0089, -0.5856, -0.9544,  ...,  0.1396,  0.1210,  0.1048]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4716, -0.1914, -0.9974,  ...,  0.1395,  0.1209,  0.1048],\n",
      "        [-0.4716, -0.1914, -0.9974,  ...,  0.1395,  0.1209,  0.1048],\n",
      "        [-0.4716, -0.1914, -0.9974,  ...,  0.1395,  0.1209,  0.1048],\n",
      "        ...,\n",
      "        [-0.4716, -0.1914, -0.9974,  ...,  0.1395,  0.1209,  0.1048],\n",
      "        [-0.4716, -0.1914, -0.9974,  ...,  0.1395,  0.1209,  0.1048],\n",
      "        [-0.4716, -0.1914, -0.9974,  ...,  0.1395,  0.1209,  0.1048]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8366,  0.2381, -0.9019,  ...,  0.1394,  0.1209,  0.1047],\n",
      "        [-0.8366,  0.2381, -0.9019,  ...,  0.1394,  0.1209,  0.1047],\n",
      "        [-0.8366,  0.2381, -0.9019,  ...,  0.1394,  0.1209,  0.1047],\n",
      "        ...,\n",
      "        [-0.8366,  0.2381, -0.9019,  ...,  0.1394,  0.1209,  0.1047],\n",
      "        [-0.8366,  0.2381, -0.9019,  ...,  0.1394,  0.1209,  0.1047],\n",
      "        [-0.8366,  0.2381, -0.9019,  ...,  0.1394,  0.1209,  0.1047]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9968,  0.6236, -0.6810,  ...,  0.1394,  0.1208,  0.1047],\n",
      "        [-0.9968,  0.6236, -0.6810,  ...,  0.1394,  0.1208,  0.1047],\n",
      "        [-0.9968,  0.6236, -0.6810,  ...,  0.1394,  0.1208,  0.1047],\n",
      "        ...,\n",
      "        [-0.9968,  0.6236, -0.6810,  ...,  0.1394,  0.1208,  0.1047],\n",
      "        [-0.9968,  0.6236, -0.6810,  ...,  0.1394,  0.1208,  0.1047],\n",
      "        [-0.9968,  0.6236, -0.6810,  ...,  0.1394,  0.1208,  0.1047]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9130,  0.8941, -0.3655,  ...,  0.1393,  0.1207,  0.1046],\n",
      "        [-0.9130,  0.8941, -0.3655,  ...,  0.1393,  0.1207,  0.1046],\n",
      "        [-0.9130,  0.8941, -0.3655,  ...,  0.1393,  0.1207,  0.1046],\n",
      "        ...,\n",
      "        [-0.9130,  0.8941, -0.3655,  ...,  0.1393,  0.1207,  0.1046],\n",
      "        [-0.9130,  0.8941, -0.3655,  ...,  0.1393,  0.1207,  0.1046],\n",
      "        [-0.9130,  0.8941, -0.3655,  ...,  0.1393,  0.1207,  0.1046]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-6.0560e-01,  9.9951e-01,  7.5677e-04,  ...,  1.3922e-01,\n",
      "          1.2066e-01,  1.0455e-01],\n",
      "        [-6.0560e-01,  9.9951e-01,  7.5677e-04,  ...,  1.3922e-01,\n",
      "          1.2066e-01,  1.0455e-01],\n",
      "        [-6.0560e-01,  9.9951e-01,  7.5677e-04,  ...,  1.3922e-01,\n",
      "          1.2066e-01,  1.0455e-01],\n",
      "        ...,\n",
      "        [-6.0560e-01,  9.9951e-01,  7.5677e-04,  ...,  1.3922e-01,\n",
      "          1.2066e-01,  1.0455e-01],\n",
      "        [-6.0560e-01,  9.9951e-01,  7.5677e-04,  ...,  1.3922e-01,\n",
      "          1.2066e-01,  1.0455e-01],\n",
      "        [-6.0560e-01,  9.9951e-01,  7.5677e-04,  ...,  1.3922e-01,\n",
      "          1.2066e-01,  1.0455e-01]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1500,  0.9205,  0.3669,  ...,  0.1391,  0.1206,  0.1045],\n",
      "        [-0.1500,  0.9205,  0.3669,  ...,  0.1391,  0.1206,  0.1045],\n",
      "        [-0.1500,  0.9205,  0.3669,  ...,  0.1391,  0.1206,  0.1045],\n",
      "        ...,\n",
      "        [-0.1500,  0.9205,  0.3669,  ...,  0.1391,  0.1206,  0.1045],\n",
      "        [-0.1500,  0.9205,  0.3669,  ...,  0.1391,  0.1206,  0.1045],\n",
      "        [-0.1500,  0.9205,  0.3669,  ...,  0.1391,  0.1206,  0.1045]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.3424, 0.6715, 0.6821,  ..., 0.1391, 0.1205, 0.1044],\n",
      "        [0.3424, 0.6715, 0.6821,  ..., 0.1391, 0.1205, 0.1044],\n",
      "        [0.3424, 0.6715, 0.6821,  ..., 0.1391, 0.1205, 0.1044],\n",
      "        ...,\n",
      "        [0.3424, 0.6715, 0.6821,  ..., 0.1391, 0.1205, 0.1044],\n",
      "        [0.3424, 0.6715, 0.6821,  ..., 0.1391, 0.1205, 0.1044],\n",
      "        [0.3424, 0.6715, 0.6821,  ..., 0.1391, 0.1205, 0.1044]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.7509, 0.2987, 0.9025,  ..., 0.1390, 0.1205, 0.1044],\n",
      "        [0.7509, 0.2987, 0.9025,  ..., 0.1390, 0.1205, 0.1044],\n",
      "        [0.7509, 0.2987, 0.9025,  ..., 0.1390, 0.1205, 0.1044],\n",
      "        ...,\n",
      "        [0.7509, 0.2987, 0.9025,  ..., 0.1390, 0.1205, 0.1044],\n",
      "        [0.7509, 0.2987, 0.9025,  ..., 0.1390, 0.1205, 0.1044],\n",
      "        [0.7509, 0.2987, 0.9025,  ..., 0.1390, 0.1205, 0.1044]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9756, -0.1293,  0.9975,  ...,  0.1389,  0.1204,  0.1043],\n",
      "        [ 0.9756, -0.1293,  0.9975,  ...,  0.1389,  0.1204,  0.1043],\n",
      "        [ 0.9756, -0.1293,  0.9975,  ...,  0.1389,  0.1204,  0.1043],\n",
      "        ...,\n",
      "        [ 0.9756, -0.1293,  0.9975,  ...,  0.1389,  0.1204,  0.1043],\n",
      "        [ 0.9756, -0.1293,  0.9975,  ...,  0.1389,  0.1204,  0.1043],\n",
      "        [ 0.9756, -0.1293,  0.9975,  ...,  0.1389,  0.1204,  0.1043]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9614, -0.5334,  0.9539,  ...,  0.1388,  0.1203,  0.1043],\n",
      "        [ 0.9614, -0.5334,  0.9539,  ...,  0.1388,  0.1203,  0.1043],\n",
      "        [ 0.9614, -0.5334,  0.9539,  ...,  0.1388,  0.1203,  0.1043],\n",
      "        ...,\n",
      "        [ 0.9614, -0.5334,  0.9539,  ...,  0.1388,  0.1203,  0.1043],\n",
      "        [ 0.9614, -0.5334,  0.9539,  ...,  0.1388,  0.1203,  0.1043],\n",
      "        [ 0.9614, -0.5334,  0.9539,  ...,  0.1388,  0.1203,  0.1043]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7118, -0.8391,  0.7778,  ...,  0.1388,  0.1203,  0.1042],\n",
      "        [ 0.7118, -0.8391,  0.7778,  ...,  0.1388,  0.1203,  0.1042],\n",
      "        [ 0.7118, -0.8391,  0.7778,  ...,  0.1388,  0.1203,  0.1042],\n",
      "        ...,\n",
      "        [ 0.7118, -0.8391,  0.7778,  ...,  0.1388,  0.1203,  0.1042],\n",
      "        [ 0.7118, -0.8391,  0.7778,  ...,  0.1388,  0.1203,  0.1042],\n",
      "        [ 0.7118, -0.8391,  0.7778,  ...,  0.1388,  0.1203,  0.1042]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2880, -0.9899,  0.4936,  ...,  0.1387,  0.1202,  0.1041],\n",
      "        [ 0.2880, -0.9899,  0.4936,  ...,  0.1387,  0.1202,  0.1041],\n",
      "        [ 0.2880, -0.9899,  0.4936,  ...,  0.1387,  0.1202,  0.1041],\n",
      "        ...,\n",
      "        [ 0.2880, -0.9899,  0.4936,  ...,  0.1387,  0.1202,  0.1041],\n",
      "        [ 0.2880, -0.9899,  0.4936,  ...,  0.1387,  0.1202,  0.1041],\n",
      "        [ 0.2880, -0.9899,  0.4936,  ...,  0.1387,  0.1202,  0.1041]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2064, -0.9580,  0.1408,  ...,  0.1386,  0.1201,  0.1041],\n",
      "        [-0.2064, -0.9580,  0.1408,  ...,  0.1386,  0.1201,  0.1041],\n",
      "        [-0.2064, -0.9580,  0.1408,  ...,  0.1386,  0.1201,  0.1041],\n",
      "        ...,\n",
      "        [-0.2064, -0.9580,  0.1408,  ...,  0.1386,  0.1201,  0.1041],\n",
      "        [-0.2064, -0.9580,  0.1408,  ...,  0.1386,  0.1201,  0.1041],\n",
      "        [-0.2064, -0.9580,  0.1408,  ...,  0.1386,  0.1201,  0.1041]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6502, -0.7493, -0.2316,  ...,  0.1385,  0.1201,  0.1040],\n",
      "        [-0.6502, -0.7493, -0.2316,  ...,  0.1385,  0.1201,  0.1040],\n",
      "        [-0.6502, -0.7493, -0.2316,  ...,  0.1385,  0.1201,  0.1040],\n",
      "        ...,\n",
      "        [-0.6502, -0.7493, -0.2316,  ...,  0.1385,  0.1201,  0.1040],\n",
      "        [-0.6502, -0.7493, -0.2316,  ...,  0.1385,  0.1201,  0.1040],\n",
      "        [-0.6502, -0.7493, -0.2316,  ...,  0.1385,  0.1201,  0.1040]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9349, -0.4023, -0.5718,  ...,  0.1385,  0.1200,  0.1040],\n",
      "        [-0.9349, -0.4023, -0.5718,  ...,  0.1385,  0.1200,  0.1040],\n",
      "        [-0.9349, -0.4023, -0.5718,  ...,  0.1385,  0.1200,  0.1040],\n",
      "        ...,\n",
      "        [-0.9349, -0.4023, -0.5718,  ...,  0.1385,  0.1200,  0.1040],\n",
      "        [-0.9349, -0.4023, -0.5718,  ...,  0.1385,  0.1200,  0.1040],\n",
      "        [-0.9349, -0.4023, -0.5718,  ...,  0.1385,  0.1200,  0.1040]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9906,  0.0190, -0.8325,  ...,  0.1384,  0.1199,  0.1039],\n",
      "        [-0.9906,  0.0190, -0.8325,  ...,  0.1384,  0.1199,  0.1039],\n",
      "        [-0.9906,  0.0190, -0.8325,  ...,  0.1384,  0.1199,  0.1039],\n",
      "        ...,\n",
      "        [-0.9906,  0.0190, -0.8325,  ...,  0.1384,  0.1199,  0.1039],\n",
      "        [-0.9906,  0.0190, -0.8325,  ...,  0.1384,  0.1199,  0.1039],\n",
      "        [-0.9906,  0.0190, -0.8325,  ...,  0.1384,  0.1199,  0.1039]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8038,  0.4367, -0.9776,  ...,  0.1383,  0.1199,  0.1039],\n",
      "        [-0.8038,  0.4367, -0.9776,  ...,  0.1383,  0.1199,  0.1039],\n",
      "        [-0.8038,  0.4367, -0.9776,  ...,  0.1383,  0.1199,  0.1039],\n",
      "        ...,\n",
      "        [-0.8038,  0.4367, -0.9776,  ...,  0.1383,  0.1199,  0.1039],\n",
      "        [-0.8038,  0.4367, -0.9776,  ...,  0.1383,  0.1199,  0.1039],\n",
      "        [-0.8038,  0.4367, -0.9776,  ...,  0.1383,  0.1199,  0.1039]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4202,  0.7739, -0.9868,  ...,  0.1382,  0.1198,  0.1038],\n",
      "        [-0.4202,  0.7739, -0.9868,  ...,  0.1382,  0.1198,  0.1038],\n",
      "        [-0.4202,  0.7739, -0.9868,  ...,  0.1382,  0.1198,  0.1038],\n",
      "        ...,\n",
      "        [-0.4202,  0.7739, -0.9868,  ...,  0.1382,  0.1198,  0.1038],\n",
      "        [-0.4202,  0.7739, -0.9868,  ...,  0.1382,  0.1198,  0.1038],\n",
      "        [-0.4202,  0.7739, -0.9868,  ...,  0.1382,  0.1198,  0.1038]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0662,  0.9682, -0.8589,  ...,  0.1382,  0.1197,  0.1037],\n",
      "        [ 0.0662,  0.9682, -0.8589,  ...,  0.1382,  0.1197,  0.1037],\n",
      "        [ 0.0662,  0.9682, -0.8589,  ...,  0.1382,  0.1197,  0.1037],\n",
      "        ...,\n",
      "        [ 0.0662,  0.9682, -0.8589,  ...,  0.1382,  0.1197,  0.1037],\n",
      "        [ 0.0662,  0.9682, -0.8589,  ...,  0.1382,  0.1197,  0.1037],\n",
      "        [ 0.0662,  0.9682, -0.8589,  ...,  0.1382,  0.1197,  0.1037]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5365,  0.9838, -0.6117,  ...,  0.1381,  0.1197,  0.1037],\n",
      "        [ 0.5365,  0.9838, -0.6117,  ...,  0.1381,  0.1197,  0.1037],\n",
      "        [ 0.5365,  0.9838, -0.6117,  ...,  0.1381,  0.1197,  0.1037],\n",
      "        ...,\n",
      "        [ 0.5365,  0.9838, -0.6117,  ...,  0.1381,  0.1197,  0.1037],\n",
      "        [ 0.5365,  0.9838, -0.6117,  ...,  0.1381,  0.1197,  0.1037],\n",
      "        [ 0.5365,  0.9838, -0.6117,  ...,  0.1381,  0.1197,  0.1037]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8754,  0.8179, -0.2795,  ...,  0.1380,  0.1196,  0.1036],\n",
      "        [ 0.8754,  0.8179, -0.2795,  ...,  0.1380,  0.1196,  0.1036],\n",
      "        [ 0.8754,  0.8179, -0.2795,  ...,  0.1380,  0.1196,  0.1036],\n",
      "        ...,\n",
      "        [ 0.8754,  0.8179, -0.2795,  ...,  0.1380,  0.1196,  0.1036],\n",
      "        [ 0.8754,  0.8179, -0.2795,  ...,  0.1380,  0.1196,  0.1036],\n",
      "        [ 0.8754,  0.8179, -0.2795,  ...,  0.1380,  0.1196,  0.1036]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[1.0000, 0.5010, 0.0915,  ..., 0.1379, 0.1195, 0.1036],\n",
      "        [1.0000, 0.5010, 0.0915,  ..., 0.1379, 0.1195, 0.1036],\n",
      "        [1.0000, 0.5010, 0.0915,  ..., 0.1379, 0.1195, 0.1036],\n",
      "        ...,\n",
      "        [1.0000, 0.5010, 0.0915,  ..., 0.1379, 0.1195, 0.1036],\n",
      "        [1.0000, 0.5010, 0.0915,  ..., 0.1379, 0.1195, 0.1036],\n",
      "        [1.0000, 0.5010, 0.0915,  ..., 0.1379, 0.1195, 0.1036]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8797, 0.0916, 0.4499,  ..., 0.1378, 0.1195, 0.1035],\n",
      "        [0.8797, 0.0916, 0.4499,  ..., 0.1378, 0.1195, 0.1035],\n",
      "        [0.8797, 0.0916, 0.4499,  ..., 0.1378, 0.1195, 0.1035],\n",
      "        ...,\n",
      "        [0.8797, 0.0916, 0.4499,  ..., 0.1378, 0.1195, 0.1035],\n",
      "        [0.8797, 0.0916, 0.4499,  ..., 0.1378, 0.1195, 0.1035],\n",
      "        [0.8797, 0.0916, 0.4499,  ..., 0.1378, 0.1195, 0.1035]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5441, -0.3347,  0.7457,  ...,  0.1378,  0.1194,  0.1035],\n",
      "        [ 0.5441, -0.3347,  0.7457,  ...,  0.1378,  0.1194,  0.1035],\n",
      "        [ 0.5441, -0.3347,  0.7457,  ...,  0.1378,  0.1194,  0.1035],\n",
      "        ...,\n",
      "        [ 0.5441, -0.3347,  0.7457,  ...,  0.1378,  0.1194,  0.1035],\n",
      "        [ 0.5441, -0.3347,  0.7457,  ...,  0.1378,  0.1194,  0.1035],\n",
      "        [ 0.5441, -0.3347,  0.7457,  ...,  0.1378,  0.1194,  0.1035]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0752, -0.6992,  0.9379,  ...,  0.1377,  0.1193,  0.1034],\n",
      "        [ 0.0752, -0.6992,  0.9379,  ...,  0.1377,  0.1193,  0.1034],\n",
      "        [ 0.0752, -0.6992,  0.9379,  ...,  0.1377,  0.1193,  0.1034],\n",
      "        ...,\n",
      "        [ 0.0752, -0.6992,  0.9379,  ...,  0.1377,  0.1193,  0.1034],\n",
      "        [ 0.0752, -0.6992,  0.9379,  ...,  0.1377,  0.1193,  0.1034],\n",
      "        [ 0.0752, -0.6992,  0.9379,  ...,  0.1377,  0.1193,  0.1034]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4120, -0.9346,  0.9998,  ...,  0.1376,  0.1193,  0.1033],\n",
      "        [-0.4120, -0.9346,  0.9998,  ...,  0.1376,  0.1193,  0.1033],\n",
      "        [-0.4120, -0.9346,  0.9998,  ...,  0.1376,  0.1193,  0.1033],\n",
      "        ...,\n",
      "        [-0.4120, -0.9346,  0.9998,  ...,  0.1376,  0.1193,  0.1033],\n",
      "        [-0.4120, -0.9346,  0.9998,  ...,  0.1376,  0.1193,  0.1033],\n",
      "        [-0.4120, -0.9346,  0.9998,  ...,  0.1376,  0.1193,  0.1033]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7984, -0.9976,  0.9228,  ...,  0.1375,  0.1192,  0.1033],\n",
      "        [-0.7984, -0.9976,  0.9228,  ...,  0.1375,  0.1192,  0.1033],\n",
      "        [-0.7984, -0.9976,  0.9228,  ...,  0.1375,  0.1192,  0.1033],\n",
      "        ...,\n",
      "        [-0.7984, -0.9976,  0.9228,  ...,  0.1375,  0.1192,  0.1033],\n",
      "        [-0.7984, -0.9976,  0.9228,  ...,  0.1375,  0.1192,  0.1033],\n",
      "        [-0.7984, -0.9976,  0.9228,  ...,  0.1375,  0.1192,  0.1033]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9893, -0.8764,  0.7175,  ...,  0.1375,  0.1191,  0.1032],\n",
      "        [-0.9893, -0.8764,  0.7175,  ...,  0.1375,  0.1191,  0.1032],\n",
      "        [-0.9893, -0.8764,  0.7175,  ...,  0.1375,  0.1191,  0.1032],\n",
      "        ...,\n",
      "        [-0.9893, -0.8764,  0.7175,  ...,  0.1375,  0.1191,  0.1032],\n",
      "        [-0.9893, -0.8764,  0.7175,  ...,  0.1375,  0.1191,  0.1032],\n",
      "        [-0.9893, -0.8764,  0.7175,  ...,  0.1375,  0.1191,  0.1032]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9380, -0.5935,  0.4126,  ...,  0.1374,  0.1191,  0.1032],\n",
      "        [-0.9380, -0.5935,  0.4126,  ...,  0.1374,  0.1191,  0.1032],\n",
      "        [-0.9380, -0.5935,  0.4126,  ...,  0.1374,  0.1191,  0.1032],\n",
      "        ...,\n",
      "        [-0.9380, -0.5935,  0.4126,  ...,  0.1374,  0.1191,  0.1032],\n",
      "        [-0.9380, -0.5935,  0.4126,  ...,  0.1374,  0.1191,  0.1032],\n",
      "        [-0.9380, -0.5935,  0.4126,  ...,  0.1374,  0.1191,  0.1032]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6570, -0.2011,  0.0503,  ...,  0.1373,  0.1190,  0.1031],\n",
      "        [-0.6570, -0.2011,  0.0503,  ...,  0.1373,  0.1190,  0.1031],\n",
      "        [-0.6570, -0.2011,  0.0503,  ...,  0.1373,  0.1190,  0.1031],\n",
      "        ...,\n",
      "        [-0.6570, -0.2011,  0.0503,  ...,  0.1373,  0.1190,  0.1031],\n",
      "        [-0.6570, -0.2011,  0.0503,  ...,  0.1373,  0.1190,  0.1031],\n",
      "        [-0.6570, -0.2011,  0.0503,  ...,  0.1373,  0.1190,  0.1031]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2152,  0.2285, -0.3190,  ...,  0.1372,  0.1189,  0.1031],\n",
      "        [-0.2152,  0.2285, -0.3190,  ...,  0.1372,  0.1189,  0.1031],\n",
      "        [-0.2152,  0.2285, -0.3190,  ...,  0.1372,  0.1189,  0.1031],\n",
      "        ...,\n",
      "        [-0.2152,  0.2285, -0.3190,  ...,  0.1372,  0.1189,  0.1031],\n",
      "        [-0.2152,  0.2285, -0.3190,  ...,  0.1372,  0.1189,  0.1031],\n",
      "        [-0.2152,  0.2285, -0.3190,  ...,  0.1372,  0.1189,  0.1031]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2793,  0.6159, -0.6439,  ...,  0.1372,  0.1189,  0.1030],\n",
      "        [ 0.2793,  0.6159, -0.6439,  ...,  0.1372,  0.1189,  0.1030],\n",
      "        [ 0.2793,  0.6159, -0.6439,  ...,  0.1372,  0.1189,  0.1030],\n",
      "        ...,\n",
      "        [ 0.2793,  0.6159, -0.6439,  ...,  0.1372,  0.1189,  0.1030],\n",
      "        [ 0.2793,  0.6159, -0.6439,  ...,  0.1372,  0.1189,  0.1030],\n",
      "        [ 0.2793,  0.6159, -0.6439,  ...,  0.1372,  0.1189,  0.1030]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7055,  0.8896, -0.8794,  ...,  0.1371,  0.1188,  0.1029],\n",
      "        [ 0.7055,  0.8896, -0.8794,  ...,  0.1371,  0.1188,  0.1029],\n",
      "        [ 0.7055,  0.8896, -0.8794,  ...,  0.1371,  0.1188,  0.1029],\n",
      "        ...,\n",
      "        [ 0.7055,  0.8896, -0.8794,  ...,  0.1371,  0.1188,  0.1029],\n",
      "        [ 0.7055,  0.8896, -0.8794,  ...,  0.1371,  0.1188,  0.1029],\n",
      "        [ 0.7055,  0.8896, -0.8794,  ...,  0.1371,  0.1188,  0.1029]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9589,  0.9991, -0.9926,  ...,  0.1370,  0.1187,  0.1029],\n",
      "        [ 0.9589,  0.9991, -0.9926,  ...,  0.1370,  0.1187,  0.1029],\n",
      "        [ 0.9589,  0.9991, -0.9926,  ...,  0.1370,  0.1187,  0.1029],\n",
      "        ...,\n",
      "        [ 0.9589,  0.9991, -0.9926,  ...,  0.1370,  0.1187,  0.1029],\n",
      "        [ 0.9589,  0.9991, -0.9926,  ...,  0.1370,  0.1187,  0.1029],\n",
      "        [ 0.9589,  0.9991, -0.9926,  ...,  0.1370,  0.1187,  0.1029]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9775,  0.9243, -0.9680,  ...,  0.1369,  0.1187,  0.1028],\n",
      "        [ 0.9775,  0.9243, -0.9680,  ...,  0.1369,  0.1187,  0.1028],\n",
      "        [ 0.9775,  0.9243, -0.9680,  ...,  0.1369,  0.1187,  0.1028],\n",
      "        ...,\n",
      "        [ 0.9775,  0.9243, -0.9680,  ...,  0.1369,  0.1187,  0.1028],\n",
      "        [ 0.9775,  0.9243, -0.9680,  ...,  0.1369,  0.1187,  0.1028],\n",
      "        [ 0.9775,  0.9243, -0.9680,  ...,  0.1369,  0.1187,  0.1028]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7569,  0.6788, -0.8089,  ...,  0.1369,  0.1186,  0.1028],\n",
      "        [ 0.7569,  0.6788, -0.8089,  ...,  0.1369,  0.1186,  0.1028],\n",
      "        [ 0.7569,  0.6788, -0.8089,  ...,  0.1369,  0.1186,  0.1028],\n",
      "        ...,\n",
      "        [ 0.7569,  0.6788, -0.8089,  ...,  0.1369,  0.1186,  0.1028],\n",
      "        [ 0.7569,  0.6788, -0.8089,  ...,  0.1369,  0.1186,  0.1028],\n",
      "        [ 0.7569,  0.6788, -0.8089,  ...,  0.1369,  0.1186,  0.1028]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3509,  0.3081, -0.5374,  ...,  0.1368,  0.1185,  0.1027],\n",
      "        [ 0.3509,  0.3081, -0.5374,  ...,  0.1368,  0.1185,  0.1027],\n",
      "        [ 0.3509,  0.3081, -0.5374,  ...,  0.1368,  0.1185,  0.1027],\n",
      "        ...,\n",
      "        [ 0.3509,  0.3081, -0.5374,  ...,  0.1368,  0.1185,  0.1027],\n",
      "        [ 0.3509,  0.3081, -0.5374,  ...,  0.1368,  0.1185,  0.1027],\n",
      "        [ 0.3509,  0.3081, -0.5374,  ...,  0.1368,  0.1185,  0.1027]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1410, -0.1195, -0.1911,  ...,  0.1367,  0.1185,  0.1027],\n",
      "        [-0.1410, -0.1195, -0.1911,  ...,  0.1367,  0.1185,  0.1027],\n",
      "        [-0.1410, -0.1195, -0.1911,  ...,  0.1367,  0.1185,  0.1027],\n",
      "        ...,\n",
      "        [-0.1410, -0.1195, -0.1911,  ...,  0.1367,  0.1185,  0.1027],\n",
      "        [-0.1410, -0.1195, -0.1911,  ...,  0.1367,  0.1185,  0.1027],\n",
      "        [-0.1410, -0.1195, -0.1911,  ...,  0.1367,  0.1185,  0.1027]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5984, -0.5251,  0.1816,  ...,  0.1366,  0.1184,  0.1026],\n",
      "        [-0.5984, -0.5251,  0.1816,  ...,  0.1366,  0.1184,  0.1026],\n",
      "        [-0.5984, -0.5251,  0.1816,  ...,  0.1366,  0.1184,  0.1026],\n",
      "        ...,\n",
      "        [-0.5984, -0.5251,  0.1816,  ...,  0.1366,  0.1184,  0.1026],\n",
      "        [-0.5984, -0.5251,  0.1816,  ...,  0.1366,  0.1184,  0.1026],\n",
      "        [-0.5984, -0.5251,  0.1816,  ...,  0.1366,  0.1184,  0.1026]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9093, -0.8337,  0.5291,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9093, -0.8337,  0.5291,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9093, -0.8337,  0.5291,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        ...,\n",
      "        [-0.9093, -0.8337,  0.5291,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9093, -0.8337,  0.5291,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9093, -0.8337,  0.5291,  ...,  0.1365,  0.1183,  0.1025]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9975, -0.9885,  0.8031,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9975, -0.9885,  0.8031,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9975, -0.9885,  0.8031,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        ...,\n",
      "        [-0.9975, -0.9885,  0.8031,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9975, -0.9885,  0.8031,  ...,  0.1365,  0.1183,  0.1025],\n",
      "        [-0.9975, -0.9885,  0.8031,  ...,  0.1365,  0.1183,  0.1025]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8415, -0.9608,  0.9655,  ...,  0.1364,  0.1182,  0.1024],\n",
      "        [-0.8415, -0.9608,  0.9655,  ...,  0.1364,  0.1182,  0.1024],\n",
      "        [-0.8415, -0.9608,  0.9655,  ...,  0.1364,  0.1182,  0.1024],\n",
      "        ...,\n",
      "        [-0.8415, -0.9608,  0.9655,  ...,  0.1364,  0.1182,  0.1024],\n",
      "        [-0.8415, -0.9608,  0.9655,  ...,  0.1364,  0.1182,  0.1024],\n",
      "        [-0.8415, -0.9608,  0.9655,  ...,  0.1364,  0.1182,  0.1024]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4795, -0.7558,  0.9938,  ...,  0.1363,  0.1181,  0.1024],\n",
      "        [-0.4795, -0.7558,  0.9938,  ...,  0.1363,  0.1181,  0.1024],\n",
      "        [-0.4795, -0.7558,  0.9938,  ...,  0.1363,  0.1181,  0.1024],\n",
      "        ...,\n",
      "        [-0.4795, -0.7558,  0.9938,  ...,  0.1363,  0.1181,  0.1024],\n",
      "        [-0.4795, -0.7558,  0.9938,  ...,  0.1363,  0.1181,  0.1024],\n",
      "        [-0.4795, -0.7558,  0.9938,  ...,  0.1363,  0.1181,  0.1024]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-7.5361e-05, -4.1135e-01,  8.8397e-01,  ...,  1.3624e-01,\n",
      "          1.1807e-01,  1.0231e-01],\n",
      "        [-7.5361e-05, -4.1135e-01,  8.8397e-01,  ...,  1.3624e-01,\n",
      "          1.1807e-01,  1.0231e-01],\n",
      "        [-7.5361e-05, -4.1135e-01,  8.8397e-01,  ...,  1.3624e-01,\n",
      "          1.1807e-01,  1.0231e-01],\n",
      "        ...,\n",
      "        [-7.5361e-05, -4.1135e-01,  8.8397e-01,  ...,  1.3624e-01,\n",
      "          1.1807e-01,  1.0231e-01],\n",
      "        [-7.5361e-05, -4.1135e-01,  8.8397e-01,  ...,  1.3624e-01,\n",
      "          1.1807e-01,  1.0231e-01],\n",
      "        [-7.5361e-05, -4.1135e-01,  8.8397e-01,  ...,  1.3624e-01,\n",
      "          1.1807e-01,  1.0231e-01]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.4794, 0.0091, 0.6513,  ..., 0.1362, 0.1180, 0.1023],\n",
      "        [0.4794, 0.0091, 0.6513,  ..., 0.1362, 0.1180, 0.1023],\n",
      "        [0.4794, 0.0091, 0.6513,  ..., 0.1362, 0.1180, 0.1023],\n",
      "        ...,\n",
      "        [0.4794, 0.0091, 0.6513,  ..., 0.1362, 0.1180, 0.1023],\n",
      "        [0.4794, 0.0091, 0.6513,  ..., 0.1362, 0.1180, 0.1023],\n",
      "        [0.4794, 0.0091, 0.6513,  ..., 0.1362, 0.1180, 0.1023]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8414, 0.4278, 0.3281,  ..., 0.1361, 0.1179, 0.1022],\n",
      "        [0.8414, 0.4278, 0.3281,  ..., 0.1361, 0.1179, 0.1022],\n",
      "        [0.8414, 0.4278, 0.3281,  ..., 0.1361, 0.1179, 0.1022],\n",
      "        ...,\n",
      "        [0.8414, 0.4278, 0.3281,  ..., 0.1361, 0.1179, 0.1022],\n",
      "        [0.8414, 0.4278, 0.3281,  ..., 0.1361, 0.1179, 0.1022],\n",
      "        [0.8414, 0.4278, 0.3281,  ..., 0.1361, 0.1179, 0.1022]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9975,  0.7676, -0.0406,  ...,  0.1360,  0.1179,  0.1021],\n",
      "        [ 0.9975,  0.7676, -0.0406,  ...,  0.1360,  0.1179,  0.1021],\n",
      "        [ 0.9975,  0.7676, -0.0406,  ...,  0.1360,  0.1179,  0.1021],\n",
      "        ...,\n",
      "        [ 0.9975,  0.7676, -0.0406,  ...,  0.1360,  0.1179,  0.1021],\n",
      "        [ 0.9975,  0.7676, -0.0406,  ...,  0.1360,  0.1179,  0.1021],\n",
      "        [ 0.9975,  0.7676, -0.0406,  ...,  0.1360,  0.1179,  0.1021]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9093,  0.9657, -0.4037,  ...,  0.1359,  0.1178,  0.1021],\n",
      "        [ 0.9093,  0.9657, -0.4037,  ...,  0.1359,  0.1178,  0.1021],\n",
      "        [ 0.9093,  0.9657, -0.4037,  ...,  0.1359,  0.1178,  0.1021],\n",
      "        ...,\n",
      "        [ 0.9093,  0.9657, -0.4037,  ...,  0.1359,  0.1178,  0.1021],\n",
      "        [ 0.9093,  0.9657, -0.4037,  ...,  0.1359,  0.1178,  0.1021],\n",
      "        [ 0.9093,  0.9657, -0.4037,  ...,  0.1359,  0.1178,  0.1021]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5985,  0.9856, -0.7107,  ...,  0.1359,  0.1177,  0.1020],\n",
      "        [ 0.5985,  0.9856, -0.7107,  ...,  0.1359,  0.1177,  0.1020],\n",
      "        [ 0.5985,  0.9856, -0.7107,  ...,  0.1359,  0.1177,  0.1020],\n",
      "        ...,\n",
      "        [ 0.5985,  0.9856, -0.7107,  ...,  0.1359,  0.1177,  0.1020],\n",
      "        [ 0.5985,  0.9856, -0.7107,  ...,  0.1359,  0.1177,  0.1020],\n",
      "        [ 0.5985,  0.9856, -0.7107,  ...,  0.1359,  0.1177,  0.1020]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1412,  0.8235, -0.9190,  ...,  0.1358,  0.1177,  0.1020],\n",
      "        [ 0.1412,  0.8235, -0.9190,  ...,  0.1358,  0.1177,  0.1020],\n",
      "        [ 0.1412,  0.8235, -0.9190,  ...,  0.1358,  0.1177,  0.1020],\n",
      "        ...,\n",
      "        [ 0.1412,  0.8235, -0.9190,  ...,  0.1358,  0.1177,  0.1020],\n",
      "        [ 0.1412,  0.8235, -0.9190,  ...,  0.1358,  0.1177,  0.1020],\n",
      "        [ 0.1412,  0.8235, -0.9190,  ...,  0.1358,  0.1177,  0.1020]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3507,  0.5095, -0.9995,  ...,  0.1357,  0.1176,  0.1019],\n",
      "        [-0.3507,  0.5095, -0.9995,  ...,  0.1357,  0.1176,  0.1019],\n",
      "        [-0.3507,  0.5095, -0.9995,  ...,  0.1357,  0.1176,  0.1019],\n",
      "        ...,\n",
      "        [-0.3507,  0.5095, -0.9995,  ...,  0.1357,  0.1176,  0.1019],\n",
      "        [-0.3507,  0.5095, -0.9995,  ...,  0.1357,  0.1176,  0.1019],\n",
      "        [-0.3507,  0.5095, -0.9995,  ...,  0.1357,  0.1176,  0.1019]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7568,  0.1015, -0.9412,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.7568,  0.1015, -0.9412,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.7568,  0.1015, -0.9412,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        ...,\n",
      "        [-0.7568,  0.1015, -0.9412,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.7568,  0.1015, -0.9412,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.7568,  0.1015, -0.9412,  ...,  0.1356,  0.1175,  0.1018]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9775, -0.3253, -0.7521,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.9775, -0.3253, -0.7521,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.9775, -0.3253, -0.7521,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        ...,\n",
      "        [-0.9775, -0.3253, -0.7521,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.9775, -0.3253, -0.7521,  ...,  0.1356,  0.1175,  0.1018],\n",
      "        [-0.9775, -0.3253, -0.7521,  ...,  0.1356,  0.1175,  0.1018]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9589, -0.6920, -0.4585,  ...,  0.1355,  0.1174,  0.1017],\n",
      "        [-0.9589, -0.6920, -0.4585,  ...,  0.1355,  0.1174,  0.1017],\n",
      "        [-0.9589, -0.6920, -0.4585,  ...,  0.1355,  0.1174,  0.1017],\n",
      "        ...,\n",
      "        [-0.9589, -0.6920, -0.4585,  ...,  0.1355,  0.1174,  0.1017],\n",
      "        [-0.9589, -0.6920, -0.4585,  ...,  0.1355,  0.1174,  0.1017],\n",
      "        [-0.9589, -0.6920, -0.4585,  ...,  0.1355,  0.1174,  0.1017]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7056, -0.9311, -0.1012,  ...,  0.1354,  0.1173,  0.1017],\n",
      "        [-0.7056, -0.9311, -0.1012,  ...,  0.1354,  0.1173,  0.1017],\n",
      "        [-0.7056, -0.9311, -0.1012,  ...,  0.1354,  0.1173,  0.1017],\n",
      "        ...,\n",
      "        [-0.7056, -0.9311, -0.1012,  ...,  0.1354,  0.1173,  0.1017],\n",
      "        [-0.7056, -0.9311, -0.1012,  ...,  0.1354,  0.1173,  0.1017],\n",
      "        [-0.7056, -0.9311, -0.1012,  ...,  0.1354,  0.1173,  0.1017]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2795, -0.9982,  0.2701,  ...,  0.1353,  0.1173,  0.1016],\n",
      "        [-0.2795, -0.9982,  0.2701,  ...,  0.1353,  0.1173,  0.1016],\n",
      "        [-0.2795, -0.9982,  0.2701,  ...,  0.1353,  0.1173,  0.1016],\n",
      "        ...,\n",
      "        [-0.2795, -0.9982,  0.2701,  ...,  0.1353,  0.1173,  0.1016],\n",
      "        [-0.2795, -0.9982,  0.2701,  ...,  0.1353,  0.1173,  0.1016],\n",
      "        [-0.2795, -0.9982,  0.2701,  ...,  0.1353,  0.1173,  0.1016]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2150, -0.8812,  0.6040,  ...,  0.1353,  0.1172,  0.1016],\n",
      "        [ 0.2150, -0.8812,  0.6040,  ...,  0.1353,  0.1172,  0.1016],\n",
      "        [ 0.2150, -0.8812,  0.6040,  ...,  0.1353,  0.1172,  0.1016],\n",
      "        ...,\n",
      "        [ 0.2150, -0.8812,  0.6040,  ...,  0.1353,  0.1172,  0.1016],\n",
      "        [ 0.2150, -0.8812,  0.6040,  ...,  0.1353,  0.1172,  0.1016],\n",
      "        [ 0.2150, -0.8812,  0.6040,  ...,  0.1353,  0.1172,  0.1016]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6569, -0.6015,  0.8539,  ...,  0.1352,  0.1171,  0.1015],\n",
      "        [ 0.6569, -0.6015,  0.8539,  ...,  0.1352,  0.1171,  0.1015],\n",
      "        [ 0.6569, -0.6015,  0.8539,  ...,  0.1352,  0.1171,  0.1015],\n",
      "        ...,\n",
      "        [ 0.6569, -0.6015,  0.8539,  ...,  0.1352,  0.1171,  0.1015],\n",
      "        [ 0.6569, -0.6015,  0.8539,  ...,  0.1352,  0.1171,  0.1015],\n",
      "        [ 0.6569, -0.6015,  0.8539,  ...,  0.1352,  0.1171,  0.1015]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9380, -0.2108,  0.9852,  ...,  0.1351,  0.1171,  0.1014],\n",
      "        [ 0.9380, -0.2108,  0.9852,  ...,  0.1351,  0.1171,  0.1014],\n",
      "        [ 0.9380, -0.2108,  0.9852,  ...,  0.1351,  0.1171,  0.1014],\n",
      "        ...,\n",
      "        [ 0.9380, -0.2108,  0.9852,  ...,  0.1351,  0.1171,  0.1014],\n",
      "        [ 0.9380, -0.2108,  0.9852,  ...,  0.1351,  0.1171,  0.1014],\n",
      "        [ 0.9380, -0.2108,  0.9852,  ...,  0.1351,  0.1171,  0.1014]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9894, 0.2188, 0.9796,  ..., 0.1350, 0.1170, 0.1014],\n",
      "        [0.9894, 0.2188, 0.9796,  ..., 0.1350, 0.1170, 0.1014],\n",
      "        [0.9894, 0.2188, 0.9796,  ..., 0.1350, 0.1170, 0.1014],\n",
      "        ...,\n",
      "        [0.9894, 0.2188, 0.9796,  ..., 0.1350, 0.1170, 0.1014],\n",
      "        [0.9894, 0.2188, 0.9796,  ..., 0.1350, 0.1170, 0.1014],\n",
      "        [0.9894, 0.2188, 0.9796,  ..., 0.1350, 0.1170, 0.1014]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.7985, 0.6080, 0.8378,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.7985, 0.6080, 0.8378,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.7985, 0.6080, 0.8378,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        ...,\n",
      "        [0.7985, 0.6080, 0.8378,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.7985, 0.6080, 0.8378,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.7985, 0.6080, 0.8378,  ..., 0.1349, 0.1169, 0.1013]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.4122, 0.8850, 0.5797,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.4122, 0.8850, 0.5797,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.4122, 0.8850, 0.5797,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        ...,\n",
      "        [0.4122, 0.8850, 0.5797,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.4122, 0.8850, 0.5797,  ..., 0.1349, 0.1169, 0.1013],\n",
      "        [0.4122, 0.8850, 0.5797,  ..., 0.1349, 0.1169, 0.1013]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0751,  0.9987,  0.2410,  ...,  0.1348,  0.1168,  0.1012],\n",
      "        [-0.0751,  0.9987,  0.2410,  ...,  0.1348,  0.1168,  0.1012],\n",
      "        [-0.0751,  0.9987,  0.2410,  ...,  0.1348,  0.1168,  0.1012],\n",
      "        ...,\n",
      "        [-0.0751,  0.9987,  0.2410,  ...,  0.1348,  0.1168,  0.1012],\n",
      "        [-0.0751,  0.9987,  0.2410,  ...,  0.1348,  0.1168,  0.1012],\n",
      "        [-0.0751,  0.9987,  0.2410,  ...,  0.1348,  0.1168,  0.1012]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5440,  0.9280, -0.1311,  ...,  0.1347,  0.1167,  0.1012],\n",
      "        [-0.5440,  0.9280, -0.1311,  ...,  0.1347,  0.1167,  0.1012],\n",
      "        [-0.5440,  0.9280, -0.1311,  ...,  0.1347,  0.1167,  0.1012],\n",
      "        ...,\n",
      "        [-0.5440,  0.9280, -0.1311,  ...,  0.1347,  0.1167,  0.1012],\n",
      "        [-0.5440,  0.9280, -0.1311,  ...,  0.1347,  0.1167,  0.1012],\n",
      "        [-0.5440,  0.9280, -0.1311,  ...,  0.1347,  0.1167,  0.1012]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8797,  0.6861, -0.4851,  ...,  0.1346,  0.1167,  0.1011],\n",
      "        [-0.8797,  0.6861, -0.4851,  ...,  0.1346,  0.1167,  0.1011],\n",
      "        [-0.8797,  0.6861, -0.4851,  ...,  0.1346,  0.1167,  0.1011],\n",
      "        ...,\n",
      "        [-0.8797,  0.6861, -0.4851,  ...,  0.1346,  0.1167,  0.1011],\n",
      "        [-0.8797,  0.6861, -0.4851,  ...,  0.1346,  0.1167,  0.1011],\n",
      "        [-0.8797,  0.6861, -0.4851,  ...,  0.1346,  0.1167,  0.1011]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-1.0000,  0.3175, -0.7716,  ...,  0.1346,  0.1166,  0.1010],\n",
      "        [-1.0000,  0.3175, -0.7716,  ...,  0.1346,  0.1166,  0.1010],\n",
      "        [-1.0000,  0.3175, -0.7716,  ...,  0.1346,  0.1166,  0.1010],\n",
      "        ...,\n",
      "        [-1.0000,  0.3175, -0.7716,  ...,  0.1346,  0.1166,  0.1010],\n",
      "        [-1.0000,  0.3175, -0.7716,  ...,  0.1346,  0.1166,  0.1010],\n",
      "        [-1.0000,  0.3175, -0.7716,  ...,  0.1346,  0.1166,  0.1010]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8755, -0.1097, -0.9510,  ...,  0.1345,  0.1166,  0.1010],\n",
      "        [-0.8755, -0.1097, -0.9510,  ...,  0.1345,  0.1166,  0.1010],\n",
      "        [-0.8755, -0.1097, -0.9510,  ...,  0.1345,  0.1166,  0.1010],\n",
      "        ...,\n",
      "        [-0.8755, -0.1097, -0.9510,  ...,  0.1345,  0.1166,  0.1010],\n",
      "        [-0.8755, -0.1097, -0.9510,  ...,  0.1345,  0.1166,  0.1010],\n",
      "        [-0.8755, -0.1097, -0.9510,  ...,  0.1345,  0.1166,  0.1010]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5366, -0.5166, -0.9982,  ...,  0.1344,  0.1165,  0.1009],\n",
      "        [-0.5366, -0.5166, -0.9982,  ...,  0.1344,  0.1165,  0.1009],\n",
      "        [-0.5366, -0.5166, -0.9982,  ...,  0.1344,  0.1165,  0.1009],\n",
      "        ...,\n",
      "        [-0.5366, -0.5166, -0.9982,  ...,  0.1344,  0.1165,  0.1009],\n",
      "        [-0.5366, -0.5166, -0.9982,  ...,  0.1344,  0.1165,  0.1009],\n",
      "        [-0.5366, -0.5166, -0.9982,  ...,  0.1344,  0.1165,  0.1009]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0664, -0.8282, -0.9067,  ...,  0.1343,  0.1164,  0.1009],\n",
      "        [-0.0664, -0.8282, -0.9067,  ...,  0.1343,  0.1164,  0.1009],\n",
      "        [-0.0664, -0.8282, -0.9067,  ...,  0.1343,  0.1164,  0.1009],\n",
      "        ...,\n",
      "        [-0.0664, -0.8282, -0.9067,  ...,  0.1343,  0.1164,  0.1009],\n",
      "        [-0.0664, -0.8282, -0.9067,  ...,  0.1343,  0.1164,  0.1009],\n",
      "        [-0.0664, -0.8282, -0.9067,  ...,  0.1343,  0.1164,  0.1009]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4201, -0.9869, -0.6892,  ...,  0.1343,  0.1164,  0.1008],\n",
      "        [ 0.4201, -0.9869, -0.6892,  ...,  0.1343,  0.1164,  0.1008],\n",
      "        [ 0.4201, -0.9869, -0.6892,  ...,  0.1343,  0.1164,  0.1008],\n",
      "        ...,\n",
      "        [ 0.4201, -0.9869, -0.6892,  ...,  0.1343,  0.1164,  0.1008],\n",
      "        [ 0.4201, -0.9869, -0.6892,  ...,  0.1343,  0.1164,  0.1008],\n",
      "        [ 0.4201, -0.9869, -0.6892,  ...,  0.1343,  0.1164,  0.1008]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8037, -0.9635, -0.3760,  ...,  0.1342,  0.1163,  0.1008],\n",
      "        [ 0.8037, -0.9635, -0.3760,  ...,  0.1342,  0.1163,  0.1008],\n",
      "        [ 0.8037, -0.9635, -0.3760,  ...,  0.1342,  0.1163,  0.1008],\n",
      "        ...,\n",
      "        [ 0.8037, -0.9635, -0.3760,  ...,  0.1342,  0.1163,  0.1008],\n",
      "        [ 0.8037, -0.9635, -0.3760,  ...,  0.1342,  0.1163,  0.1008],\n",
      "        [ 0.8037, -0.9635, -0.3760,  ...,  0.1342,  0.1163,  0.1008]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9906, -0.7622, -0.0105,  ...,  0.1341,  0.1162,  0.1007],\n",
      "        [ 0.9906, -0.7622, -0.0105,  ...,  0.1341,  0.1162,  0.1007],\n",
      "        [ 0.9906, -0.7622, -0.0105,  ...,  0.1341,  0.1162,  0.1007],\n",
      "        ...,\n",
      "        [ 0.9906, -0.7622, -0.0105,  ...,  0.1341,  0.1162,  0.1007],\n",
      "        [ 0.9906, -0.7622, -0.0105,  ...,  0.1341,  0.1162,  0.1007],\n",
      "        [ 0.9906, -0.7622, -0.0105,  ...,  0.1341,  0.1162,  0.1007]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9349, -0.4203,  0.3564,  ...,  0.1340,  0.1162,  0.1006],\n",
      "        [ 0.9349, -0.4203,  0.3564,  ...,  0.1340,  0.1162,  0.1006],\n",
      "        [ 0.9349, -0.4203,  0.3564,  ...,  0.1340,  0.1162,  0.1006],\n",
      "        ...,\n",
      "        [ 0.9349, -0.4203,  0.3564,  ...,  0.1340,  0.1162,  0.1006],\n",
      "        [ 0.9349, -0.4203,  0.3564,  ...,  0.1340,  0.1162,  0.1006],\n",
      "        [ 0.9349, -0.4203,  0.3564,  ...,  0.1340,  0.1162,  0.1006]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6503, -0.0008,  0.6738,  ...,  0.1340,  0.1161,  0.1006],\n",
      "        [ 0.6503, -0.0008,  0.6738,  ...,  0.1340,  0.1161,  0.1006],\n",
      "        [ 0.6503, -0.0008,  0.6738,  ...,  0.1340,  0.1161,  0.1006],\n",
      "        ...,\n",
      "        [ 0.6503, -0.0008,  0.6738,  ...,  0.1340,  0.1161,  0.1006],\n",
      "        [ 0.6503, -0.0008,  0.6738,  ...,  0.1340,  0.1161,  0.1006],\n",
      "        [ 0.6503, -0.0008,  0.6738,  ...,  0.1340,  0.1161,  0.1006]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.2065, 0.4189, 0.8976,  ..., 0.1339, 0.1160, 0.1005],\n",
      "        [0.2065, 0.4189, 0.8976,  ..., 0.1339, 0.1160, 0.1005],\n",
      "        [0.2065, 0.4189, 0.8976,  ..., 0.1339, 0.1160, 0.1005],\n",
      "        ...,\n",
      "        [0.2065, 0.4189, 0.8976,  ..., 0.1339, 0.1160, 0.1005],\n",
      "        [0.2065, 0.4189, 0.8976,  ..., 0.1339, 0.1160, 0.1005],\n",
      "        [0.2065, 0.4189, 0.8976,  ..., 0.1339, 0.1160, 0.1005]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2878,  0.7612,  0.9967,  ...,  0.1338,  0.1160,  0.1005],\n",
      "        [-0.2878,  0.7612,  0.9967,  ...,  0.1338,  0.1160,  0.1005],\n",
      "        [-0.2878,  0.7612,  0.9967,  ...,  0.1338,  0.1160,  0.1005],\n",
      "        ...,\n",
      "        [-0.2878,  0.7612,  0.9967,  ...,  0.1338,  0.1160,  0.1005],\n",
      "        [-0.2878,  0.7612,  0.9967,  ...,  0.1338,  0.1160,  0.1005],\n",
      "        [-0.2878,  0.7612,  0.9967,  ...,  0.1338,  0.1160,  0.1005]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7117,  0.9631,  0.9573,  ...,  0.1337,  0.1159,  0.1004],\n",
      "        [-0.7117,  0.9631,  0.9573,  ...,  0.1337,  0.1159,  0.1004],\n",
      "        [-0.7117,  0.9631,  0.9573,  ...,  0.1337,  0.1159,  0.1004],\n",
      "        ...,\n",
      "        [-0.7117,  0.9631,  0.9573,  ...,  0.1337,  0.1159,  0.1004],\n",
      "        [-0.7117,  0.9631,  0.9573,  ...,  0.1337,  0.1159,  0.1004],\n",
      "        [-0.7117,  0.9631,  0.9573,  ...,  0.1337,  0.1159,  0.1004]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9614,  0.9872,  0.7848,  ...,  0.1336,  0.1158,  0.1004],\n",
      "        [-0.9614,  0.9872,  0.7848,  ...,  0.1336,  0.1158,  0.1004],\n",
      "        [-0.9614,  0.9872,  0.7848,  ...,  0.1336,  0.1158,  0.1004],\n",
      "        ...,\n",
      "        [-0.9614,  0.9872,  0.7848,  ...,  0.1336,  0.1158,  0.1004],\n",
      "        [-0.9614,  0.9872,  0.7848,  ...,  0.1336,  0.1158,  0.1004],\n",
      "        [-0.9614,  0.9872,  0.7848,  ...,  0.1336,  0.1158,  0.1004]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9756,  0.8291,  0.5034,  ...,  0.1336,  0.1158,  0.1003],\n",
      "        [-0.9756,  0.8291,  0.5034,  ...,  0.1336,  0.1158,  0.1003],\n",
      "        [-0.9756,  0.8291,  0.5034,  ...,  0.1336,  0.1158,  0.1003],\n",
      "        ...,\n",
      "        [-0.9756,  0.8291,  0.5034,  ...,  0.1336,  0.1158,  0.1003],\n",
      "        [-0.9756,  0.8291,  0.5034,  ...,  0.1336,  0.1158,  0.1003],\n",
      "        [-0.9756,  0.8291,  0.5034,  ...,  0.1336,  0.1158,  0.1003]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7510,  0.5180,  0.1520,  ...,  0.1335,  0.1157,  0.1002],\n",
      "        [-0.7510,  0.5180,  0.1520,  ...,  0.1335,  0.1157,  0.1002],\n",
      "        [-0.7510,  0.5180,  0.1520,  ...,  0.1335,  0.1157,  0.1002],\n",
      "        ...,\n",
      "        [-0.7510,  0.5180,  0.1520,  ...,  0.1335,  0.1157,  0.1002],\n",
      "        [-0.7510,  0.5180,  0.1520,  ...,  0.1335,  0.1157,  0.1002],\n",
      "        [-0.7510,  0.5180,  0.1520,  ...,  0.1335,  0.1157,  0.1002]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3426,  0.1113, -0.2206,  ...,  0.1334,  0.1156,  0.1002],\n",
      "        [-0.3426,  0.1113, -0.2206,  ...,  0.1334,  0.1156,  0.1002],\n",
      "        [-0.3426,  0.1113, -0.2206,  ...,  0.1334,  0.1156,  0.1002],\n",
      "        ...,\n",
      "        [-0.3426,  0.1113, -0.2206,  ...,  0.1334,  0.1156,  0.1002],\n",
      "        [-0.3426,  0.1113, -0.2206,  ...,  0.1334,  0.1156,  0.1002],\n",
      "        [-0.3426,  0.1113, -0.2206,  ...,  0.1334,  0.1156,  0.1002]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1498, -0.3160, -0.5624,  ...,  0.1333,  0.1156,  0.1001],\n",
      "        [ 0.1498, -0.3160, -0.5624,  ...,  0.1333,  0.1156,  0.1001],\n",
      "        [ 0.1498, -0.3160, -0.5624,  ...,  0.1333,  0.1156,  0.1001],\n",
      "        ...,\n",
      "        [ 0.1498, -0.3160, -0.5624,  ...,  0.1333,  0.1156,  0.1001],\n",
      "        [ 0.1498, -0.3160, -0.5624,  ...,  0.1333,  0.1156,  0.1001],\n",
      "        [ 0.1498, -0.3160, -0.5624,  ...,  0.1333,  0.1156,  0.1001]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6055, -0.6849, -0.8262,  ...,  0.1333,  0.1155,  0.1001],\n",
      "        [ 0.6055, -0.6849, -0.8262,  ...,  0.1333,  0.1155,  0.1001],\n",
      "        [ 0.6055, -0.6849, -0.8262,  ...,  0.1333,  0.1155,  0.1001],\n",
      "        ...,\n",
      "        [ 0.6055, -0.6849, -0.8262,  ...,  0.1333,  0.1155,  0.1001],\n",
      "        [ 0.6055, -0.6849, -0.8262,  ...,  0.1333,  0.1155,  0.1001],\n",
      "        [ 0.6055, -0.6849, -0.8262,  ...,  0.1333,  0.1155,  0.1001]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9129, -0.9274, -0.9751,  ...,  0.1332,  0.1154,  0.1000],\n",
      "        [ 0.9129, -0.9274, -0.9751,  ...,  0.1332,  0.1154,  0.1000],\n",
      "        [ 0.9129, -0.9274, -0.9751,  ...,  0.1332,  0.1154,  0.1000],\n",
      "        ...,\n",
      "        [ 0.9129, -0.9274, -0.9751,  ...,  0.1332,  0.1154,  0.1000],\n",
      "        [ 0.9129, -0.9274, -0.9751,  ...,  0.1332,  0.1154,  0.1000],\n",
      "        [ 0.9129, -0.9274, -0.9751,  ...,  0.1332,  0.1154,  0.1000]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9968, -0.9988, -0.9886,  ...,  0.1331,  0.1154,  0.1000],\n",
      "        [ 0.9968, -0.9988, -0.9886,  ...,  0.1331,  0.1154,  0.1000],\n",
      "        [ 0.9968, -0.9988, -0.9886,  ...,  0.1331,  0.1154,  0.1000],\n",
      "        ...,\n",
      "        [ 0.9968, -0.9988, -0.9886,  ...,  0.1331,  0.1154,  0.1000],\n",
      "        [ 0.9968, -0.9988, -0.9886,  ...,  0.1331,  0.1154,  0.1000],\n",
      "        [ 0.9968, -0.9988, -0.9886,  ...,  0.1331,  0.1154,  0.1000]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8367, -0.8858, -0.8646,  ...,  0.1330,  0.1153,  0.0999],\n",
      "        [ 0.8367, -0.8858, -0.8646,  ...,  0.1330,  0.1153,  0.0999],\n",
      "        [ 0.8367, -0.8858, -0.8646,  ...,  0.1330,  0.1153,  0.0999],\n",
      "        ...,\n",
      "        [ 0.8367, -0.8858, -0.8646,  ...,  0.1330,  0.1153,  0.0999],\n",
      "        [ 0.8367, -0.8858, -0.8646,  ...,  0.1330,  0.1153,  0.0999],\n",
      "        [ 0.8367, -0.8858, -0.8646,  ...,  0.1330,  0.1153,  0.0999]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4717, -0.6093, -0.6206,  ...,  0.1330,  0.1152,  0.0998],\n",
      "        [ 0.4717, -0.6093, -0.6206,  ...,  0.1330,  0.1152,  0.0998],\n",
      "        [ 0.4717, -0.6093, -0.6206,  ...,  0.1330,  0.1152,  0.0998],\n",
      "        ...,\n",
      "        [ 0.4717, -0.6093, -0.6206,  ...,  0.1330,  0.1152,  0.0998],\n",
      "        [ 0.4717, -0.6093, -0.6206,  ...,  0.1330,  0.1152,  0.0998],\n",
      "        [ 0.4717, -0.6093, -0.6206,  ...,  0.1330,  0.1152,  0.0998]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0088, -0.2205, -0.2903,  ...,  0.1329,  0.1152,  0.0998],\n",
      "        [-0.0088, -0.2205, -0.2903,  ...,  0.1329,  0.1152,  0.0998],\n",
      "        [-0.0088, -0.2205, -0.2903,  ...,  0.1329,  0.1152,  0.0998],\n",
      "        ...,\n",
      "        [-0.0088, -0.2205, -0.2903,  ...,  0.1329,  0.1152,  0.0998],\n",
      "        [-0.0088, -0.2205, -0.2903,  ...,  0.1329,  0.1152,  0.0998],\n",
      "        [-0.0088, -0.2205, -0.2903,  ...,  0.1329,  0.1152,  0.0998]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4871,  0.2091,  0.0803,  ...,  0.1328,  0.1151,  0.0997],\n",
      "        [-0.4871,  0.2091,  0.0803,  ...,  0.1328,  0.1151,  0.0997],\n",
      "        [-0.4871,  0.2091,  0.0803,  ...,  0.1328,  0.1151,  0.0997],\n",
      "        ...,\n",
      "        [-0.4871,  0.2091,  0.0803,  ...,  0.1328,  0.1151,  0.0997],\n",
      "        [-0.4871,  0.2091,  0.0803,  ...,  0.1328,  0.1151,  0.0997],\n",
      "        [-0.4871,  0.2091,  0.0803,  ...,  0.1328,  0.1151,  0.0997]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8462,  0.6001,  0.4398,  ...,  0.1327,  0.1150,  0.0997],\n",
      "        [-0.8462,  0.6001,  0.4398,  ...,  0.1327,  0.1150,  0.0997],\n",
      "        [-0.8462,  0.6001,  0.4398,  ...,  0.1327,  0.1150,  0.0997],\n",
      "        ...,\n",
      "        [-0.8462,  0.6001,  0.4398,  ...,  0.1327,  0.1150,  0.0997],\n",
      "        [-0.8462,  0.6001,  0.4398,  ...,  0.1327,  0.1150,  0.0997],\n",
      "        [-0.8462,  0.6001,  0.4398,  ...,  0.1327,  0.1150,  0.0997]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9981,  0.8804,  0.7381,  ...,  0.1327,  0.1150,  0.0996],\n",
      "        [-0.9981,  0.8804,  0.7381,  ...,  0.1327,  0.1150,  0.0996],\n",
      "        [-0.9981,  0.8804,  0.7381,  ...,  0.1327,  0.1150,  0.0996],\n",
      "        ...,\n",
      "        [-0.9981,  0.8804,  0.7381,  ...,  0.1327,  0.1150,  0.0996],\n",
      "        [-0.9981,  0.8804,  0.7381,  ...,  0.1327,  0.1150,  0.0996],\n",
      "        [-0.9981,  0.8804,  0.7381,  ...,  0.1327,  0.1150,  0.0996]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9056,  0.9981,  0.9339,  ...,  0.1326,  0.1149,  0.0996],\n",
      "        [-0.9056,  0.9981,  0.9339,  ...,  0.1326,  0.1149,  0.0996],\n",
      "        [-0.9056,  0.9981,  0.9339,  ...,  0.1326,  0.1149,  0.0996],\n",
      "        ...,\n",
      "        [-0.9056,  0.9981,  0.9339,  ...,  0.1326,  0.1149,  0.0996],\n",
      "        [-0.9056,  0.9981,  0.9339,  ...,  0.1326,  0.1149,  0.0996],\n",
      "        [-0.9056,  0.9981,  0.9339,  ...,  0.1326,  0.1149,  0.0996]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5914,  0.9317,  1.0000,  ...,  0.1325,  0.1148,  0.0995],\n",
      "        [-0.5914,  0.9317,  1.0000,  ...,  0.1325,  0.1148,  0.0995],\n",
      "        [-0.5914,  0.9317,  1.0000,  ...,  0.1325,  0.1148,  0.0995],\n",
      "        ...,\n",
      "        [-0.5914,  0.9317,  1.0000,  ...,  0.1325,  0.1148,  0.0995],\n",
      "        [-0.5914,  0.9317,  1.0000,  ...,  0.1325,  0.1148,  0.0995],\n",
      "        [-0.5914,  0.9317,  1.0000,  ...,  0.1325,  0.1148,  0.0995]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1324,  0.6932,  0.9270,  ...,  0.1324,  0.1148,  0.0994],\n",
      "        [-0.1324,  0.6932,  0.9270,  ...,  0.1324,  0.1148,  0.0994],\n",
      "        [-0.1324,  0.6932,  0.9270,  ...,  0.1324,  0.1148,  0.0994],\n",
      "        ...,\n",
      "        [-0.1324,  0.6932,  0.9270,  ...,  0.1324,  0.1148,  0.0994],\n",
      "        [-0.1324,  0.6932,  0.9270,  ...,  0.1324,  0.1148,  0.0994],\n",
      "        [-0.1324,  0.6932,  0.9270,  ...,  0.1324,  0.1148,  0.0994]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.3590, 0.3269, 0.7253,  ..., 0.1324, 0.1147, 0.0994],\n",
      "        [0.3590, 0.3269, 0.7253,  ..., 0.1324, 0.1147, 0.0994],\n",
      "        [0.3590, 0.3269, 0.7253,  ..., 0.1324, 0.1147, 0.0994],\n",
      "        ...,\n",
      "        [0.3590, 0.3269, 0.7253,  ..., 0.1324, 0.1147, 0.0994],\n",
      "        [0.3590, 0.3269, 0.7253,  ..., 0.1324, 0.1147, 0.0994],\n",
      "        [0.3590, 0.3269, 0.7253,  ..., 0.1324, 0.1147, 0.0994]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7625, -0.0998,  0.4228,  ...,  0.1323,  0.1146,  0.0993],\n",
      "        [ 0.7625, -0.0998,  0.4228,  ...,  0.1323,  0.1146,  0.0993],\n",
      "        [ 0.7625, -0.0998,  0.4228,  ...,  0.1323,  0.1146,  0.0993],\n",
      "        ...,\n",
      "        [ 0.7625, -0.0998,  0.4228,  ...,  0.1323,  0.1146,  0.0993],\n",
      "        [ 0.7625, -0.0998,  0.4228,  ...,  0.1323,  0.1146,  0.0993],\n",
      "        [ 0.7625, -0.0998,  0.4228,  ...,  0.1323,  0.1146,  0.0993]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9793, -0.5081,  0.0616,  ...,  0.1322,  0.1146,  0.0993],\n",
      "        [ 0.9793, -0.5081,  0.0616,  ...,  0.1322,  0.1146,  0.0993],\n",
      "        [ 0.9793, -0.5081,  0.0616,  ...,  0.1322,  0.1146,  0.0993],\n",
      "        ...,\n",
      "        [ 0.9793, -0.5081,  0.0616,  ...,  0.1322,  0.1146,  0.0993],\n",
      "        [ 0.9793, -0.5081,  0.0616,  ...,  0.1322,  0.1146,  0.0993],\n",
      "        [ 0.9793, -0.5081,  0.0616,  ...,  0.1322,  0.1146,  0.0993]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9564, -0.8226, -0.3083,  ...,  0.1321,  0.1145,  0.0992],\n",
      "        [ 0.9564, -0.8226, -0.3083,  ...,  0.1321,  0.1145,  0.0992],\n",
      "        [ 0.9564, -0.8226, -0.3083,  ...,  0.1321,  0.1145,  0.0992],\n",
      "        ...,\n",
      "        [ 0.9564, -0.8226, -0.3083,  ...,  0.1321,  0.1145,  0.0992],\n",
      "        [ 0.9564, -0.8226, -0.3083,  ...,  0.1321,  0.1145,  0.0992],\n",
      "        [ 0.9564, -0.8226, -0.3083,  ...,  0.1321,  0.1145,  0.0992]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6993, -0.9853, -0.6352,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.6993, -0.9853, -0.6352,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.6993, -0.9853, -0.6352,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        ...,\n",
      "        [ 0.6993, -0.9853, -0.6352,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.6993, -0.9853, -0.6352,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.6993, -0.9853, -0.6352,  ...,  0.1320,  0.1144,  0.0991]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2710, -0.9661, -0.8739,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.2710, -0.9661, -0.8739,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.2710, -0.9661, -0.8739,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        ...,\n",
      "        [ 0.2710, -0.9661, -0.8739,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.2710, -0.9661, -0.8739,  ...,  0.1320,  0.1144,  0.0991],\n",
      "        [ 0.2710, -0.9661, -0.8739,  ...,  0.1320,  0.1144,  0.0991]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2237, -0.7686, -0.9912,  ...,  0.1319,  0.1143,  0.0990],\n",
      "        [-0.2237, -0.7686, -0.9912,  ...,  0.1319,  0.1143,  0.0990],\n",
      "        [-0.2237, -0.7686, -0.9912,  ...,  0.1319,  0.1143,  0.0990],\n",
      "        ...,\n",
      "        [-0.2237, -0.7686, -0.9912,  ...,  0.1319,  0.1143,  0.0990],\n",
      "        [-0.2237, -0.7686, -0.9912,  ...,  0.1319,  0.1143,  0.0990],\n",
      "        [-0.2237, -0.7686, -0.9912,  ...,  0.1319,  0.1143,  0.0990]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6636, -0.4293, -0.9708,  ...,  0.1318,  0.1142,  0.0990],\n",
      "        [-0.6636, -0.4293, -0.9708,  ...,  0.1318,  0.1142,  0.0990],\n",
      "        [-0.6636, -0.4293, -0.9708,  ...,  0.1318,  0.1142,  0.0990],\n",
      "        ...,\n",
      "        [-0.6636, -0.4293, -0.9708,  ...,  0.1318,  0.1142,  0.0990],\n",
      "        [-0.6636, -0.4293, -0.9708,  ...,  0.1318,  0.1142,  0.0990],\n",
      "        [-0.6636, -0.4293, -0.9708,  ...,  0.1318,  0.1142,  0.0990]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9410, -0.0107, -0.8155,  ...,  0.1317,  0.1142,  0.0989],\n",
      "        [-0.9410, -0.0107, -0.8155,  ...,  0.1317,  0.1142,  0.0989],\n",
      "        [-0.9410, -0.0107, -0.8155,  ...,  0.1317,  0.1142,  0.0989],\n",
      "        ...,\n",
      "        [-0.9410, -0.0107, -0.8155,  ...,  0.1317,  0.1142,  0.0989],\n",
      "        [-0.9410, -0.0107, -0.8155,  ...,  0.1317,  0.1142,  0.0989],\n",
      "        [-0.9410, -0.0107, -0.8155,  ...,  0.1317,  0.1142,  0.0989]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9880,  0.4098, -0.5469,  ...,  0.1317,  0.1141,  0.0989],\n",
      "        [-0.9880,  0.4098, -0.5469,  ...,  0.1317,  0.1141,  0.0989],\n",
      "        [-0.9880,  0.4098, -0.5469,  ...,  0.1317,  0.1141,  0.0989],\n",
      "        ...,\n",
      "        [-0.9880,  0.4098, -0.5469,  ...,  0.1317,  0.1141,  0.0989],\n",
      "        [-0.9880,  0.4098, -0.5469,  ...,  0.1317,  0.1141,  0.0989],\n",
      "        [-0.9880,  0.4098, -0.5469,  ...,  0.1317,  0.1141,  0.0989]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7932,  0.7547, -0.2022,  ...,  0.1316,  0.1140,  0.0988],\n",
      "        [-0.7932,  0.7547, -0.2022,  ...,  0.1316,  0.1140,  0.0988],\n",
      "        [-0.7932,  0.7547, -0.2022,  ...,  0.1316,  0.1140,  0.0988],\n",
      "        ...,\n",
      "        [-0.7932,  0.7547, -0.2022,  ...,  0.1316,  0.1140,  0.0988],\n",
      "        [-0.7932,  0.7547, -0.2022,  ...,  0.1316,  0.1140,  0.0988],\n",
      "        [-0.7932,  0.7547, -0.2022,  ...,  0.1316,  0.1140,  0.0988]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4041,  0.9603,  0.1705,  ...,  0.1315,  0.1140,  0.0987],\n",
      "        [-0.4041,  0.9603,  0.1705,  ...,  0.1315,  0.1140,  0.0987],\n",
      "        [-0.4041,  0.9603,  0.1705,  ...,  0.1315,  0.1140,  0.0987],\n",
      "        ...,\n",
      "        [-0.4041,  0.9603,  0.1705,  ...,  0.1315,  0.1140,  0.0987],\n",
      "        [-0.4041,  0.9603,  0.1705,  ...,  0.1315,  0.1140,  0.0987],\n",
      "        [-0.4041,  0.9603,  0.1705,  ...,  0.1315,  0.1140,  0.0987]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.0839, 0.9887, 0.5195,  ..., 0.1314, 0.1139, 0.0987],\n",
      "        [0.0839, 0.9887, 0.5195,  ..., 0.1314, 0.1139, 0.0987],\n",
      "        [0.0839, 0.9887, 0.5195,  ..., 0.1314, 0.1139, 0.0987],\n",
      "        ...,\n",
      "        [0.0839, 0.9887, 0.5195,  ..., 0.1314, 0.1139, 0.0987],\n",
      "        [0.0839, 0.9887, 0.5195,  ..., 0.1314, 0.1139, 0.0987],\n",
      "        [0.0839, 0.9887, 0.5195,  ..., 0.1314, 0.1139, 0.0987]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.5514, 0.8346, 0.7963,  ..., 0.1314, 0.1138, 0.0986],\n",
      "        [0.5514, 0.8346, 0.7963,  ..., 0.1314, 0.1138, 0.0986],\n",
      "        [0.5514, 0.8346, 0.7963,  ..., 0.1314, 0.1138, 0.0986],\n",
      "        ...,\n",
      "        [0.5514, 0.8346, 0.7963,  ..., 0.1314, 0.1138, 0.0986],\n",
      "        [0.5514, 0.8346, 0.7963,  ..., 0.1314, 0.1138, 0.0986],\n",
      "        [0.5514, 0.8346, 0.7963,  ..., 0.1314, 0.1138, 0.0986]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8838, 0.5264, 0.9625,  ..., 0.1313, 0.1138, 0.0986],\n",
      "        [0.8838, 0.5264, 0.9625,  ..., 0.1313, 0.1138, 0.0986],\n",
      "        [0.8838, 0.5264, 0.9625,  ..., 0.1313, 0.1138, 0.0986],\n",
      "        ...,\n",
      "        [0.8838, 0.5264, 0.9625,  ..., 0.1313, 0.1138, 0.0986],\n",
      "        [0.8838, 0.5264, 0.9625,  ..., 0.1313, 0.1138, 0.0986],\n",
      "        [0.8838, 0.5264, 0.9625,  ..., 0.1313, 0.1138, 0.0986]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9999, 0.1211, 0.9950,  ..., 0.1312, 0.1137, 0.0985],\n",
      "        [0.9999, 0.1211, 0.9950,  ..., 0.1312, 0.1137, 0.0985],\n",
      "        [0.9999, 0.1211, 0.9950,  ..., 0.1312, 0.1137, 0.0985],\n",
      "        ...,\n",
      "        [0.9999, 0.1211, 0.9950,  ..., 0.1312, 0.1137, 0.0985],\n",
      "        [0.9999, 0.1211, 0.9950,  ..., 0.1312, 0.1137, 0.0985],\n",
      "        [0.9999, 0.1211, 0.9950,  ..., 0.1312, 0.1137, 0.0985]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8712, -0.3065,  0.8892,  ...,  0.1311,  0.1136,  0.0985],\n",
      "        [ 0.8712, -0.3065,  0.8892,  ...,  0.1311,  0.1136,  0.0985],\n",
      "        [ 0.8712, -0.3065,  0.8892,  ...,  0.1311,  0.1136,  0.0985],\n",
      "        ...,\n",
      "        [ 0.8712, -0.3065,  0.8892,  ...,  0.1311,  0.1136,  0.0985],\n",
      "        [ 0.8712, -0.3065,  0.8892,  ...,  0.1311,  0.1136,  0.0985],\n",
      "        [ 0.8712, -0.3065,  0.8892,  ...,  0.1311,  0.1136,  0.0985]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5291, -0.6776,  0.6599,  ...,  0.1311,  0.1136,  0.0984],\n",
      "        [ 0.5291, -0.6776,  0.6599,  ...,  0.1311,  0.1136,  0.0984],\n",
      "        [ 0.5291, -0.6776,  0.6599,  ...,  0.1311,  0.1136,  0.0984],\n",
      "        ...,\n",
      "        [ 0.5291, -0.6776,  0.6599,  ...,  0.1311,  0.1136,  0.0984],\n",
      "        [ 0.5291, -0.6776,  0.6599,  ...,  0.1311,  0.1136,  0.0984],\n",
      "        [ 0.5291, -0.6776,  0.6599,  ...,  0.1311,  0.1136,  0.0984]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0576, -0.9237,  0.3388,  ...,  0.1310,  0.1135,  0.0983],\n",
      "        [ 0.0576, -0.9237,  0.3388,  ...,  0.1310,  0.1135,  0.0983],\n",
      "        [ 0.0576, -0.9237,  0.3388,  ...,  0.1310,  0.1135,  0.0983],\n",
      "        ...,\n",
      "        [ 0.0576, -0.9237,  0.3388,  ...,  0.1310,  0.1135,  0.0983],\n",
      "        [ 0.0576, -0.9237,  0.3388,  ...,  0.1310,  0.1135,  0.0983],\n",
      "        [ 0.0576, -0.9237,  0.3388,  ...,  0.1310,  0.1135,  0.0983]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4281, -0.9992, -0.0293,  ...,  0.1309,  0.1134,  0.0983],\n",
      "        [-0.4281, -0.9992, -0.0293,  ...,  0.1309,  0.1134,  0.0983],\n",
      "        [-0.4281, -0.9992, -0.0293,  ...,  0.1309,  0.1134,  0.0983],\n",
      "        ...,\n",
      "        [-0.4281, -0.9992, -0.0293,  ...,  0.1309,  0.1134,  0.0983],\n",
      "        [-0.4281, -0.9992, -0.0293,  ...,  0.1309,  0.1134,  0.0983],\n",
      "        [-0.4281, -0.9992, -0.0293,  ...,  0.1309,  0.1134,  0.0983]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8090, -0.8903, -0.3933,  ...,  0.1308,  0.1134,  0.0982],\n",
      "        [-0.8090, -0.8903, -0.3933,  ...,  0.1308,  0.1134,  0.0982],\n",
      "        [-0.8090, -0.8903, -0.3933,  ...,  0.1308,  0.1134,  0.0982],\n",
      "        ...,\n",
      "        [-0.8090, -0.8903, -0.3933,  ...,  0.1308,  0.1134,  0.0982],\n",
      "        [-0.8090, -0.8903, -0.3933,  ...,  0.1308,  0.1134,  0.0982],\n",
      "        [-0.8090, -0.8903, -0.3933,  ...,  0.1308,  0.1134,  0.0982]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9918, -0.6171, -0.7027,  ...,  0.1307,  0.1133,  0.0982],\n",
      "        [-0.9918, -0.6171, -0.7027,  ...,  0.1307,  0.1133,  0.0982],\n",
      "        [-0.9918, -0.6171, -0.7027,  ...,  0.1307,  0.1133,  0.0982],\n",
      "        ...,\n",
      "        [-0.9918, -0.6171, -0.7027,  ...,  0.1307,  0.1133,  0.0982],\n",
      "        [-0.9918, -0.6171, -0.7027,  ...,  0.1307,  0.1133,  0.0982],\n",
      "        [-0.9918, -0.6171, -0.7027,  ...,  0.1307,  0.1133,  0.0982]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9317, -0.2301, -0.9144,  ...,  0.1307,  0.1132,  0.0981],\n",
      "        [-0.9317, -0.2301, -0.9144,  ...,  0.1307,  0.1132,  0.0981],\n",
      "        [-0.9317, -0.2301, -0.9144,  ...,  0.1307,  0.1132,  0.0981],\n",
      "        ...,\n",
      "        [-0.9317, -0.2301, -0.9144,  ...,  0.1307,  0.1132,  0.0981],\n",
      "        [-0.9317, -0.2301, -0.9144,  ...,  0.1307,  0.1132,  0.0981],\n",
      "        [-0.9317, -0.2301, -0.9144,  ...,  0.1307,  0.1132,  0.0981]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6436,  0.1995, -0.9991,  ...,  0.1306,  0.1132,  0.0981],\n",
      "        [-0.6436,  0.1995, -0.9991,  ...,  0.1306,  0.1132,  0.0981],\n",
      "        [-0.6436,  0.1995, -0.9991,  ...,  0.1306,  0.1132,  0.0981],\n",
      "        ...,\n",
      "        [-0.6436,  0.1995, -0.9991,  ...,  0.1306,  0.1132,  0.0981],\n",
      "        [-0.6436,  0.1995, -0.9991,  ...,  0.1306,  0.1132,  0.0981],\n",
      "        [-0.6436,  0.1995, -0.9991,  ...,  0.1306,  0.1132,  0.0981]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1979,  0.5922, -0.9450,  ...,  0.1305,  0.1131,  0.0980],\n",
      "        [-0.1979,  0.5922, -0.9450,  ...,  0.1305,  0.1131,  0.0980],\n",
      "        [-0.1979,  0.5922, -0.9450,  ...,  0.1305,  0.1131,  0.0980],\n",
      "        ...,\n",
      "        [-0.1979,  0.5922, -0.9450,  ...,  0.1305,  0.1131,  0.0980],\n",
      "        [-0.1979,  0.5922, -0.9450,  ...,  0.1305,  0.1131,  0.0980],\n",
      "        [-0.1979,  0.5922, -0.9450,  ...,  0.1305,  0.1131,  0.0980]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2963,  0.8757, -0.7595,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.2963,  0.8757, -0.7595,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.2963,  0.8757, -0.7595,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        ...,\n",
      "        [ 0.2963,  0.8757, -0.7595,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.2963,  0.8757, -0.7595,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.2963,  0.8757, -0.7595,  ...,  0.1304,  0.1130,  0.0979]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7179,  0.9975, -0.4685,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.7179,  0.9975, -0.4685,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.7179,  0.9975, -0.4685,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        ...,\n",
      "        [ 0.7179,  0.9975, -0.4685,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.7179,  0.9975, -0.4685,  ...,  0.1304,  0.1130,  0.0979],\n",
      "        [ 0.7179,  0.9975, -0.4685,  ...,  0.1304,  0.1130,  0.0979]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9638,  0.9352, -0.1125,  ...,  0.1303,  0.1129,  0.0978],\n",
      "        [ 0.9638,  0.9352, -0.1125,  ...,  0.1303,  0.1129,  0.0978],\n",
      "        [ 0.9638,  0.9352, -0.1125,  ...,  0.1303,  0.1129,  0.0978],\n",
      "        ...,\n",
      "        [ 0.9638,  0.9352, -0.1125,  ...,  0.1303,  0.1129,  0.0978],\n",
      "        [ 0.9638,  0.9352, -0.1125,  ...,  0.1303,  0.1129,  0.0978],\n",
      "        [ 0.9638,  0.9352, -0.1125,  ...,  0.1303,  0.1129,  0.0978]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9737, 0.7003, 0.2592,  ..., 0.1302, 0.1128, 0.0978],\n",
      "        [0.9737, 0.7003, 0.2592,  ..., 0.1302, 0.1128, 0.0978],\n",
      "        [0.9737, 0.7003, 0.2592,  ..., 0.1302, 0.1128, 0.0978],\n",
      "        ...,\n",
      "        [0.9737, 0.7003, 0.2592,  ..., 0.1302, 0.1128, 0.0978],\n",
      "        [0.9737, 0.7003, 0.2592,  ..., 0.1302, 0.1128, 0.0978],\n",
      "        [0.9737, 0.7003, 0.2592,  ..., 0.1302, 0.1128, 0.0978]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.7452, 0.3362, 0.5949,  ..., 0.1301, 0.1128, 0.0977],\n",
      "        [0.7452, 0.3362, 0.5949,  ..., 0.1301, 0.1128, 0.0977],\n",
      "        [0.7452, 0.3362, 0.5949,  ..., 0.1301, 0.1128, 0.0977],\n",
      "        ...,\n",
      "        [0.7452, 0.3362, 0.5949,  ..., 0.1301, 0.1128, 0.0977],\n",
      "        [0.7452, 0.3362, 0.5949,  ..., 0.1301, 0.1128, 0.0977],\n",
      "        [0.7452, 0.3362, 0.5949,  ..., 0.1301, 0.1128, 0.0977]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3342, -0.0900,  0.8480,  ...,  0.1301,  0.1127,  0.0977],\n",
      "        [ 0.3342, -0.0900,  0.8480,  ...,  0.1301,  0.1127,  0.0977],\n",
      "        [ 0.3342, -0.0900,  0.8480,  ...,  0.1301,  0.1127,  0.0977],\n",
      "        ...,\n",
      "        [ 0.3342, -0.0900,  0.8480,  ...,  0.1301,  0.1127,  0.0977],\n",
      "        [ 0.3342, -0.0900,  0.8480,  ...,  0.1301,  0.1127,  0.0977],\n",
      "        [ 0.3342, -0.0900,  0.8480,  ...,  0.1301,  0.1127,  0.0977]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1585, -0.4996,  0.9832,  ...,  0.1300,  0.1126,  0.0976],\n",
      "        [-0.1585, -0.4996,  0.9832,  ...,  0.1300,  0.1126,  0.0976],\n",
      "        [-0.1585, -0.4996,  0.9832,  ...,  0.1300,  0.1126,  0.0976],\n",
      "        ...,\n",
      "        [-0.1585, -0.4996,  0.9832,  ...,  0.1300,  0.1126,  0.0976],\n",
      "        [-0.1585, -0.4996,  0.9832,  ...,  0.1300,  0.1126,  0.0976],\n",
      "        [-0.1585, -0.4996,  0.9832,  ...,  0.1300,  0.1126,  0.0976]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6125, -0.8170,  0.9818,  ...,  0.1299,  0.1126,  0.0975],\n",
      "        [-0.6125, -0.8170,  0.9818,  ...,  0.1299,  0.1126,  0.0975],\n",
      "        [-0.6125, -0.8170,  0.9818,  ...,  0.1299,  0.1126,  0.0975],\n",
      "        ...,\n",
      "        [-0.6125, -0.8170,  0.9818,  ...,  0.1299,  0.1126,  0.0975],\n",
      "        [-0.6125, -0.8170,  0.9818,  ...,  0.1299,  0.1126,  0.0975],\n",
      "        [-0.6125, -0.8170,  0.9818,  ...,  0.1299,  0.1126,  0.0975]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9165, -0.9835,  0.8439,  ...,  0.1298,  0.1125,  0.0975],\n",
      "        [-0.9165, -0.9835,  0.8439,  ...,  0.1298,  0.1125,  0.0975],\n",
      "        [-0.9165, -0.9835,  0.8439,  ...,  0.1298,  0.1125,  0.0975],\n",
      "        ...,\n",
      "        [-0.9165, -0.9835,  0.8439,  ...,  0.1298,  0.1125,  0.0975],\n",
      "        [-0.9165, -0.9835,  0.8439,  ...,  0.1298,  0.1125,  0.0975],\n",
      "        [-0.9165, -0.9835,  0.8439,  ...,  0.1298,  0.1125,  0.0975]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9961, -0.9686,  0.5889,  ...,  0.1298,  0.1124,  0.0974],\n",
      "        [-0.9961, -0.9686,  0.5889,  ...,  0.1298,  0.1124,  0.0974],\n",
      "        [-0.9961, -0.9686,  0.5889,  ...,  0.1298,  0.1124,  0.0974],\n",
      "        ...,\n",
      "        [-0.9961, -0.9686,  0.5889,  ...,  0.1298,  0.1124,  0.0974],\n",
      "        [-0.9961, -0.9686,  0.5889,  ...,  0.1298,  0.1124,  0.0974],\n",
      "        [-0.9961, -0.9686,  0.5889,  ...,  0.1298,  0.1124,  0.0974]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8318, -0.7749,  0.2520,  ...,  0.1297,  0.1124,  0.0974],\n",
      "        [-0.8318, -0.7749,  0.2520,  ...,  0.1297,  0.1124,  0.0974],\n",
      "        [-0.8318, -0.7749,  0.2520,  ...,  0.1297,  0.1124,  0.0974],\n",
      "        ...,\n",
      "        [-0.8318, -0.7749,  0.2520,  ...,  0.1297,  0.1124,  0.0974],\n",
      "        [-0.8318, -0.7749,  0.2520,  ...,  0.1297,  0.1124,  0.0974],\n",
      "        [-0.8318, -0.7749,  0.2520,  ...,  0.1297,  0.1124,  0.0974]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4639, -0.4382, -0.1199,  ...,  0.1296,  0.1123,  0.0973],\n",
      "        [-0.4639, -0.4382, -0.1199,  ...,  0.1296,  0.1123,  0.0973],\n",
      "        [-0.4639, -0.4382, -0.1199,  ...,  0.1296,  0.1123,  0.0973],\n",
      "        ...,\n",
      "        [-0.4639, -0.4382, -0.1199,  ...,  0.1296,  0.1123,  0.0973],\n",
      "        [-0.4639, -0.4382, -0.1199,  ...,  0.1296,  0.1123,  0.0973],\n",
      "        [-0.4639, -0.4382, -0.1199,  ...,  0.1296,  0.1123,  0.0973]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0176, -0.0206, -0.4752,  ...,  0.1295,  0.1122,  0.0973],\n",
      "        [ 0.0176, -0.0206, -0.4752,  ...,  0.1295,  0.1122,  0.0973],\n",
      "        [ 0.0176, -0.0206, -0.4752,  ...,  0.1295,  0.1122,  0.0973],\n",
      "        ...,\n",
      "        [ 0.0176, -0.0206, -0.4752,  ...,  0.1295,  0.1122,  0.0973],\n",
      "        [ 0.0176, -0.0206, -0.4752,  ...,  0.1295,  0.1122,  0.0973],\n",
      "        [ 0.0176, -0.0206, -0.4752,  ...,  0.1295,  0.1122,  0.0973]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4948,  0.4008, -0.7644,  ...,  0.1295,  0.1122,  0.0972],\n",
      "        [ 0.4948,  0.4008, -0.7644,  ...,  0.1295,  0.1122,  0.0972],\n",
      "        [ 0.4948,  0.4008, -0.7644,  ...,  0.1295,  0.1122,  0.0972],\n",
      "        ...,\n",
      "        [ 0.4948,  0.4008, -0.7644,  ...,  0.1295,  0.1122,  0.0972],\n",
      "        [ 0.4948,  0.4008, -0.7644,  ...,  0.1295,  0.1122,  0.0972],\n",
      "        [ 0.4948,  0.4008, -0.7644,  ...,  0.1295,  0.1122,  0.0972]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8509,  0.7482, -0.9474,  ...,  0.1294,  0.1121,  0.0971],\n",
      "        [ 0.8509,  0.7482, -0.9474,  ...,  0.1294,  0.1121,  0.0971],\n",
      "        [ 0.8509,  0.7482, -0.9474,  ...,  0.1294,  0.1121,  0.0971],\n",
      "        ...,\n",
      "        [ 0.8509,  0.7482, -0.9474,  ...,  0.1294,  0.1121,  0.0971],\n",
      "        [ 0.8509,  0.7482, -0.9474,  ...,  0.1294,  0.1121,  0.0971],\n",
      "        [ 0.8509,  0.7482, -0.9474,  ...,  0.1294,  0.1121,  0.0971]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9986,  0.9576, -0.9988,  ...,  0.1293,  0.1120,  0.0971],\n",
      "        [ 0.9986,  0.9576, -0.9988,  ...,  0.1293,  0.1120,  0.0971],\n",
      "        [ 0.9986,  0.9576, -0.9988,  ...,  0.1293,  0.1120,  0.0971],\n",
      "        ...,\n",
      "        [ 0.9986,  0.9576, -0.9988,  ...,  0.1293,  0.1120,  0.0971],\n",
      "        [ 0.9986,  0.9576, -0.9988,  ...,  0.1293,  0.1120,  0.0971],\n",
      "        [ 0.9986,  0.9576, -0.9988,  ...,  0.1293,  0.1120,  0.0971]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9018,  0.9901, -0.9114,  ...,  0.1292,  0.1120,  0.0970],\n",
      "        [ 0.9018,  0.9901, -0.9114,  ...,  0.1292,  0.1120,  0.0970],\n",
      "        [ 0.9018,  0.9901, -0.9114,  ...,  0.1292,  0.1120,  0.0970],\n",
      "        ...,\n",
      "        [ 0.9018,  0.9901, -0.9114,  ...,  0.1292,  0.1120,  0.0970],\n",
      "        [ 0.9018,  0.9901, -0.9114,  ...,  0.1292,  0.1120,  0.0970],\n",
      "        [ 0.9018,  0.9901, -0.9114,  ...,  0.1292,  0.1120,  0.0970]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5843,  0.8400, -0.6973,  ...,  0.1291,  0.1119,  0.0970],\n",
      "        [ 0.5843,  0.8400, -0.6973,  ...,  0.1291,  0.1119,  0.0970],\n",
      "        [ 0.5843,  0.8400, -0.6973,  ...,  0.1291,  0.1119,  0.0970],\n",
      "        ...,\n",
      "        [ 0.5843,  0.8400, -0.6973,  ...,  0.1291,  0.1119,  0.0970],\n",
      "        [ 0.5843,  0.8400, -0.6973,  ...,  0.1291,  0.1119,  0.0970],\n",
      "        [ 0.5843,  0.8400, -0.6973,  ...,  0.1291,  0.1119,  0.0970]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1236,  0.5348, -0.3864,  ...,  0.1291,  0.1118,  0.0969],\n",
      "        [ 0.1236,  0.5348, -0.3864,  ...,  0.1291,  0.1118,  0.0969],\n",
      "        [ 0.1236,  0.5348, -0.3864,  ...,  0.1291,  0.1118,  0.0969],\n",
      "        ...,\n",
      "        [ 0.1236,  0.5348, -0.3864,  ...,  0.1291,  0.1118,  0.0969],\n",
      "        [ 0.1236,  0.5348, -0.3864,  ...,  0.1291,  0.1118,  0.0969],\n",
      "        [ 0.1236,  0.5348, -0.3864,  ...,  0.1291,  0.1118,  0.0969]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3672,  0.1310, -0.0218,  ...,  0.1290,  0.1118,  0.0968],\n",
      "        [-0.3672,  0.1310, -0.0218,  ...,  0.1290,  0.1118,  0.0968],\n",
      "        [-0.3672,  0.1310, -0.0218,  ...,  0.1290,  0.1118,  0.0968],\n",
      "        ...,\n",
      "        [-0.3672,  0.1310, -0.0218,  ...,  0.1290,  0.1118,  0.0968],\n",
      "        [-0.3672,  0.1310, -0.0218,  ...,  0.1290,  0.1118,  0.0968],\n",
      "        [-0.3672,  0.1310, -0.0218,  ...,  0.1290,  0.1118,  0.0968]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7682, -0.2971,  0.3458,  ...,  0.1289,  0.1117,  0.0968],\n",
      "        [-0.7682, -0.2971,  0.3458,  ...,  0.1289,  0.1117,  0.0968],\n",
      "        [-0.7682, -0.2971,  0.3458,  ...,  0.1289,  0.1117,  0.0968],\n",
      "        ...,\n",
      "        [-0.7682, -0.2971,  0.3458,  ...,  0.1289,  0.1117,  0.0968],\n",
      "        [-0.7682, -0.2971,  0.3458,  ...,  0.1289,  0.1117,  0.0968],\n",
      "        [-0.7682, -0.2971,  0.3458,  ...,  0.1289,  0.1117,  0.0968]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9811, -0.6703,  0.6654,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9811, -0.6703,  0.6654,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9811, -0.6703,  0.6654,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        ...,\n",
      "        [-0.9811, -0.6703,  0.6654,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9811, -0.6703,  0.6654,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9811, -0.6703,  0.6654,  ...,  0.1288,  0.1116,  0.0967]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9538, -0.9198,  0.8926,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9538, -0.9198,  0.8926,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9538, -0.9198,  0.8926,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        ...,\n",
      "        [-0.9538, -0.9198,  0.8926,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9538, -0.9198,  0.8926,  ...,  0.1288,  0.1116,  0.0967],\n",
      "        [-0.9538, -0.9198,  0.8926,  ...,  0.1288,  0.1116,  0.0967]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6929, -0.9996,  0.9957,  ...,  0.1287,  0.1115,  0.0966],\n",
      "        [-0.6929, -0.9996,  0.9957,  ...,  0.1287,  0.1115,  0.0966],\n",
      "        [-0.6929, -0.9996,  0.9957,  ...,  0.1287,  0.1115,  0.0966],\n",
      "        ...,\n",
      "        [-0.6929, -0.9996,  0.9957,  ...,  0.1287,  0.1115,  0.0966],\n",
      "        [-0.6929, -0.9996,  0.9957,  ...,  0.1287,  0.1115,  0.0966],\n",
      "        [-0.6929, -0.9996,  0.9957,  ...,  0.1287,  0.1115,  0.0966]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2624, -0.8948,  0.9605,  ...,  0.1286,  0.1115,  0.0966],\n",
      "        [-0.2624, -0.8948,  0.9605,  ...,  0.1286,  0.1115,  0.0966],\n",
      "        [-0.2624, -0.8948,  0.9605,  ...,  0.1286,  0.1115,  0.0966],\n",
      "        ...,\n",
      "        [-0.2624, -0.8948,  0.9605,  ...,  0.1286,  0.1115,  0.0966],\n",
      "        [-0.2624, -0.8948,  0.9605,  ...,  0.1286,  0.1115,  0.0966],\n",
      "        [-0.2624, -0.8948,  0.9605,  ...,  0.1286,  0.1115,  0.0966]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2323, -0.6249,  0.7918,  ...,  0.1285,  0.1114,  0.0965],\n",
      "        [ 0.2323, -0.6249,  0.7918,  ...,  0.1285,  0.1114,  0.0965],\n",
      "        [ 0.2323, -0.6249,  0.7918,  ...,  0.1285,  0.1114,  0.0965],\n",
      "        ...,\n",
      "        [ 0.2323, -0.6249,  0.7918,  ...,  0.1285,  0.1114,  0.0965],\n",
      "        [ 0.2323, -0.6249,  0.7918,  ...,  0.1285,  0.1114,  0.0965],\n",
      "        [ 0.2323, -0.6249,  0.7918,  ...,  0.1285,  0.1114,  0.0965]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6702, -0.2397,  0.5131,  ...,  0.1285,  0.1113,  0.0964],\n",
      "        [ 0.6702, -0.2397,  0.5131,  ...,  0.1285,  0.1113,  0.0964],\n",
      "        [ 0.6702, -0.2397,  0.5131,  ...,  0.1285,  0.1113,  0.0964],\n",
      "        ...,\n",
      "        [ 0.6702, -0.2397,  0.5131,  ...,  0.1285,  0.1113,  0.0964],\n",
      "        [ 0.6702, -0.2397,  0.5131,  ...,  0.1285,  0.1113,  0.0964],\n",
      "        [ 0.6702, -0.2397,  0.5131,  ...,  0.1285,  0.1113,  0.0964]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9440, 0.1898, 0.1631,  ..., 0.1284, 0.1113, 0.0964],\n",
      "        [0.9440, 0.1898, 0.1631,  ..., 0.1284, 0.1113, 0.0964],\n",
      "        [0.9440, 0.1898, 0.1631,  ..., 0.1284, 0.1113, 0.0964],\n",
      "        ...,\n",
      "        [0.9440, 0.1898, 0.1631,  ..., 0.1284, 0.1113, 0.0964],\n",
      "        [0.9440, 0.1898, 0.1631,  ..., 0.1284, 0.1113, 0.0964],\n",
      "        [0.9440, 0.1898, 0.1631,  ..., 0.1284, 0.1113, 0.0964]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9866,  0.5842, -0.2095,  ...,  0.1283,  0.1112,  0.0963],\n",
      "        [ 0.9866,  0.5842, -0.2095,  ...,  0.1283,  0.1112,  0.0963],\n",
      "        [ 0.9866,  0.5842, -0.2095,  ...,  0.1283,  0.1112,  0.0963],\n",
      "        ...,\n",
      "        [ 0.9866,  0.5842, -0.2095,  ...,  0.1283,  0.1112,  0.0963],\n",
      "        [ 0.9866,  0.5842, -0.2095,  ...,  0.1283,  0.1112,  0.0963],\n",
      "        [ 0.9866,  0.5842, -0.2095,  ...,  0.1283,  0.1112,  0.0963]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7878,  0.8708, -0.5531,  ...,  0.1282,  0.1111,  0.0963],\n",
      "        [ 0.7878,  0.8708, -0.5531,  ...,  0.1282,  0.1111,  0.0963],\n",
      "        [ 0.7878,  0.8708, -0.5531,  ...,  0.1282,  0.1111,  0.0963],\n",
      "        ...,\n",
      "        [ 0.7878,  0.8708, -0.5531,  ...,  0.1282,  0.1111,  0.0963],\n",
      "        [ 0.7878,  0.8708, -0.5531,  ...,  0.1282,  0.1111,  0.0963],\n",
      "        [ 0.7878,  0.8708, -0.5531,  ...,  0.1282,  0.1111,  0.0963]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3960,  0.9967, -0.8198,  ...,  0.1282,  0.1111,  0.0962],\n",
      "        [ 0.3960,  0.9967, -0.8198,  ...,  0.1282,  0.1111,  0.0962],\n",
      "        [ 0.3960,  0.9967, -0.8198,  ...,  0.1282,  0.1111,  0.0962],\n",
      "        ...,\n",
      "        [ 0.3960,  0.9967, -0.8198,  ...,  0.1282,  0.1111,  0.0962],\n",
      "        [ 0.3960,  0.9967, -0.8198,  ...,  0.1282,  0.1111,  0.0962],\n",
      "        [ 0.3960,  0.9967, -0.8198,  ...,  0.1282,  0.1111,  0.0962]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0927,  0.9387, -0.9726,  ...,  0.1281,  0.1110,  0.0962],\n",
      "        [-0.0927,  0.9387, -0.9726,  ...,  0.1281,  0.1110,  0.0962],\n",
      "        [-0.0927,  0.9387, -0.9726,  ...,  0.1281,  0.1110,  0.0962],\n",
      "        ...,\n",
      "        [-0.0927,  0.9387, -0.9726,  ...,  0.1281,  0.1110,  0.0962],\n",
      "        [-0.0927,  0.9387, -0.9726,  ...,  0.1281,  0.1110,  0.0962],\n",
      "        [-0.0927,  0.9387, -0.9726,  ...,  0.1281,  0.1110,  0.0962]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5587,  0.7073, -0.9902,  ...,  0.1280,  0.1109,  0.0961],\n",
      "        [-0.5587,  0.7073, -0.9902,  ...,  0.1280,  0.1109,  0.0961],\n",
      "        [-0.5587,  0.7073, -0.9902,  ...,  0.1280,  0.1109,  0.0961],\n",
      "        ...,\n",
      "        [-0.5587,  0.7073, -0.9902,  ...,  0.1280,  0.1109,  0.0961],\n",
      "        [-0.5587,  0.7073, -0.9902,  ...,  0.1280,  0.1109,  0.0961],\n",
      "        [-0.5587,  0.7073, -0.9902,  ...,  0.1280,  0.1109,  0.0961]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8879,  0.3455, -0.8703,  ...,  0.1279,  0.1109,  0.0960],\n",
      "        [-0.8879,  0.3455, -0.8703,  ...,  0.1279,  0.1109,  0.0960],\n",
      "        [-0.8879,  0.3455, -0.8703,  ...,  0.1279,  0.1109,  0.0960],\n",
      "        ...,\n",
      "        [-0.8879,  0.3455, -0.8703,  ...,  0.1279,  0.1109,  0.0960],\n",
      "        [-0.8879,  0.3455, -0.8703,  ...,  0.1279,  0.1109,  0.0960],\n",
      "        [-0.8879,  0.3455, -0.8703,  ...,  0.1279,  0.1109,  0.0960]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9998, -0.0801, -0.6294,  ...,  0.1278,  0.1108,  0.0960],\n",
      "        [-0.9998, -0.0801, -0.6294,  ...,  0.1278,  0.1108,  0.0960],\n",
      "        [-0.9998, -0.0801, -0.6294,  ...,  0.1278,  0.1108,  0.0960],\n",
      "        ...,\n",
      "        [-0.9998, -0.0801, -0.6294,  ...,  0.1278,  0.1108,  0.0960],\n",
      "        [-0.9998, -0.0801, -0.6294,  ...,  0.1278,  0.1108,  0.0960],\n",
      "        [-0.9998, -0.0801, -0.6294,  ...,  0.1278,  0.1108,  0.0960]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8668, -0.4910, -0.3011,  ...,  0.1278,  0.1107,  0.0959],\n",
      "        [-0.8668, -0.4910, -0.3011,  ...,  0.1278,  0.1107,  0.0959],\n",
      "        [-0.8668, -0.4910, -0.3011,  ...,  0.1278,  0.1107,  0.0959],\n",
      "        ...,\n",
      "        [-0.8668, -0.4910, -0.3011,  ...,  0.1278,  0.1107,  0.0959],\n",
      "        [-0.8668, -0.4910, -0.3011,  ...,  0.1278,  0.1107,  0.0959],\n",
      "        [-0.8668, -0.4910, -0.3011,  ...,  0.1278,  0.1107,  0.0959]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5216, -0.8112,  0.0690,  ...,  0.1277,  0.1107,  0.0959],\n",
      "        [-0.5216, -0.8112,  0.0690,  ...,  0.1277,  0.1107,  0.0959],\n",
      "        [-0.5216, -0.8112,  0.0690,  ...,  0.1277,  0.1107,  0.0959],\n",
      "        ...,\n",
      "        [-0.5216, -0.8112,  0.0690,  ...,  0.1277,  0.1107,  0.0959],\n",
      "        [-0.5216, -0.8112,  0.0690,  ...,  0.1277,  0.1107,  0.0959],\n",
      "        [-0.5216, -0.8112,  0.0690,  ...,  0.1277,  0.1107,  0.0959]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0487, -0.9817,  0.4296,  ...,  0.1276,  0.1106,  0.0958],\n",
      "        [-0.0487, -0.9817,  0.4296,  ...,  0.1276,  0.1106,  0.0958],\n",
      "        [-0.0487, -0.9817,  0.4296,  ...,  0.1276,  0.1106,  0.0958],\n",
      "        ...,\n",
      "        [-0.0487, -0.9817,  0.4296,  ...,  0.1276,  0.1106,  0.0958],\n",
      "        [-0.0487, -0.9817,  0.4296,  ...,  0.1276,  0.1106,  0.0958],\n",
      "        [-0.0487, -0.9817,  0.4296,  ...,  0.1276,  0.1106,  0.0958]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4361, -0.9710,  0.7305,  ...,  0.1275,  0.1105,  0.0958],\n",
      "        [ 0.4361, -0.9710,  0.7305,  ...,  0.1275,  0.1105,  0.0958],\n",
      "        [ 0.4361, -0.9710,  0.7305,  ...,  0.1275,  0.1105,  0.0958],\n",
      "        ...,\n",
      "        [ 0.4361, -0.9710,  0.7305,  ...,  0.1275,  0.1105,  0.0958],\n",
      "        [ 0.4361, -0.9710,  0.7305,  ...,  0.1275,  0.1105,  0.0958],\n",
      "        [ 0.4361, -0.9710,  0.7305,  ...,  0.1275,  0.1105,  0.0958]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8141, -0.7811,  0.9298,  ...,  0.1275,  0.1105,  0.0957],\n",
      "        [ 0.8141, -0.7811,  0.9298,  ...,  0.1275,  0.1105,  0.0957],\n",
      "        [ 0.8141, -0.7811,  0.9298,  ...,  0.1275,  0.1105,  0.0957],\n",
      "        ...,\n",
      "        [ 0.8141, -0.7811,  0.9298,  ...,  0.1275,  0.1105,  0.0957],\n",
      "        [ 0.8141, -0.7811,  0.9298,  ...,  0.1275,  0.1105,  0.0957],\n",
      "        [ 0.8141, -0.7811,  0.9298,  ...,  0.1275,  0.1105,  0.0957]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9929, -0.4470,  1.0000,  ...,  0.1274,  0.1104,  0.0956],\n",
      "        [ 0.9929, -0.4470,  1.0000,  ...,  0.1274,  0.1104,  0.0956],\n",
      "        [ 0.9929, -0.4470,  1.0000,  ...,  0.1274,  0.1104,  0.0956],\n",
      "        ...,\n",
      "        [ 0.9929, -0.4470,  1.0000,  ...,  0.1274,  0.1104,  0.0956],\n",
      "        [ 0.9929, -0.4470,  1.0000,  ...,  0.1274,  0.1104,  0.0956],\n",
      "        [ 0.9929, -0.4470,  1.0000,  ...,  0.1274,  0.1104,  0.0956]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9285, -0.0305,  0.9312,  ...,  0.1273,  0.1103,  0.0956],\n",
      "        [ 0.9285, -0.0305,  0.9312,  ...,  0.1273,  0.1103,  0.0956],\n",
      "        [ 0.9285, -0.0305,  0.9312,  ...,  0.1273,  0.1103,  0.0956],\n",
      "        ...,\n",
      "        [ 0.9285, -0.0305,  0.9312,  ...,  0.1273,  0.1103,  0.0956],\n",
      "        [ 0.9285, -0.0305,  0.9312,  ...,  0.1273,  0.1103,  0.0956],\n",
      "        [ 0.9285, -0.0305,  0.9312,  ...,  0.1273,  0.1103,  0.0956]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.6368, 0.3917, 0.7331,  ..., 0.1272, 0.1103, 0.0955],\n",
      "        [0.6368, 0.3917, 0.7331,  ..., 0.1272, 0.1103, 0.0955],\n",
      "        [0.6368, 0.3917, 0.7331,  ..., 0.1272, 0.1103, 0.0955],\n",
      "        ...,\n",
      "        [0.6368, 0.3917, 0.7331,  ..., 0.1272, 0.1103, 0.0955],\n",
      "        [0.6368, 0.3917, 0.7331,  ..., 0.1272, 0.1103, 0.0955],\n",
      "        [0.6368, 0.3917, 0.7331,  ..., 0.1272, 0.1103, 0.0955]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.1892, 0.7416, 0.4330,  ..., 0.1272, 0.1102, 0.0955],\n",
      "        [0.1892, 0.7416, 0.4330,  ..., 0.1272, 0.1102, 0.0955],\n",
      "        [0.1892, 0.7416, 0.4330,  ..., 0.1272, 0.1102, 0.0955],\n",
      "        ...,\n",
      "        [0.1892, 0.7416, 0.4330,  ..., 0.1272, 0.1102, 0.0955],\n",
      "        [0.1892, 0.7416, 0.4330,  ..., 0.1272, 0.1102, 0.0955],\n",
      "        [0.1892, 0.7416, 0.4330,  ..., 0.1272, 0.1102, 0.0955]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3047,  0.9546,  0.0729,  ...,  0.1271,  0.1101,  0.0954],\n",
      "        [-0.3047,  0.9546,  0.0729,  ...,  0.1271,  0.1101,  0.0954],\n",
      "        [-0.3047,  0.9546,  0.0729,  ...,  0.1271,  0.1101,  0.0954],\n",
      "        ...,\n",
      "        [-0.3047,  0.9546,  0.0729,  ...,  0.1271,  0.1101,  0.0954],\n",
      "        [-0.3047,  0.9546,  0.0729,  ...,  0.1271,  0.1101,  0.0954],\n",
      "        [-0.3047,  0.9546,  0.0729,  ...,  0.1271,  0.1101,  0.0954]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7241,  0.9915, -0.2975,  ...,  0.1270,  0.1101,  0.0954],\n",
      "        [-0.7241,  0.9915, -0.2975,  ...,  0.1270,  0.1101,  0.0954],\n",
      "        [-0.7241,  0.9915, -0.2975,  ...,  0.1270,  0.1101,  0.0954],\n",
      "        ...,\n",
      "        [-0.7241,  0.9915, -0.2975,  ...,  0.1270,  0.1101,  0.0954],\n",
      "        [-0.7241,  0.9915, -0.2975,  ...,  0.1270,  0.1101,  0.0954],\n",
      "        [-0.7241,  0.9915, -0.2975,  ...,  0.1270,  0.1101,  0.0954]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9661,  0.8453, -0.6265,  ...,  0.1269,  0.1100,  0.0953],\n",
      "        [-0.9661,  0.8453, -0.6265,  ...,  0.1269,  0.1100,  0.0953],\n",
      "        [-0.9661,  0.8453, -0.6265,  ...,  0.1269,  0.1100,  0.0953],\n",
      "        ...,\n",
      "        [-0.9661,  0.8453, -0.6265,  ...,  0.1269,  0.1100,  0.0953],\n",
      "        [-0.9661,  0.8453, -0.6265,  ...,  0.1269,  0.1100,  0.0953],\n",
      "        [-0.9661,  0.8453, -0.6265,  ...,  0.1269,  0.1100,  0.0953]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9716,  0.5431, -0.8684,  ...,  0.1269,  0.1099,  0.0952],\n",
      "        [-0.9716,  0.5431, -0.8684,  ...,  0.1269,  0.1099,  0.0952],\n",
      "        [-0.9716,  0.5431, -0.8684,  ...,  0.1269,  0.1099,  0.0952],\n",
      "        ...,\n",
      "        [-0.9716,  0.5431, -0.8684,  ...,  0.1269,  0.1099,  0.0952],\n",
      "        [-0.9716,  0.5431, -0.8684,  ...,  0.1269,  0.1099,  0.0952],\n",
      "        [-0.9716,  0.5431, -0.8684,  ...,  0.1269,  0.1099,  0.0952]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7392,  0.1407, -0.9897,  ...,  0.1268,  0.1099,  0.0952],\n",
      "        [-0.7392,  0.1407, -0.9897,  ...,  0.1268,  0.1099,  0.0952],\n",
      "        [-0.7392,  0.1407, -0.9897,  ...,  0.1268,  0.1099,  0.0952],\n",
      "        ...,\n",
      "        [-0.7392,  0.1407, -0.9897,  ...,  0.1268,  0.1099,  0.0952],\n",
      "        [-0.7392,  0.1407, -0.9897,  ...,  0.1268,  0.1099,  0.0952],\n",
      "        [-0.7392,  0.1407, -0.9897,  ...,  0.1268,  0.1099,  0.0952]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3259, -0.2877, -0.9734,  ...,  0.1267,  0.1098,  0.0951],\n",
      "        [-0.3259, -0.2877, -0.9734,  ...,  0.1267,  0.1098,  0.0951],\n",
      "        [-0.3259, -0.2877, -0.9734,  ...,  0.1267,  0.1098,  0.0951],\n",
      "        ...,\n",
      "        [-0.3259, -0.2877, -0.9734,  ...,  0.1267,  0.1098,  0.0951],\n",
      "        [-0.3259, -0.2877, -0.9734,  ...,  0.1267,  0.1098,  0.0951],\n",
      "        [-0.3259, -0.2877, -0.9734,  ...,  0.1267,  0.1098,  0.0951]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1673, -0.6630, -0.8219,  ...,  0.1266,  0.1097,  0.0951],\n",
      "        [ 0.1673, -0.6630, -0.8219,  ...,  0.1266,  0.1097,  0.0951],\n",
      "        [ 0.1673, -0.6630, -0.8219,  ...,  0.1266,  0.1097,  0.0951],\n",
      "        ...,\n",
      "        [ 0.1673, -0.6630, -0.8219,  ...,  0.1266,  0.1097,  0.0951],\n",
      "        [ 0.1673, -0.6630, -0.8219,  ...,  0.1266,  0.1097,  0.0951],\n",
      "        [ 0.1673, -0.6630, -0.8219,  ...,  0.1266,  0.1097,  0.0951]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6195, -0.9159, -0.5563,  ...,  0.1265,  0.1097,  0.0950],\n",
      "        [ 0.6195, -0.9159, -0.5563,  ...,  0.1265,  0.1097,  0.0950],\n",
      "        [ 0.6195, -0.9159, -0.5563,  ...,  0.1265,  0.1097,  0.0950],\n",
      "        ...,\n",
      "        [ 0.6195, -0.9159, -0.5563,  ...,  0.1265,  0.1097,  0.0950],\n",
      "        [ 0.6195, -0.9159, -0.5563,  ...,  0.1265,  0.1097,  0.0950],\n",
      "        [ 0.6195, -0.9159, -0.5563,  ...,  0.1265,  0.1097,  0.0950]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9200, -0.9998, -0.2133,  ...,  0.1265,  0.1096,  0.0950],\n",
      "        [ 0.9200, -0.9998, -0.2133,  ...,  0.1265,  0.1096,  0.0950],\n",
      "        [ 0.9200, -0.9998, -0.2133,  ...,  0.1265,  0.1096,  0.0950],\n",
      "        ...,\n",
      "        [ 0.9200, -0.9998, -0.2133,  ...,  0.1265,  0.1096,  0.0950],\n",
      "        [ 0.9200, -0.9998, -0.2133,  ...,  0.1265,  0.1096,  0.0950],\n",
      "        [ 0.9200, -0.9998, -0.2133,  ...,  0.1265,  0.1096,  0.0950]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9953, -0.8992,  0.1594,  ...,  0.1264,  0.1095,  0.0949],\n",
      "        [ 0.9953, -0.8992,  0.1594,  ...,  0.1264,  0.1095,  0.0949],\n",
      "        [ 0.9953, -0.8992,  0.1594,  ...,  0.1264,  0.1095,  0.0949],\n",
      "        ...,\n",
      "        [ 0.9953, -0.8992,  0.1594,  ...,  0.1264,  0.1095,  0.0949],\n",
      "        [ 0.9953, -0.8992,  0.1594,  ...,  0.1264,  0.1095,  0.0949],\n",
      "        [ 0.9953, -0.8992,  0.1594,  ...,  0.1264,  0.1095,  0.0949]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8269, -0.6326,  0.5098,  ...,  0.1263,  0.1095,  0.0948],\n",
      "        [ 0.8269, -0.6326,  0.5098,  ...,  0.1263,  0.1095,  0.0948],\n",
      "        [ 0.8269, -0.6326,  0.5098,  ...,  0.1263,  0.1095,  0.0948],\n",
      "        ...,\n",
      "        [ 0.8269, -0.6326,  0.5098,  ...,  0.1263,  0.1095,  0.0948],\n",
      "        [ 0.8269, -0.6326,  0.5098,  ...,  0.1263,  0.1095,  0.0948],\n",
      "        [ 0.8269, -0.6326,  0.5098,  ...,  0.1263,  0.1095,  0.0948]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4560, -0.2492,  0.7895,  ...,  0.1262,  0.1094,  0.0948],\n",
      "        [ 0.4560, -0.2492,  0.7895,  ...,  0.1262,  0.1094,  0.0948],\n",
      "        [ 0.4560, -0.2492,  0.7895,  ...,  0.1262,  0.1094,  0.0948],\n",
      "        ...,\n",
      "        [ 0.4560, -0.2492,  0.7895,  ...,  0.1262,  0.1094,  0.0948],\n",
      "        [ 0.4560, -0.2492,  0.7895,  ...,  0.1262,  0.1094,  0.0948],\n",
      "        [ 0.4560, -0.2492,  0.7895,  ...,  0.1262,  0.1094,  0.0948]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0265,  0.1801,  0.9594,  ...,  0.1262,  0.1093,  0.0947],\n",
      "        [-0.0265,  0.1801,  0.9594,  ...,  0.1262,  0.1093,  0.0947],\n",
      "        [-0.0265,  0.1801,  0.9594,  ...,  0.1262,  0.1093,  0.0947],\n",
      "        ...,\n",
      "        [-0.0265,  0.1801,  0.9594,  ...,  0.1262,  0.1093,  0.0947],\n",
      "        [-0.0265,  0.1801,  0.9594,  ...,  0.1262,  0.1093,  0.0947],\n",
      "        [-0.0265,  0.1801,  0.9594,  ...,  0.1262,  0.1093,  0.0947]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5025,  0.5762,  0.9960,  ...,  0.1261,  0.1093,  0.0947],\n",
      "        [-0.5025,  0.5762,  0.9960,  ...,  0.1261,  0.1093,  0.0947],\n",
      "        [-0.5025,  0.5762,  0.9960,  ...,  0.1261,  0.1093,  0.0947],\n",
      "        ...,\n",
      "        [-0.5025,  0.5762,  0.9960,  ...,  0.1261,  0.1093,  0.0947],\n",
      "        [-0.5025,  0.5762,  0.9960,  ...,  0.1261,  0.1093,  0.0947],\n",
      "        [-0.5025,  0.5762,  0.9960,  ...,  0.1261,  0.1093,  0.0947]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8555,  0.8660,  0.8943,  ...,  0.1260,  0.1092,  0.0946],\n",
      "        [-0.8555,  0.8660,  0.8943,  ...,  0.1260,  0.1092,  0.0946],\n",
      "        [-0.8555,  0.8660,  0.8943,  ...,  0.1260,  0.1092,  0.0946],\n",
      "        ...,\n",
      "        [-0.8555,  0.8660,  0.8943,  ...,  0.1260,  0.1092,  0.0946],\n",
      "        [-0.8555,  0.8660,  0.8943,  ...,  0.1260,  0.1092,  0.0946],\n",
      "        [-0.8555,  0.8660,  0.8943,  ...,  0.1260,  0.1092,  0.0946]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9990,  0.9959,  0.6683,  ...,  0.1259,  0.1091,  0.0946],\n",
      "        [-0.9990,  0.9959,  0.6683,  ...,  0.1259,  0.1091,  0.0946],\n",
      "        [-0.9990,  0.9959,  0.6683,  ...,  0.1259,  0.1091,  0.0946],\n",
      "        ...,\n",
      "        [-0.9990,  0.9959,  0.6683,  ...,  0.1259,  0.1091,  0.0946],\n",
      "        [-0.9990,  0.9959,  0.6683,  ...,  0.1259,  0.1091,  0.0946],\n",
      "        [-0.9990,  0.9959,  0.6683,  ...,  0.1259,  0.1091,  0.0946]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8980,  0.9420,  0.3494,  ...,  0.1259,  0.1091,  0.0945],\n",
      "        [-0.8980,  0.9420,  0.3494,  ...,  0.1259,  0.1091,  0.0945],\n",
      "        [-0.8980,  0.9420,  0.3494,  ...,  0.1259,  0.1091,  0.0945],\n",
      "        ...,\n",
      "        [-0.8980,  0.9420,  0.3494,  ...,  0.1259,  0.1091,  0.0945],\n",
      "        [-0.8980,  0.9420,  0.3494,  ...,  0.1259,  0.1091,  0.0945],\n",
      "        [-0.8980,  0.9420,  0.3494,  ...,  0.1259,  0.1091,  0.0945]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5771,  0.7143, -0.0180,  ...,  0.1258,  0.1090,  0.0944],\n",
      "        [-0.5771,  0.7143, -0.0180,  ...,  0.1258,  0.1090,  0.0944],\n",
      "        [-0.5771,  0.7143, -0.0180,  ...,  0.1258,  0.1090,  0.0944],\n",
      "        ...,\n",
      "        [-0.5771,  0.7143, -0.0180,  ...,  0.1258,  0.1090,  0.0944],\n",
      "        [-0.5771,  0.7143, -0.0180,  ...,  0.1258,  0.1090,  0.0944],\n",
      "        [-0.5771,  0.7143, -0.0180,  ...,  0.1258,  0.1090,  0.0944]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1149,  0.3547, -0.3829,  ...,  0.1257,  0.1089,  0.0944],\n",
      "        [-0.1149,  0.3547, -0.3829,  ...,  0.1257,  0.1089,  0.0944],\n",
      "        [-0.1149,  0.3547, -0.3829,  ...,  0.1257,  0.1089,  0.0944],\n",
      "        ...,\n",
      "        [-0.1149,  0.3547, -0.3829,  ...,  0.1257,  0.1089,  0.0944],\n",
      "        [-0.1149,  0.3547, -0.3829,  ...,  0.1257,  0.1089,  0.0944],\n",
      "        [-0.1149,  0.3547, -0.3829,  ...,  0.1257,  0.1089,  0.0944]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3755, -0.0703, -0.6946,  ...,  0.1256,  0.1089,  0.0943],\n",
      "        [ 0.3755, -0.0703, -0.6946,  ...,  0.1256,  0.1089,  0.0943],\n",
      "        [ 0.3755, -0.0703, -0.6946,  ...,  0.1256,  0.1089,  0.0943],\n",
      "        ...,\n",
      "        [ 0.3755, -0.0703, -0.6946,  ...,  0.1256,  0.1089,  0.0943],\n",
      "        [ 0.3755, -0.0703, -0.6946,  ...,  0.1256,  0.1089,  0.0943],\n",
      "        [ 0.3755, -0.0703, -0.6946,  ...,  0.1256,  0.1089,  0.0943]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7738, -0.4824, -0.9098,  ...,  0.1256,  0.1088,  0.0943],\n",
      "        [ 0.7738, -0.4824, -0.9098,  ...,  0.1256,  0.1088,  0.0943],\n",
      "        [ 0.7738, -0.4824, -0.9098,  ...,  0.1256,  0.1088,  0.0943],\n",
      "        ...,\n",
      "        [ 0.7738, -0.4824, -0.9098,  ...,  0.1256,  0.1088,  0.0943],\n",
      "        [ 0.7738, -0.4824, -0.9098,  ...,  0.1256,  0.1088,  0.0943],\n",
      "        [ 0.7738, -0.4824, -0.9098,  ...,  0.1256,  0.1088,  0.0943]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9828, -0.8054, -0.9986,  ...,  0.1255,  0.1087,  0.0942],\n",
      "        [ 0.9828, -0.8054, -0.9986,  ...,  0.1255,  0.1087,  0.0942],\n",
      "        [ 0.9828, -0.8054, -0.9986,  ...,  0.1255,  0.1087,  0.0942],\n",
      "        ...,\n",
      "        [ 0.9828, -0.8054, -0.9986,  ...,  0.1255,  0.1087,  0.0942],\n",
      "        [ 0.9828, -0.8054, -0.9986,  ...,  0.1255,  0.1087,  0.0942],\n",
      "        [ 0.9828, -0.8054, -0.9986,  ...,  0.1255,  0.1087,  0.0942]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9511, -0.9798, -0.9486,  ...,  0.1254,  0.1087,  0.0941],\n",
      "        [ 0.9511, -0.9798, -0.9486,  ...,  0.1254,  0.1087,  0.0941],\n",
      "        [ 0.9511, -0.9798, -0.9486,  ...,  0.1254,  0.1087,  0.0941],\n",
      "        ...,\n",
      "        [ 0.9511, -0.9798, -0.9486,  ...,  0.1254,  0.1087,  0.0941],\n",
      "        [ 0.9511, -0.9798, -0.9486,  ...,  0.1254,  0.1087,  0.0941],\n",
      "        [ 0.9511, -0.9798, -0.9486,  ...,  0.1254,  0.1087,  0.0941]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6865, -0.9733, -0.7669,  ...,  0.1253,  0.1086,  0.0941],\n",
      "        [ 0.6865, -0.9733, -0.7669,  ...,  0.1253,  0.1086,  0.0941],\n",
      "        [ 0.6865, -0.9733, -0.7669,  ...,  0.1253,  0.1086,  0.0941],\n",
      "        ...,\n",
      "        [ 0.6865, -0.9733, -0.7669,  ...,  0.1253,  0.1086,  0.0941],\n",
      "        [ 0.6865, -0.9733, -0.7669,  ...,  0.1253,  0.1086,  0.0941],\n",
      "        [ 0.6865, -0.9733, -0.7669,  ...,  0.1253,  0.1086,  0.0941]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2539, -0.7873, -0.4785,  ...,  0.1253,  0.1085,  0.0940],\n",
      "        [ 0.2539, -0.7873, -0.4785,  ...,  0.1253,  0.1085,  0.0940],\n",
      "        [ 0.2539, -0.7873, -0.4785,  ...,  0.1253,  0.1085,  0.0940],\n",
      "        ...,\n",
      "        [ 0.2539, -0.7873, -0.4785,  ...,  0.1253,  0.1085,  0.0940],\n",
      "        [ 0.2539, -0.7873, -0.4785,  ...,  0.1253,  0.1085,  0.0940],\n",
      "        [ 0.2539, -0.7873, -0.4785,  ...,  0.1253,  0.1085,  0.0940]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2409, -0.4559, -0.1237,  ...,  0.1252,  0.1085,  0.0940],\n",
      "        [-0.2409, -0.4559, -0.1237,  ...,  0.1252,  0.1085,  0.0940],\n",
      "        [-0.2409, -0.4559, -0.1237,  ...,  0.1252,  0.1085,  0.0940],\n",
      "        ...,\n",
      "        [-0.2409, -0.4559, -0.1237,  ...,  0.1252,  0.1085,  0.0940],\n",
      "        [-0.2409, -0.4559, -0.1237,  ...,  0.1252,  0.1085,  0.0940],\n",
      "        [-0.2409, -0.4559, -0.1237,  ...,  0.1252,  0.1085,  0.0940]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6767, -0.0404,  0.2483,  ...,  0.1251,  0.1084,  0.0939],\n",
      "        [-0.6767, -0.0404,  0.2483,  ...,  0.1251,  0.1084,  0.0939],\n",
      "        [-0.6767, -0.0404,  0.2483,  ...,  0.1251,  0.1084,  0.0939],\n",
      "        ...,\n",
      "        [-0.6767, -0.0404,  0.2483,  ...,  0.1251,  0.1084,  0.0939],\n",
      "        [-0.6767, -0.0404,  0.2483,  ...,  0.1251,  0.1084,  0.0939],\n",
      "        [-0.6767, -0.0404,  0.2483,  ...,  0.1251,  0.1084,  0.0939]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9468,  0.3826,  0.5858,  ...,  0.1250,  0.1083,  0.0939],\n",
      "        [-0.9468,  0.3826,  0.5858,  ...,  0.1250,  0.1083,  0.0939],\n",
      "        [-0.9468,  0.3826,  0.5858,  ...,  0.1250,  0.1083,  0.0939],\n",
      "        ...,\n",
      "        [-0.9468,  0.3826,  0.5858,  ...,  0.1250,  0.1083,  0.0939],\n",
      "        [-0.9468,  0.3826,  0.5858,  ...,  0.1250,  0.1083,  0.0939],\n",
      "        [-0.9468,  0.3826,  0.5858,  ...,  0.1250,  0.1083,  0.0939]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9852,  0.7349,  0.8419,  ...,  0.1249,  0.1083,  0.0938],\n",
      "        [-0.9852,  0.7349,  0.8419,  ...,  0.1249,  0.1083,  0.0938],\n",
      "        [-0.9852,  0.7349,  0.8419,  ...,  0.1249,  0.1083,  0.0938],\n",
      "        ...,\n",
      "        [-0.9852,  0.7349,  0.8419,  ...,  0.1249,  0.1083,  0.0938],\n",
      "        [-0.9852,  0.7349,  0.8419,  ...,  0.1249,  0.1083,  0.0938],\n",
      "        [-0.9852,  0.7349,  0.8419,  ...,  0.1249,  0.1083,  0.0938]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7823,  0.9516,  0.9810,  ...,  0.1249,  0.1082,  0.0937],\n",
      "        [-0.7823,  0.9516,  0.9810,  ...,  0.1249,  0.1082,  0.0937],\n",
      "        [-0.7823,  0.9516,  0.9810,  ...,  0.1249,  0.1082,  0.0937],\n",
      "        ...,\n",
      "        [-0.7823,  0.9516,  0.9810,  ...,  0.1249,  0.1082,  0.0937],\n",
      "        [-0.7823,  0.9516,  0.9810,  ...,  0.1249,  0.1082,  0.0937],\n",
      "        [-0.7823,  0.9516,  0.9810,  ...,  0.1249,  0.1082,  0.0937]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3879,  0.9927,  0.9839,  ...,  0.1248,  0.1081,  0.0937],\n",
      "        [-0.3879,  0.9927,  0.9839,  ...,  0.1248,  0.1081,  0.0937],\n",
      "        [-0.3879,  0.9927,  0.9839,  ...,  0.1248,  0.1081,  0.0937],\n",
      "        ...,\n",
      "        [-0.3879,  0.9927,  0.9839,  ...,  0.1248,  0.1081,  0.0937],\n",
      "        [-0.3879,  0.9927,  0.9839,  ...,  0.1248,  0.1081,  0.0937],\n",
      "        [-0.3879,  0.9927,  0.9839,  ...,  0.1248,  0.1081,  0.0937]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.1015, 0.8506, 0.8499,  ..., 0.1247, 0.1081, 0.0936],\n",
      "        [0.1015, 0.8506, 0.8499,  ..., 0.1247, 0.1081, 0.0936],\n",
      "        [0.1015, 0.8506, 0.8499,  ..., 0.1247, 0.1081, 0.0936],\n",
      "        ...,\n",
      "        [0.1015, 0.8506, 0.8499,  ..., 0.1247, 0.1081, 0.0936],\n",
      "        [0.1015, 0.8506, 0.8499,  ..., 0.1247, 0.1081, 0.0936],\n",
      "        [0.1015, 0.8506, 0.8499,  ..., 0.1247, 0.1081, 0.0936]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.5660, 0.5514, 0.5980,  ..., 0.1246, 0.1080, 0.0936],\n",
      "        [0.5660, 0.5514, 0.5980,  ..., 0.1246, 0.1080, 0.0936],\n",
      "        [0.5660, 0.5514, 0.5980,  ..., 0.1246, 0.1080, 0.0936],\n",
      "        ...,\n",
      "        [0.5660, 0.5514, 0.5980,  ..., 0.1246, 0.1080, 0.0936],\n",
      "        [0.5660, 0.5514, 0.5980,  ..., 0.1246, 0.1080, 0.0936],\n",
      "        [0.5660, 0.5514, 0.5980,  ..., 0.1246, 0.1080, 0.0936]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8920, 0.1505, 0.2629,  ..., 0.1246, 0.1079, 0.0935],\n",
      "        [0.8920, 0.1505, 0.2629,  ..., 0.1246, 0.1079, 0.0935],\n",
      "        [0.8920, 0.1505, 0.2629,  ..., 0.1246, 0.1079, 0.0935],\n",
      "        ...,\n",
      "        [0.8920, 0.1505, 0.2629,  ..., 0.1246, 0.1079, 0.0935],\n",
      "        [0.8920, 0.1505, 0.2629,  ..., 0.1246, 0.1079, 0.0935],\n",
      "        [0.8920, 0.1505, 0.2629,  ..., 0.1246, 0.1079, 0.0935]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9995, -0.2782, -0.1087,  ...,  0.1245,  0.1079,  0.0935],\n",
      "        [ 0.9995, -0.2782, -0.1087,  ...,  0.1245,  0.1079,  0.0935],\n",
      "        [ 0.9995, -0.2782, -0.1087,  ...,  0.1245,  0.1079,  0.0935],\n",
      "        ...,\n",
      "        [ 0.9995, -0.2782, -0.1087,  ...,  0.1245,  0.1079,  0.0935],\n",
      "        [ 0.9995, -0.2782, -0.1087,  ...,  0.1245,  0.1079,  0.0935],\n",
      "        [ 0.9995, -0.2782, -0.1087,  ...,  0.1245,  0.1079,  0.0935]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8623, -0.6555, -0.4652,  ...,  0.1244,  0.1078,  0.0934],\n",
      "        [ 0.8623, -0.6555, -0.4652,  ...,  0.1244,  0.1078,  0.0934],\n",
      "        [ 0.8623, -0.6555, -0.4652,  ...,  0.1244,  0.1078,  0.0934],\n",
      "        ...,\n",
      "        [ 0.8623, -0.6555, -0.4652,  ...,  0.1244,  0.1078,  0.0934],\n",
      "        [ 0.8623, -0.6555, -0.4652,  ...,  0.1244,  0.1078,  0.0934],\n",
      "        [ 0.8623, -0.6555, -0.4652,  ...,  0.1244,  0.1078,  0.0934]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5140, -0.9119, -0.7571,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.5140, -0.9119, -0.7571,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.5140, -0.9119, -0.7571,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        ...,\n",
      "        [ 0.5140, -0.9119, -0.7571,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.5140, -0.9119, -0.7571,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.5140, -0.9119, -0.7571,  ...,  0.1243,  0.1077,  0.0933]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0399, -0.9999, -0.9437,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.0399, -0.9999, -0.9437,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.0399, -0.9999, -0.9437,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        ...,\n",
      "        [ 0.0399, -0.9999, -0.9437,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.0399, -0.9999, -0.9437,  ...,  0.1243,  0.1077,  0.0933],\n",
      "        [ 0.0399, -0.9999, -0.9437,  ...,  0.1243,  0.1077,  0.0933]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4440, -0.9035, -0.9993,  ...,  0.1242,  0.1076,  0.0932],\n",
      "        [-0.4440, -0.9035, -0.9993,  ...,  0.1242,  0.1076,  0.0932],\n",
      "        [-0.4440, -0.9035, -0.9993,  ...,  0.1242,  0.1076,  0.0932],\n",
      "        ...,\n",
      "        [-0.4440, -0.9035, -0.9993,  ...,  0.1242,  0.1076,  0.0932],\n",
      "        [-0.4440, -0.9035, -0.9993,  ...,  0.1242,  0.1076,  0.0932],\n",
      "        [-0.4440, -0.9035, -0.9993,  ...,  0.1242,  0.1076,  0.0932]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8193, -0.6402, -0.9160,  ...,  0.1241,  0.1075,  0.0932],\n",
      "        [-0.8193, -0.6402, -0.9160,  ...,  0.1241,  0.1075,  0.0932],\n",
      "        [-0.8193, -0.6402, -0.9160,  ...,  0.1241,  0.1075,  0.0932],\n",
      "        ...,\n",
      "        [-0.8193, -0.6402, -0.9160,  ...,  0.1241,  0.1075,  0.0932],\n",
      "        [-0.8193, -0.6402, -0.9160,  ...,  0.1241,  0.1075,  0.0932],\n",
      "        [-0.8193, -0.6402, -0.9160,  ...,  0.1241,  0.1075,  0.0932]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9939, -0.2588, -0.7054,  ...,  0.1240,  0.1075,  0.0931],\n",
      "        [-0.9939, -0.2588, -0.7054,  ...,  0.1240,  0.1075,  0.0931],\n",
      "        [-0.9939, -0.2588, -0.7054,  ...,  0.1240,  0.1075,  0.0931],\n",
      "        ...,\n",
      "        [-0.9939, -0.2588, -0.7054,  ...,  0.1240,  0.1075,  0.0931],\n",
      "        [-0.9939, -0.2588, -0.7054,  ...,  0.1240,  0.1075,  0.0931],\n",
      "        [-0.9939, -0.2588, -0.7054,  ...,  0.1240,  0.1075,  0.0931]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9252,  0.1703, -0.3968,  ...,  0.1240,  0.1074,  0.0931],\n",
      "        [-0.9252,  0.1703, -0.3968,  ...,  0.1240,  0.1074,  0.0931],\n",
      "        [-0.9252,  0.1703, -0.3968,  ...,  0.1240,  0.1074,  0.0931],\n",
      "        ...,\n",
      "        [-0.9252,  0.1703, -0.3968,  ...,  0.1240,  0.1074,  0.0931],\n",
      "        [-0.9252,  0.1703, -0.3968,  ...,  0.1240,  0.1074,  0.0931],\n",
      "        [-0.9252,  0.1703, -0.3968,  ...,  0.1240,  0.1074,  0.0931]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6299,  0.5681, -0.0331,  ...,  0.1239,  0.1073,  0.0930],\n",
      "        [-0.6299,  0.5681, -0.0331,  ...,  0.1239,  0.1073,  0.0930],\n",
      "        [-0.6299,  0.5681, -0.0331,  ...,  0.1239,  0.1073,  0.0930],\n",
      "        ...,\n",
      "        [-0.6299,  0.5681, -0.0331,  ...,  0.1239,  0.1073,  0.0930],\n",
      "        [-0.6299,  0.5681, -0.0331,  ...,  0.1239,  0.1073,  0.0930],\n",
      "        [-0.6299,  0.5681, -0.0331,  ...,  0.1239,  0.1073,  0.0930]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1805,  0.8610,  0.3352,  ...,  0.1238,  0.1073,  0.0929],\n",
      "        [-0.1805,  0.8610,  0.3352,  ...,  0.1238,  0.1073,  0.0929],\n",
      "        [-0.1805,  0.8610,  0.3352,  ...,  0.1238,  0.1073,  0.0929],\n",
      "        ...,\n",
      "        [-0.1805,  0.8610,  0.3352,  ...,  0.1238,  0.1073,  0.0929],\n",
      "        [-0.1805,  0.8610,  0.3352,  ...,  0.1238,  0.1073,  0.0929],\n",
      "        [-0.1805,  0.8610,  0.3352,  ...,  0.1238,  0.1073,  0.0929]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.3132, 0.9949, 0.6570,  ..., 0.1237, 0.1072, 0.0929],\n",
      "        [0.3132, 0.9949, 0.6570,  ..., 0.1237, 0.1072, 0.0929],\n",
      "        [0.3132, 0.9949, 0.6570,  ..., 0.1237, 0.1072, 0.0929],\n",
      "        ...,\n",
      "        [0.3132, 0.9949, 0.6570,  ..., 0.1237, 0.1072, 0.0929],\n",
      "        [0.3132, 0.9949, 0.6570,  ..., 0.1237, 0.1072, 0.0929],\n",
      "        [0.3132, 0.9949, 0.6570,  ..., 0.1237, 0.1072, 0.0929]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.7301, 0.9453, 0.8874,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.7301, 0.9453, 0.8874,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.7301, 0.9453, 0.8874,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        ...,\n",
      "        [0.7301, 0.9453, 0.8874,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.7301, 0.9453, 0.8874,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.7301, 0.9453, 0.8874,  ..., 0.1236, 0.1071, 0.0928]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9683, 0.7212, 0.9946,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.9683, 0.7212, 0.9946,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.9683, 0.7212, 0.9946,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        ...,\n",
      "        [0.9683, 0.7212, 0.9946,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.9683, 0.7212, 0.9946,  ..., 0.1236, 0.1071, 0.0928],\n",
      "        [0.9683, 0.7212, 0.9946,  ..., 0.1236, 0.1071, 0.0928]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9695, 0.3640, 0.9635,  ..., 0.1235, 0.1070, 0.0927],\n",
      "        [0.9695, 0.3640, 0.9635,  ..., 0.1235, 0.1070, 0.0927],\n",
      "        [0.9695, 0.3640, 0.9635,  ..., 0.1235, 0.1070, 0.0927],\n",
      "        ...,\n",
      "        [0.9695, 0.3640, 0.9635,  ..., 0.1235, 0.1070, 0.0927],\n",
      "        [0.9695, 0.3640, 0.9635,  ..., 0.1235, 0.1070, 0.0927],\n",
      "        [0.9695, 0.3640, 0.9635,  ..., 0.1235, 0.1070, 0.0927]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7332, -0.0604,  0.7986,  ...,  0.1234,  0.1069,  0.0927],\n",
      "        [ 0.7332, -0.0604,  0.7986,  ...,  0.1234,  0.1069,  0.0927],\n",
      "        [ 0.7332, -0.0604,  0.7986,  ...,  0.1234,  0.1069,  0.0927],\n",
      "        ...,\n",
      "        [ 0.7332, -0.0604,  0.7986,  ...,  0.1234,  0.1069,  0.0927],\n",
      "        [ 0.7332, -0.0604,  0.7986,  ...,  0.1234,  0.1069,  0.0927],\n",
      "        [ 0.7332, -0.0604,  0.7986,  ...,  0.1234,  0.1069,  0.0927]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3175, -0.4737,  0.5227,  ...,  0.1233,  0.1069,  0.0926],\n",
      "        [ 0.3175, -0.4737,  0.5227,  ...,  0.1233,  0.1069,  0.0926],\n",
      "        [ 0.3175, -0.4737,  0.5227,  ...,  0.1233,  0.1069,  0.0926],\n",
      "        ...,\n",
      "        [ 0.3175, -0.4737,  0.5227,  ...,  0.1233,  0.1069,  0.0926],\n",
      "        [ 0.3175, -0.4737,  0.5227,  ...,  0.1233,  0.1069,  0.0926],\n",
      "        [ 0.3175, -0.4737,  0.5227,  ...,  0.1233,  0.1069,  0.0926]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1760, -0.7995,  0.1742,  ...,  0.1233,  0.1068,  0.0925],\n",
      "        [-0.1760, -0.7995,  0.1742,  ...,  0.1233,  0.1068,  0.0925],\n",
      "        [-0.1760, -0.7995,  0.1742,  ...,  0.1233,  0.1068,  0.0925],\n",
      "        ...,\n",
      "        [-0.1760, -0.7995,  0.1742,  ...,  0.1233,  0.1068,  0.0925],\n",
      "        [-0.1760, -0.7995,  0.1742,  ...,  0.1233,  0.1068,  0.0925],\n",
      "        [-0.1760, -0.7995,  0.1742,  ...,  0.1233,  0.1068,  0.0925]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6264, -0.9777, -0.1985,  ...,  0.1232,  0.1067,  0.0925],\n",
      "        [-0.6264, -0.9777, -0.1985,  ...,  0.1232,  0.1067,  0.0925],\n",
      "        [-0.6264, -0.9777, -0.1985,  ...,  0.1232,  0.1067,  0.0925],\n",
      "        ...,\n",
      "        [-0.6264, -0.9777, -0.1985,  ...,  0.1232,  0.1067,  0.0925],\n",
      "        [-0.6264, -0.9777, -0.1985,  ...,  0.1232,  0.1067,  0.0925],\n",
      "        [-0.6264, -0.9777, -0.1985,  ...,  0.1232,  0.1067,  0.0925]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9234, -0.9755, -0.5436,  ...,  0.1231,  0.1067,  0.0924],\n",
      "        [-0.9234, -0.9755, -0.5436,  ...,  0.1231,  0.1067,  0.0924],\n",
      "        [-0.9234, -0.9755, -0.5436,  ...,  0.1231,  0.1067,  0.0924],\n",
      "        ...,\n",
      "        [-0.9234, -0.9755, -0.5436,  ...,  0.1231,  0.1067,  0.0924],\n",
      "        [-0.9234, -0.9755, -0.5436,  ...,  0.1231,  0.1067,  0.0924],\n",
      "        [-0.9234, -0.9755, -0.5436,  ...,  0.1231,  0.1067,  0.0924]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9944, -0.7933, -0.8132,  ...,  0.1230,  0.1066,  0.0924],\n",
      "        [-0.9944, -0.7933, -0.8132,  ...,  0.1230,  0.1066,  0.0924],\n",
      "        [-0.9944, -0.7933, -0.8132,  ...,  0.1230,  0.1066,  0.0924],\n",
      "        ...,\n",
      "        [-0.9944, -0.7933, -0.8132,  ...,  0.1230,  0.1066,  0.0924],\n",
      "        [-0.9944, -0.7933, -0.8132,  ...,  0.1230,  0.1066,  0.0924],\n",
      "        [-0.9944, -0.7933, -0.8132,  ...,  0.1230,  0.1066,  0.0924]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8219, -0.4646, -0.9699,  ...,  0.1230,  0.1065,  0.0923],\n",
      "        [-0.8219, -0.4646, -0.9699,  ...,  0.1230,  0.1065,  0.0923],\n",
      "        [-0.8219, -0.4646, -0.9699,  ...,  0.1230,  0.1065,  0.0923],\n",
      "        ...,\n",
      "        [-0.8219, -0.4646, -0.9699,  ...,  0.1230,  0.1065,  0.0923],\n",
      "        [-0.8219, -0.4646, -0.9699,  ...,  0.1230,  0.1065,  0.0923],\n",
      "        [-0.8219, -0.4646, -0.9699,  ...,  0.1230,  0.1065,  0.0923]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4481, -0.0502, -0.9917,  ...,  0.1229,  0.1065,  0.0923],\n",
      "        [-0.4481, -0.0502, -0.9917,  ...,  0.1229,  0.1065,  0.0923],\n",
      "        [-0.4481, -0.0502, -0.9917,  ...,  0.1229,  0.1065,  0.0923],\n",
      "        ...,\n",
      "        [-0.4481, -0.0502, -0.9917,  ...,  0.1229,  0.1065,  0.0923],\n",
      "        [-0.4481, -0.0502, -0.9917,  ...,  0.1229,  0.1065,  0.0923],\n",
      "        [-0.4481, -0.0502, -0.9917,  ...,  0.1229,  0.1065,  0.0923]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0353,  0.3735, -0.8758,  ...,  0.1228,  0.1064,  0.0922],\n",
      "        [ 0.0353,  0.3735, -0.8758,  ...,  0.1228,  0.1064,  0.0922],\n",
      "        [ 0.0353,  0.3735, -0.8758,  ...,  0.1228,  0.1064,  0.0922],\n",
      "        ...,\n",
      "        [ 0.0353,  0.3735, -0.8758,  ...,  0.1228,  0.1064,  0.0922],\n",
      "        [ 0.0353,  0.3735, -0.8758,  ...,  0.1228,  0.1064,  0.0922],\n",
      "        [ 0.0353,  0.3735, -0.8758,  ...,  0.1228,  0.1064,  0.0922]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5101,  0.7282, -0.6381,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.5101,  0.7282, -0.6381,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.5101,  0.7282, -0.6381,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        ...,\n",
      "        [ 0.5101,  0.7282, -0.6381,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.5101,  0.7282, -0.6381,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.5101,  0.7282, -0.6381,  ...,  0.1227,  0.1063,  0.0921]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8600,  0.9486, -0.3118,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.8600,  0.9486, -0.3118,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.8600,  0.9486, -0.3118,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        ...,\n",
      "        [ 0.8600,  0.9486, -0.3118,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.8600,  0.9486, -0.3118,  ...,  0.1227,  0.1063,  0.0921],\n",
      "        [ 0.8600,  0.9486, -0.3118,  ...,  0.1227,  0.1063,  0.0921]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9994, 0.9939, 0.0578,  ..., 0.1226, 0.1062, 0.0920],\n",
      "        [0.9994, 0.9939, 0.0578,  ..., 0.1226, 0.1062, 0.0920],\n",
      "        [0.9994, 0.9939, 0.0578,  ..., 0.1226, 0.1062, 0.0920],\n",
      "        ...,\n",
      "        [0.9994, 0.9939, 0.0578,  ..., 0.1226, 0.1062, 0.0920],\n",
      "        [0.9994, 0.9939, 0.0578,  ..., 0.1226, 0.1062, 0.0920],\n",
      "        [0.9994, 0.9939, 0.0578,  ..., 0.1226, 0.1062, 0.0920]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8940, 0.8557, 0.4194,  ..., 0.1225, 0.1061, 0.0920],\n",
      "        [0.8940, 0.8557, 0.4194,  ..., 0.1225, 0.1061, 0.0920],\n",
      "        [0.8940, 0.8557, 0.4194,  ..., 0.1225, 0.1061, 0.0920],\n",
      "        ...,\n",
      "        [0.8940, 0.8557, 0.4194,  ..., 0.1225, 0.1061, 0.0920],\n",
      "        [0.8940, 0.8557, 0.4194,  ..., 0.1225, 0.1061, 0.0920],\n",
      "        [0.8940, 0.8557, 0.4194,  ..., 0.1225, 0.1061, 0.0920]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.5698, 0.5596, 0.7227,  ..., 0.1224, 0.1061, 0.0919],\n",
      "        [0.5698, 0.5596, 0.7227,  ..., 0.1224, 0.1061, 0.0919],\n",
      "        [0.5698, 0.5596, 0.7227,  ..., 0.1224, 0.1061, 0.0919],\n",
      "        ...,\n",
      "        [0.5698, 0.5596, 0.7227,  ..., 0.1224, 0.1061, 0.0919],\n",
      "        [0.5698, 0.5596, 0.7227,  ..., 0.1224, 0.1061, 0.0919],\n",
      "        [0.5698, 0.5596, 0.7227,  ..., 0.1224, 0.1061, 0.0919]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.1061, 0.1603, 0.9256,  ..., 0.1223, 0.1060, 0.0918],\n",
      "        [0.1061, 0.1603, 0.9256,  ..., 0.1223, 0.1060, 0.0918],\n",
      "        [0.1061, 0.1603, 0.9256,  ..., 0.1223, 0.1060, 0.0918],\n",
      "        ...,\n",
      "        [0.1061, 0.1603, 0.9256,  ..., 0.1223, 0.1060, 0.0918],\n",
      "        [0.1061, 0.1603, 0.9256,  ..., 0.1223, 0.1060, 0.0918],\n",
      "        [0.1061, 0.1603, 0.9256,  ..., 0.1223, 0.1060, 0.0918]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3836, -0.2687,  0.9999,  ...,  0.1223,  0.1059,  0.0918],\n",
      "        [-0.3836, -0.2687,  0.9999,  ...,  0.1223,  0.1059,  0.0918],\n",
      "        [-0.3836, -0.2687,  0.9999,  ...,  0.1223,  0.1059,  0.0918],\n",
      "        ...,\n",
      "        [-0.3836, -0.2687,  0.9999,  ...,  0.1223,  0.1059,  0.0918],\n",
      "        [-0.3836, -0.2687,  0.9999,  ...,  0.1223,  0.1059,  0.0918],\n",
      "        [-0.3836, -0.2687,  0.9999,  ...,  0.1223,  0.1059,  0.0918]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7794, -0.6480,  0.9353,  ...,  0.1222,  0.1059,  0.0917],\n",
      "        [-0.7794, -0.6480,  0.9353,  ...,  0.1222,  0.1059,  0.0917],\n",
      "        [-0.7794, -0.6480,  0.9353,  ...,  0.1222,  0.1059,  0.0917],\n",
      "        ...,\n",
      "        [-0.7794, -0.6480,  0.9353,  ...,  0.1222,  0.1059,  0.0917],\n",
      "        [-0.7794, -0.6480,  0.9353,  ...,  0.1222,  0.1059,  0.0917],\n",
      "        [-0.7794, -0.6480,  0.9353,  ...,  0.1222,  0.1059,  0.0917]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9844, -0.9078,  0.7407,  ...,  0.1221,  0.1058,  0.0917],\n",
      "        [-0.9844, -0.9078,  0.7407,  ...,  0.1221,  0.1058,  0.0917],\n",
      "        [-0.9844, -0.9078,  0.7407,  ...,  0.1221,  0.1058,  0.0917],\n",
      "        ...,\n",
      "        [-0.9844, -0.9078,  0.7407,  ...,  0.1221,  0.1058,  0.0917],\n",
      "        [-0.9844, -0.9078,  0.7407,  ...,  0.1221,  0.1058,  0.0917],\n",
      "        [-0.9844, -0.9078,  0.7407,  ...,  0.1221,  0.1058,  0.0917]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9483, -1.0000,  0.4432,  ...,  0.1220,  0.1058,  0.0916],\n",
      "        [-0.9483, -1.0000,  0.4432,  ...,  0.1220,  0.1058,  0.0916],\n",
      "        [-0.9483, -1.0000,  0.4432,  ...,  0.1220,  0.1058,  0.0916],\n",
      "        ...,\n",
      "        [-0.9483, -1.0000,  0.4432,  ...,  0.1220,  0.1058,  0.0916],\n",
      "        [-0.9483, -1.0000,  0.4432,  ...,  0.1220,  0.1058,  0.0916],\n",
      "        [-0.9483, -1.0000,  0.4432,  ...,  0.1220,  0.1058,  0.0916]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6801, -0.9076,  0.0841,  ...,  0.1220,  0.1057,  0.0916],\n",
      "        [-0.6801, -0.9076,  0.0841,  ...,  0.1220,  0.1057,  0.0916],\n",
      "        [-0.6801, -0.9076,  0.0841,  ...,  0.1220,  0.1057,  0.0916],\n",
      "        ...,\n",
      "        [-0.6801, -0.9076,  0.0841,  ...,  0.1220,  0.1057,  0.0916],\n",
      "        [-0.6801, -0.9076,  0.0841,  ...,  0.1220,  0.1057,  0.0916],\n",
      "        [-0.6801, -0.9076,  0.0841,  ...,  0.1220,  0.1057,  0.0916]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2453, -0.6478, -0.2867,  ...,  0.1219,  0.1056,  0.0915],\n",
      "        [-0.2453, -0.6478, -0.2867,  ...,  0.1219,  0.1056,  0.0915],\n",
      "        [-0.2453, -0.6478, -0.2867,  ...,  0.1219,  0.1056,  0.0915],\n",
      "        ...,\n",
      "        [-0.2453, -0.6478, -0.2867,  ...,  0.1219,  0.1056,  0.0915],\n",
      "        [-0.2453, -0.6478, -0.2867,  ...,  0.1219,  0.1056,  0.0915],\n",
      "        [-0.2453, -0.6478, -0.2867,  ...,  0.1219,  0.1056,  0.0915]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2495, -0.2683, -0.6176,  ...,  0.1218,  0.1056,  0.0914],\n",
      "        [ 0.2495, -0.2683, -0.6176,  ...,  0.1218,  0.1056,  0.0914],\n",
      "        [ 0.2495, -0.2683, -0.6176,  ...,  0.1218,  0.1056,  0.0914],\n",
      "        ...,\n",
      "        [ 0.2495, -0.2683, -0.6176,  ...,  0.1218,  0.1056,  0.0914],\n",
      "        [ 0.2495, -0.2683, -0.6176,  ...,  0.1218,  0.1056,  0.0914],\n",
      "        [ 0.2495, -0.2683, -0.6176,  ...,  0.1218,  0.1056,  0.0914]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6832,  0.1606, -0.8627,  ...,  0.1217,  0.1055,  0.0914],\n",
      "        [ 0.6832,  0.1606, -0.8627,  ...,  0.1217,  0.1055,  0.0914],\n",
      "        [ 0.6832,  0.1606, -0.8627,  ...,  0.1217,  0.1055,  0.0914],\n",
      "        ...,\n",
      "        [ 0.6832,  0.1606, -0.8627,  ...,  0.1217,  0.1055,  0.0914],\n",
      "        [ 0.6832,  0.1606, -0.8627,  ...,  0.1217,  0.1055,  0.0914],\n",
      "        [ 0.6832,  0.1606, -0.8627,  ...,  0.1217,  0.1055,  0.0914]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9497,  0.5599, -0.9880,  ...,  0.1217,  0.1054,  0.0913],\n",
      "        [ 0.9497,  0.5599, -0.9880,  ...,  0.1217,  0.1054,  0.0913],\n",
      "        [ 0.9497,  0.5599, -0.9880,  ...,  0.1217,  0.1054,  0.0913],\n",
      "        ...,\n",
      "        [ 0.9497,  0.5599, -0.9880,  ...,  0.1217,  0.1054,  0.0913],\n",
      "        [ 0.9497,  0.5599, -0.9880,  ...,  0.1217,  0.1054,  0.0913],\n",
      "        [ 0.9497,  0.5599, -0.9880,  ...,  0.1217,  0.1054,  0.0913]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9836,  0.8559, -0.9760,  ...,  0.1216,  0.1054,  0.0913],\n",
      "        [ 0.9836,  0.8559, -0.9760,  ...,  0.1216,  0.1054,  0.0913],\n",
      "        [ 0.9836,  0.8559, -0.9760,  ...,  0.1216,  0.1054,  0.0913],\n",
      "        ...,\n",
      "        [ 0.9836,  0.8559, -0.9760,  ...,  0.1216,  0.1054,  0.0913],\n",
      "        [ 0.9836,  0.8559, -0.9760,  ...,  0.1216,  0.1054,  0.0913],\n",
      "        [ 0.9836,  0.8559, -0.9760,  ...,  0.1216,  0.1054,  0.0913]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7767,  0.9939, -0.8283,  ...,  0.1215,  0.1053,  0.0912],\n",
      "        [ 0.7767,  0.9939, -0.8283,  ...,  0.1215,  0.1053,  0.0912],\n",
      "        [ 0.7767,  0.9939, -0.8283,  ...,  0.1215,  0.1053,  0.0912],\n",
      "        ...,\n",
      "        [ 0.7767,  0.9939, -0.8283,  ...,  0.1215,  0.1053,  0.0912],\n",
      "        [ 0.7767,  0.9939, -0.8283,  ...,  0.1215,  0.1053,  0.0912],\n",
      "        [ 0.7767,  0.9939, -0.8283,  ...,  0.1215,  0.1053,  0.0912]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3797,  0.9485, -0.5656,  ...,  0.1214,  0.1052,  0.0912],\n",
      "        [ 0.3797,  0.9485, -0.5656,  ...,  0.1214,  0.1052,  0.0912],\n",
      "        [ 0.3797,  0.9485, -0.5656,  ...,  0.1214,  0.1052,  0.0912],\n",
      "        ...,\n",
      "        [ 0.3797,  0.9485, -0.5656,  ...,  0.1214,  0.1052,  0.0912],\n",
      "        [ 0.3797,  0.9485, -0.5656,  ...,  0.1214,  0.1052,  0.0912],\n",
      "        [ 0.3797,  0.9485, -0.5656,  ...,  0.1214,  0.1052,  0.0912]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1103,  0.7280, -0.2243,  ...,  0.1214,  0.1052,  0.0911],\n",
      "        [-0.1103,  0.7280, -0.2243,  ...,  0.1214,  0.1052,  0.0911],\n",
      "        [-0.1103,  0.7280, -0.2243,  ...,  0.1214,  0.1052,  0.0911],\n",
      "        ...,\n",
      "        [-0.1103,  0.7280, -0.2243,  ...,  0.1214,  0.1052,  0.0911],\n",
      "        [-0.1103,  0.7280, -0.2243,  ...,  0.1214,  0.1052,  0.0911],\n",
      "        [-0.1103,  0.7280, -0.2243,  ...,  0.1214,  0.1052,  0.0911]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5733,  0.3732,  0.1482,  ...,  0.1213,  0.1051,  0.0910],\n",
      "        [-0.5733,  0.3732,  0.1482,  ...,  0.1213,  0.1051,  0.0910],\n",
      "        [-0.5733,  0.3732,  0.1482,  ...,  0.1213,  0.1051,  0.0910],\n",
      "        ...,\n",
      "        [-0.5733,  0.3732,  0.1482,  ...,  0.1213,  0.1051,  0.0910],\n",
      "        [-0.5733,  0.3732,  0.1482,  ...,  0.1213,  0.1051,  0.0910],\n",
      "        [-0.5733,  0.3732,  0.1482,  ...,  0.1213,  0.1051,  0.0910]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8959, -0.0505,  0.5001,  ...,  0.1212,  0.1050,  0.0910],\n",
      "        [-0.8959, -0.0505,  0.5001,  ...,  0.1212,  0.1050,  0.0910],\n",
      "        [-0.8959, -0.0505,  0.5001,  ...,  0.1212,  0.1050,  0.0910],\n",
      "        ...,\n",
      "        [-0.8959, -0.0505,  0.5001,  ...,  0.1212,  0.1050,  0.0910],\n",
      "        [-0.8959, -0.0505,  0.5001,  ...,  0.1212,  0.1050,  0.0910],\n",
      "        [-0.8959, -0.0505,  0.5001,  ...,  0.1212,  0.1050,  0.0910]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9992, -0.4649,  0.7825,  ...,  0.1211,  0.1050,  0.0909],\n",
      "        [-0.9992, -0.4649,  0.7825,  ...,  0.1211,  0.1050,  0.0909],\n",
      "        [-0.9992, -0.4649,  0.7825,  ...,  0.1211,  0.1050,  0.0909],\n",
      "        ...,\n",
      "        [-0.9992, -0.4649,  0.7825,  ...,  0.1211,  0.1050,  0.0909],\n",
      "        [-0.9992, -0.4649,  0.7825,  ...,  0.1211,  0.1050,  0.0909],\n",
      "        [-0.9992, -0.4649,  0.7825,  ...,  0.1211,  0.1050,  0.0909]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8578, -0.7935,  0.9562,  ...,  0.1210,  0.1049,  0.0909],\n",
      "        [-0.8578, -0.7935,  0.9562,  ...,  0.1210,  0.1049,  0.0909],\n",
      "        [-0.8578, -0.7935,  0.9562,  ...,  0.1210,  0.1049,  0.0909],\n",
      "        ...,\n",
      "        [-0.8578, -0.7935,  0.9562,  ...,  0.1210,  0.1049,  0.0909],\n",
      "        [-0.8578, -0.7935,  0.9562,  ...,  0.1210,  0.1049,  0.0909],\n",
      "        [-0.8578, -0.7935,  0.9562,  ...,  0.1210,  0.1049,  0.0909]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5064, -0.9756,  0.9970,  ...,  0.1210,  0.1048,  0.0908],\n",
      "        [-0.5064, -0.9756,  0.9970,  ...,  0.1210,  0.1048,  0.0908],\n",
      "        [-0.5064, -0.9756,  0.9970,  ...,  0.1210,  0.1048,  0.0908],\n",
      "        ...,\n",
      "        [-0.5064, -0.9756,  0.9970,  ...,  0.1210,  0.1048,  0.0908],\n",
      "        [-0.5064, -0.9756,  0.9970,  ...,  0.1210,  0.1048,  0.0908],\n",
      "        [-0.5064, -0.9756,  0.9970,  ...,  0.1210,  0.1048,  0.0908]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0310, -0.9777,  0.8993,  ...,  0.1209,  0.1048,  0.0908],\n",
      "        [-0.0310, -0.9777,  0.8993,  ...,  0.1209,  0.1048,  0.0908],\n",
      "        [-0.0310, -0.9777,  0.8993,  ...,  0.1209,  0.1048,  0.0908],\n",
      "        ...,\n",
      "        [-0.0310, -0.9777,  0.8993,  ...,  0.1209,  0.1048,  0.0908],\n",
      "        [-0.0310, -0.9777,  0.8993,  ...,  0.1209,  0.1048,  0.0908],\n",
      "        [-0.0310, -0.9777,  0.8993,  ...,  0.1209,  0.1048,  0.0908]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4520, -0.7993,  0.6766,  ...,  0.1208,  0.1047,  0.0907],\n",
      "        [ 0.4520, -0.7993,  0.6766,  ...,  0.1208,  0.1047,  0.0907],\n",
      "        [ 0.4520, -0.7993,  0.6766,  ...,  0.1208,  0.1047,  0.0907],\n",
      "        ...,\n",
      "        [ 0.4520, -0.7993,  0.6766,  ...,  0.1208,  0.1047,  0.0907],\n",
      "        [ 0.4520, -0.7993,  0.6766,  ...,  0.1208,  0.1047,  0.0907],\n",
      "        [ 0.4520, -0.7993,  0.6766,  ...,  0.1208,  0.1047,  0.0907]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8243, -0.4734,  0.3600,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.8243, -0.4734,  0.3600,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.8243, -0.4734,  0.3600,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        ...,\n",
      "        [ 0.8243, -0.4734,  0.3600,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.8243, -0.4734,  0.3600,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.8243, -0.4734,  0.3600,  ...,  0.1207,  0.1046,  0.0906]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9948, -0.0601, -0.0068,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.9948, -0.0601, -0.0068,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.9948, -0.0601, -0.0068,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        ...,\n",
      "        [ 0.9948, -0.0601, -0.0068,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.9948, -0.0601, -0.0068,  ...,  0.1207,  0.1046,  0.0906],\n",
      "        [ 0.9948, -0.0601, -0.0068,  ...,  0.1207,  0.1046,  0.0906]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9218,  0.3642, -0.3725,  ...,  0.1206,  0.1045,  0.0905],\n",
      "        [ 0.9218,  0.3642, -0.3725,  ...,  0.1206,  0.1045,  0.0905],\n",
      "        [ 0.9218,  0.3642, -0.3725,  ...,  0.1206,  0.1045,  0.0905],\n",
      "        ...,\n",
      "        [ 0.9218,  0.3642, -0.3725,  ...,  0.1206,  0.1045,  0.0905],\n",
      "        [ 0.9218,  0.3642, -0.3725,  ...,  0.1206,  0.1045,  0.0905],\n",
      "        [ 0.9218,  0.3642, -0.3725,  ...,  0.1206,  0.1045,  0.0905]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6230,  0.7214, -0.6865,  ...,  0.1205,  0.1044,  0.0905],\n",
      "        [ 0.6230,  0.7214, -0.6865,  ...,  0.1205,  0.1044,  0.0905],\n",
      "        [ 0.6230,  0.7214, -0.6865,  ...,  0.1205,  0.1044,  0.0905],\n",
      "        ...,\n",
      "        [ 0.6230,  0.7214, -0.6865,  ...,  0.1205,  0.1044,  0.0905],\n",
      "        [ 0.6230,  0.7214, -0.6865,  ...,  0.1205,  0.1044,  0.0905],\n",
      "        [ 0.6230,  0.7214, -0.6865,  ...,  0.1205,  0.1044,  0.0905]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1718,  0.9454, -0.9051,  ...,  0.1204,  0.1044,  0.0904],\n",
      "        [ 0.1718,  0.9454, -0.9051,  ...,  0.1204,  0.1044,  0.0904],\n",
      "        [ 0.1718,  0.9454, -0.9051,  ...,  0.1204,  0.1044,  0.0904],\n",
      "        ...,\n",
      "        [ 0.1718,  0.9454, -0.9051,  ...,  0.1204,  0.1044,  0.0904],\n",
      "        [ 0.1718,  0.9454, -0.9051,  ...,  0.1204,  0.1044,  0.0904],\n",
      "        [ 0.1718,  0.9454, -0.9051,  ...,  0.1204,  0.1044,  0.0904]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3216,  0.9949, -0.9979,  ...,  0.1204,  0.1043,  0.0904],\n",
      "        [-0.3216,  0.9949, -0.9979,  ...,  0.1204,  0.1043,  0.0904],\n",
      "        [-0.3216,  0.9949, -0.9979,  ...,  0.1204,  0.1043,  0.0904],\n",
      "        ...,\n",
      "        [-0.3216,  0.9949, -0.9979,  ...,  0.1204,  0.1043,  0.0904],\n",
      "        [-0.3216,  0.9949, -0.9979,  ...,  0.1204,  0.1043,  0.0904],\n",
      "        [-0.3216,  0.9949, -0.9979,  ...,  0.1204,  0.1043,  0.0904]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7362,  0.8608, -0.9521,  ...,  0.1203,  0.1042,  0.0903],\n",
      "        [-0.7362,  0.8608, -0.9521,  ...,  0.1203,  0.1042,  0.0903],\n",
      "        [-0.7362,  0.8608, -0.9521,  ...,  0.1203,  0.1042,  0.0903],\n",
      "        ...,\n",
      "        [-0.7362,  0.8608, -0.9521,  ...,  0.1203,  0.1042,  0.0903],\n",
      "        [-0.7362,  0.8608, -0.9521,  ...,  0.1203,  0.1042,  0.0903],\n",
      "        [-0.7362,  0.8608, -0.9521,  ...,  0.1203,  0.1042,  0.0903]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9705,  0.5678, -0.7740,  ...,  0.1202,  0.1042,  0.0902],\n",
      "        [-0.9705,  0.5678, -0.7740,  ...,  0.1202,  0.1042,  0.0902],\n",
      "        [-0.9705,  0.5678, -0.7740,  ...,  0.1202,  0.1042,  0.0902],\n",
      "        ...,\n",
      "        [-0.9705,  0.5678, -0.7740,  ...,  0.1202,  0.1042,  0.0902],\n",
      "        [-0.9705,  0.5678, -0.7740,  ...,  0.1202,  0.1042,  0.0902],\n",
      "        [-0.9705,  0.5678, -0.7740,  ...,  0.1202,  0.1042,  0.0902]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9673,  0.1700, -0.4884,  ...,  0.1201,  0.1041,  0.0902],\n",
      "        [-0.9673,  0.1700, -0.4884,  ...,  0.1201,  0.1041,  0.0902],\n",
      "        [-0.9673,  0.1700, -0.4884,  ...,  0.1201,  0.1041,  0.0902],\n",
      "        ...,\n",
      "        [-0.9673,  0.1700, -0.4884,  ...,  0.1201,  0.1041,  0.0902],\n",
      "        [-0.9673,  0.1700, -0.4884,  ...,  0.1201,  0.1041,  0.0902],\n",
      "        [-0.9673,  0.1700, -0.4884,  ...,  0.1201,  0.1041,  0.0902]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7272, -0.2591, -0.1349,  ...,  0.1201,  0.1040,  0.0901],\n",
      "        [-0.7272, -0.2591, -0.1349,  ...,  0.1201,  0.1040,  0.0901],\n",
      "        [-0.7272, -0.2591, -0.1349,  ...,  0.1201,  0.1040,  0.0901],\n",
      "        ...,\n",
      "        [-0.7272, -0.2591, -0.1349,  ...,  0.1201,  0.1040,  0.0901],\n",
      "        [-0.7272, -0.2591, -0.1349,  ...,  0.1201,  0.1040,  0.0901],\n",
      "        [-0.7272, -0.2591, -0.1349,  ...,  0.1201,  0.1040,  0.0901]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3091, -0.6405,  0.2374,  ...,  0.1200,  0.1040,  0.0901],\n",
      "        [-0.3091, -0.6405,  0.2374,  ...,  0.1200,  0.1040,  0.0901],\n",
      "        [-0.3091, -0.6405,  0.2374,  ...,  0.1200,  0.1040,  0.0901],\n",
      "        ...,\n",
      "        [-0.3091, -0.6405,  0.2374,  ...,  0.1200,  0.1040,  0.0901],\n",
      "        [-0.3091, -0.6405,  0.2374,  ...,  0.1200,  0.1040,  0.0901],\n",
      "        [-0.3091, -0.6405,  0.2374,  ...,  0.1200,  0.1040,  0.0901]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1847, -0.9036,  0.5766,  ...,  0.1199,  0.1039,  0.0900],\n",
      "        [ 0.1847, -0.9036,  0.5766,  ...,  0.1199,  0.1039,  0.0900],\n",
      "        [ 0.1847, -0.9036,  0.5766,  ...,  0.1199,  0.1039,  0.0900],\n",
      "        ...,\n",
      "        [ 0.1847, -0.9036,  0.5766,  ...,  0.1199,  0.1039,  0.0900],\n",
      "        [ 0.1847, -0.9036,  0.5766,  ...,  0.1199,  0.1039,  0.0900],\n",
      "        [ 0.1847, -0.9036,  0.5766,  ...,  0.1199,  0.1039,  0.0900]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6333, -1.0000,  0.8358,  ...,  0.1198,  0.1038,  0.0900],\n",
      "        [ 0.6333, -1.0000,  0.8358,  ...,  0.1198,  0.1038,  0.0900],\n",
      "        [ 0.6333, -1.0000,  0.8358,  ...,  0.1198,  0.1038,  0.0900],\n",
      "        ...,\n",
      "        [ 0.6333, -1.0000,  0.8358,  ...,  0.1198,  0.1038,  0.0900],\n",
      "        [ 0.6333, -1.0000,  0.8358,  ...,  0.1198,  0.1038,  0.0900],\n",
      "        [ 0.6333, -1.0000,  0.8358,  ...,  0.1198,  0.1038,  0.0900]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9268, -0.9118,  0.9788,  ...,  0.1197,  0.1038,  0.0899],\n",
      "        [ 0.9268, -0.9118,  0.9788,  ...,  0.1197,  0.1038,  0.0899],\n",
      "        [ 0.9268, -0.9118,  0.9788,  ...,  0.1197,  0.1038,  0.0899],\n",
      "        ...,\n",
      "        [ 0.9268, -0.9118,  0.9788,  ...,  0.1197,  0.1038,  0.0899],\n",
      "        [ 0.9268, -0.9118,  0.9788,  ...,  0.1197,  0.1038,  0.0899],\n",
      "        [ 0.9268, -0.9118,  0.9788,  ...,  0.1197,  0.1038,  0.0899]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9934, -0.6553,  0.9858,  ...,  0.1197,  0.1037,  0.0898],\n",
      "        [ 0.9934, -0.6553,  0.9858,  ...,  0.1197,  0.1037,  0.0898],\n",
      "        [ 0.9934, -0.6553,  0.9858,  ...,  0.1197,  0.1037,  0.0898],\n",
      "        ...,\n",
      "        [ 0.9934, -0.6553,  0.9858,  ...,  0.1197,  0.1037,  0.0898],\n",
      "        [ 0.9934, -0.6553,  0.9858,  ...,  0.1197,  0.1037,  0.0898],\n",
      "        [ 0.9934, -0.6553,  0.9858,  ...,  0.1197,  0.1037,  0.0898]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8168, -0.2779,  0.8559,  ...,  0.1196,  0.1036,  0.0898],\n",
      "        [ 0.8168, -0.2779,  0.8559,  ...,  0.1196,  0.1036,  0.0898],\n",
      "        [ 0.8168, -0.2779,  0.8559,  ...,  0.1196,  0.1036,  0.0898],\n",
      "        ...,\n",
      "        [ 0.8168, -0.2779,  0.8559,  ...,  0.1196,  0.1036,  0.0898],\n",
      "        [ 0.8168, -0.2779,  0.8559,  ...,  0.1196,  0.1036,  0.0898],\n",
      "        [ 0.8168, -0.2779,  0.8559,  ...,  0.1196,  0.1036,  0.0898]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.4402, 0.1508, 0.6070,  ..., 0.1195, 0.1036, 0.0897],\n",
      "        [0.4402, 0.1508, 0.6070,  ..., 0.1195, 0.1036, 0.0897],\n",
      "        [0.4402, 0.1508, 0.6070,  ..., 0.1195, 0.1036, 0.0897],\n",
      "        ...,\n",
      "        [0.4402, 0.1508, 0.6070,  ..., 0.1195, 0.1036, 0.0897],\n",
      "        [0.4402, 0.1508, 0.6070,  ..., 0.1195, 0.1036, 0.0897],\n",
      "        [0.4402, 0.1508, 0.6070,  ..., 0.1195, 0.1036, 0.0897]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0442,  0.5517,  0.2737,  ...,  0.1194,  0.1035,  0.0897],\n",
      "        [-0.0442,  0.5517,  0.2737,  ...,  0.1194,  0.1035,  0.0897],\n",
      "        [-0.0442,  0.5517,  0.2737,  ...,  0.1194,  0.1035,  0.0897],\n",
      "        ...,\n",
      "        [-0.0442,  0.5517,  0.2737,  ...,  0.1194,  0.1035,  0.0897],\n",
      "        [-0.0442,  0.5517,  0.2737,  ...,  0.1194,  0.1035,  0.0897],\n",
      "        [-0.0442,  0.5517,  0.2737,  ...,  0.1194,  0.1035,  0.0897]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5177,  0.8507, -0.0975,  ...,  0.1194,  0.1034,  0.0896],\n",
      "        [-0.5177,  0.8507, -0.0975,  ...,  0.1194,  0.1034,  0.0896],\n",
      "        [-0.5177,  0.8507, -0.0975,  ...,  0.1194,  0.1034,  0.0896],\n",
      "        ...,\n",
      "        [-0.5177,  0.8507, -0.0975,  ...,  0.1194,  0.1034,  0.0896],\n",
      "        [-0.5177,  0.8507, -0.0975,  ...,  0.1194,  0.1034,  0.0896],\n",
      "        [-0.5177,  0.8507, -0.0975,  ...,  0.1194,  0.1034,  0.0896]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8645,  0.9928, -0.4552,  ...,  0.1193,  0.1034,  0.0895],\n",
      "        [-0.8645,  0.9928, -0.4552,  ...,  0.1193,  0.1034,  0.0895],\n",
      "        [-0.8645,  0.9928, -0.4552,  ...,  0.1193,  0.1034,  0.0895],\n",
      "        ...,\n",
      "        [-0.8645,  0.9928, -0.4552,  ...,  0.1193,  0.1034,  0.0895],\n",
      "        [-0.8645,  0.9928, -0.4552,  ...,  0.1193,  0.1034,  0.0895],\n",
      "        [-0.8645,  0.9928, -0.4552,  ...,  0.1193,  0.1034,  0.0895]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9996,  0.9516, -0.7496,  ...,  0.1192,  0.1033,  0.0895],\n",
      "        [-0.9996,  0.9516, -0.7496,  ...,  0.1192,  0.1033,  0.0895],\n",
      "        [-0.9996,  0.9516, -0.7496,  ...,  0.1192,  0.1033,  0.0895],\n",
      "        ...,\n",
      "        [-0.9996,  0.9516, -0.7496,  ...,  0.1192,  0.1033,  0.0895],\n",
      "        [-0.9996,  0.9516, -0.7496,  ...,  0.1192,  0.1033,  0.0895],\n",
      "        [-0.9996,  0.9516, -0.7496,  ...,  0.1192,  0.1033,  0.0895]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8900,  0.7347, -0.9399,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.8900,  0.7347, -0.9399,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.8900,  0.7347, -0.9399,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        ...,\n",
      "        [-0.8900,  0.7347, -0.9399,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.8900,  0.7347, -0.9399,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.8900,  0.7347, -0.9399,  ...,  0.1191,  0.1032,  0.0894]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5625,  0.3823, -0.9996,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.5625,  0.3823, -0.9996,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.5625,  0.3823, -0.9996,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        ...,\n",
      "        [-0.5625,  0.3823, -0.9996,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.5625,  0.3823, -0.9996,  ...,  0.1191,  0.1032,  0.0894],\n",
      "        [-0.5625,  0.3823, -0.9996,  ...,  0.1191,  0.1032,  0.0894]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0973, -0.0407, -0.9204,  ...,  0.1190,  0.1031,  0.0893],\n",
      "        [-0.0973, -0.0407, -0.9204,  ...,  0.1190,  0.1031,  0.0893],\n",
      "        [-0.0973, -0.0407, -0.9204,  ...,  0.1190,  0.1031,  0.0893],\n",
      "        ...,\n",
      "        [-0.0973, -0.0407, -0.9204,  ...,  0.1190,  0.1031,  0.0893],\n",
      "        [-0.0973, -0.0407, -0.9204,  ...,  0.1190,  0.1031,  0.0893],\n",
      "        [-0.0973, -0.0407, -0.9204,  ...,  0.1190,  0.1031,  0.0893]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3918, -0.4562, -0.7133,  ...,  0.1189,  0.1030,  0.0893],\n",
      "        [ 0.3918, -0.4562, -0.7133,  ...,  0.1189,  0.1030,  0.0893],\n",
      "        [ 0.3918, -0.4562, -0.7133,  ...,  0.1189,  0.1030,  0.0893],\n",
      "        ...,\n",
      "        [ 0.3918, -0.4562, -0.7133,  ...,  0.1189,  0.1030,  0.0893],\n",
      "        [ 0.3918, -0.4562, -0.7133,  ...,  0.1189,  0.1030,  0.0893],\n",
      "        [ 0.3918, -0.4562, -0.7133,  ...,  0.1189,  0.1030,  0.0893]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7849, -0.7875, -0.4071,  ...,  0.1188,  0.1030,  0.0892],\n",
      "        [ 0.7849, -0.7875, -0.4071,  ...,  0.1188,  0.1030,  0.0892],\n",
      "        [ 0.7849, -0.7875, -0.4071,  ...,  0.1188,  0.1030,  0.0892],\n",
      "        ...,\n",
      "        [ 0.7849, -0.7875, -0.4071,  ...,  0.1188,  0.1030,  0.0892],\n",
      "        [ 0.7849, -0.7875, -0.4071,  ...,  0.1188,  0.1030,  0.0892],\n",
      "        [ 0.7849, -0.7875, -0.4071,  ...,  0.1188,  0.1030,  0.0892]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9859, -0.9734, -0.0444,  ...,  0.1188,  0.1029,  0.0891],\n",
      "        [ 0.9859, -0.9734, -0.0444,  ...,  0.1188,  0.1029,  0.0891],\n",
      "        [ 0.9859, -0.9734, -0.0444,  ...,  0.1188,  0.1029,  0.0891],\n",
      "        ...,\n",
      "        [ 0.9859, -0.9734, -0.0444,  ...,  0.1188,  0.1029,  0.0891],\n",
      "        [ 0.9859, -0.9734, -0.0444,  ...,  0.1188,  0.1029,  0.0891],\n",
      "        [ 0.9859, -0.9734, -0.0444,  ...,  0.1188,  0.1029,  0.0891]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9455, -0.9797,  0.3246,  ...,  0.1187,  0.1028,  0.0891],\n",
      "        [ 0.9455, -0.9797,  0.3246,  ...,  0.1187,  0.1028,  0.0891],\n",
      "        [ 0.9455, -0.9797,  0.3246,  ...,  0.1187,  0.1028,  0.0891],\n",
      "        ...,\n",
      "        [ 0.9455, -0.9797,  0.3246,  ...,  0.1187,  0.1028,  0.0891],\n",
      "        [ 0.9455, -0.9797,  0.3246,  ...,  0.1187,  0.1028,  0.0891],\n",
      "        [ 0.9455, -0.9797,  0.3246,  ...,  0.1187,  0.1028,  0.0891]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6736, -0.8052,  0.6484,  ...,  0.1186,  0.1028,  0.0890],\n",
      "        [ 0.6736, -0.8052,  0.6484,  ...,  0.1186,  0.1028,  0.0890],\n",
      "        [ 0.6736, -0.8052,  0.6484,  ...,  0.1186,  0.1028,  0.0890],\n",
      "        ...,\n",
      "        [ 0.6736, -0.8052,  0.6484,  ...,  0.1186,  0.1028,  0.0890],\n",
      "        [ 0.6736, -0.8052,  0.6484,  ...,  0.1186,  0.1028,  0.0890],\n",
      "        [ 0.6736, -0.8052,  0.6484,  ...,  0.1186,  0.1028,  0.0890]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2367, -0.4820,  0.8822,  ...,  0.1185,  0.1027,  0.0890],\n",
      "        [ 0.2367, -0.4820,  0.8822,  ...,  0.1185,  0.1027,  0.0890],\n",
      "        [ 0.2367, -0.4820,  0.8822,  ...,  0.1185,  0.1027,  0.0890],\n",
      "        ...,\n",
      "        [ 0.2367, -0.4820,  0.8822,  ...,  0.1185,  0.1027,  0.0890],\n",
      "        [ 0.2367, -0.4820,  0.8822,  ...,  0.1185,  0.1027,  0.0890],\n",
      "        [ 0.2367, -0.4820,  0.8822,  ...,  0.1185,  0.1027,  0.0890]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2580, -0.0700,  0.9933,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.2580, -0.0700,  0.9933,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.2580, -0.0700,  0.9933,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        ...,\n",
      "        [-0.2580, -0.0700,  0.9933,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.2580, -0.0700,  0.9933,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.2580, -0.0700,  0.9933,  ...,  0.1184,  0.1026,  0.0889]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6896,  0.3551,  0.9665,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.6896,  0.3551,  0.9665,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.6896,  0.3551,  0.9665,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        ...,\n",
      "        [-0.6896,  0.3551,  0.9665,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.6896,  0.3551,  0.9665,  ...,  0.1184,  0.1026,  0.0889],\n",
      "        [-0.6896,  0.3551,  0.9665,  ...,  0.1184,  0.1026,  0.0889]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9524,  0.7145,  0.8054,  ...,  0.1183,  0.1025,  0.0888],\n",
      "        [-0.9524,  0.7145,  0.8054,  ...,  0.1183,  0.1025,  0.0888],\n",
      "        [-0.9524,  0.7145,  0.8054,  ...,  0.1183,  0.1025,  0.0888],\n",
      "        ...,\n",
      "        [-0.9524,  0.7145,  0.8054,  ...,  0.1183,  0.1025,  0.0888],\n",
      "        [-0.9524,  0.7145,  0.8054,  ...,  0.1183,  0.1025,  0.0888],\n",
      "        [-0.9524,  0.7145,  0.8054,  ...,  0.1183,  0.1025,  0.0888]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9820,  0.9421,  0.5323,  ...,  0.1182,  0.1024,  0.0887],\n",
      "        [-0.9820,  0.9421,  0.5323,  ...,  0.1182,  0.1024,  0.0887],\n",
      "        [-0.9820,  0.9421,  0.5323,  ...,  0.1182,  0.1024,  0.0887],\n",
      "        ...,\n",
      "        [-0.9820,  0.9421,  0.5323,  ...,  0.1182,  0.1024,  0.0887],\n",
      "        [-0.9820,  0.9421,  0.5323,  ...,  0.1182,  0.1024,  0.0887],\n",
      "        [-0.9820,  0.9421,  0.5323,  ...,  0.1182,  0.1024,  0.0887]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7711,  0.9959,  0.1853,  ...,  0.1181,  0.1024,  0.0887],\n",
      "        [-0.7711,  0.9959,  0.1853,  ...,  0.1181,  0.1024,  0.0887],\n",
      "        [-0.7711,  0.9959,  0.1853,  ...,  0.1181,  0.1024,  0.0887],\n",
      "        ...,\n",
      "        [-0.7711,  0.9959,  0.1853,  ...,  0.1181,  0.1024,  0.0887],\n",
      "        [-0.7711,  0.9959,  0.1853,  ...,  0.1181,  0.1024,  0.0887],\n",
      "        [-0.7711,  0.9959,  0.1853,  ...,  0.1181,  0.1024,  0.0887]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3715,  0.8658, -0.1874,  ...,  0.1181,  0.1023,  0.0886],\n",
      "        [-0.3715,  0.8658, -0.1874,  ...,  0.1181,  0.1023,  0.0886],\n",
      "        [-0.3715,  0.8658, -0.1874,  ...,  0.1181,  0.1023,  0.0886],\n",
      "        ...,\n",
      "        [-0.3715,  0.8658, -0.1874,  ...,  0.1181,  0.1023,  0.0886],\n",
      "        [-0.3715,  0.8658, -0.1874,  ...,  0.1181,  0.1023,  0.0886],\n",
      "        [-0.3715,  0.8658, -0.1874,  ...,  0.1181,  0.1023,  0.0886]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1191,  0.5759, -0.5341,  ...,  0.1180,  0.1022,  0.0886],\n",
      "        [ 0.1191,  0.5759, -0.5341,  ...,  0.1180,  0.1022,  0.0886],\n",
      "        [ 0.1191,  0.5759, -0.5341,  ...,  0.1180,  0.1022,  0.0886],\n",
      "        ...,\n",
      "        [ 0.1191,  0.5759, -0.5341,  ...,  0.1180,  0.1022,  0.0886],\n",
      "        [ 0.1191,  0.5759, -0.5341,  ...,  0.1180,  0.1022,  0.0886],\n",
      "        [ 0.1191,  0.5759, -0.5341,  ...,  0.1180,  0.1022,  0.0886]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.5805,  0.1798, -0.8066,  ...,  0.1179,  0.1022,  0.0885],\n",
      "        [ 0.5805,  0.1798, -0.8066,  ...,  0.1179,  0.1022,  0.0885],\n",
      "        [ 0.5805,  0.1798, -0.8066,  ...,  0.1179,  0.1022,  0.0885],\n",
      "        ...,\n",
      "        [ 0.5805,  0.1798, -0.8066,  ...,  0.1179,  0.1022,  0.0885],\n",
      "        [ 0.5805,  0.1798, -0.8066,  ...,  0.1179,  0.1022,  0.0885],\n",
      "        [ 0.5805,  0.1798, -0.8066,  ...,  0.1179,  0.1022,  0.0885]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8998, -0.2495, -0.9671,  ...,  0.1178,  0.1021,  0.0885],\n",
      "        [ 0.8998, -0.2495, -0.9671,  ...,  0.1178,  0.1021,  0.0885],\n",
      "        [ 0.8998, -0.2495, -0.9671,  ...,  0.1178,  0.1021,  0.0885],\n",
      "        ...,\n",
      "        [ 0.8998, -0.2495, -0.9671,  ...,  0.1178,  0.1021,  0.0885],\n",
      "        [ 0.8998, -0.2495, -0.9671,  ...,  0.1178,  0.1021,  0.0885],\n",
      "        [ 0.8998, -0.2495, -0.9671,  ...,  0.1178,  0.1021,  0.0885]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9988, -0.6328, -0.9931,  ...,  0.1178,  0.1020,  0.0884],\n",
      "        [ 0.9988, -0.6328, -0.9931,  ...,  0.1178,  0.1020,  0.0884],\n",
      "        [ 0.9988, -0.6328, -0.9931,  ...,  0.1178,  0.1020,  0.0884],\n",
      "        ...,\n",
      "        [ 0.9988, -0.6328, -0.9931,  ...,  0.1178,  0.1020,  0.0884],\n",
      "        [ 0.9988, -0.6328, -0.9931,  ...,  0.1178,  0.1020,  0.0884],\n",
      "        [ 0.9988, -0.6328, -0.9931,  ...,  0.1178,  0.1020,  0.0884]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8533, -0.8993, -0.8811,  ...,  0.1177,  0.1020,  0.0883],\n",
      "        [ 0.8533, -0.8993, -0.8811,  ...,  0.1177,  0.1020,  0.0883],\n",
      "        [ 0.8533, -0.8993, -0.8811,  ...,  0.1177,  0.1020,  0.0883],\n",
      "        ...,\n",
      "        [ 0.8533, -0.8993, -0.8811,  ...,  0.1177,  0.1020,  0.0883],\n",
      "        [ 0.8533, -0.8993, -0.8811,  ...,  0.1177,  0.1020,  0.0883],\n",
      "        [ 0.8533, -0.8993, -0.8811,  ...,  0.1177,  0.1020,  0.0883]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4988, -0.9998, -0.6468,  ...,  0.1176,  0.1019,  0.0883],\n",
      "        [ 0.4988, -0.9998, -0.6468,  ...,  0.1176,  0.1019,  0.0883],\n",
      "        [ 0.4988, -0.9998, -0.6468,  ...,  0.1176,  0.1019,  0.0883],\n",
      "        ...,\n",
      "        [ 0.4988, -0.9998, -0.6468,  ...,  0.1176,  0.1019,  0.0883],\n",
      "        [ 0.4988, -0.9998, -0.6468,  ...,  0.1176,  0.1019,  0.0883],\n",
      "        [ 0.4988, -0.9998, -0.6468,  ...,  0.1176,  0.1019,  0.0883]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0222, -0.9158, -0.3225,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [ 0.0222, -0.9158, -0.3225,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [ 0.0222, -0.9158, -0.3225,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        ...,\n",
      "        [ 0.0222, -0.9158, -0.3225,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [ 0.0222, -0.9158, -0.3225,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [ 0.0222, -0.9158, -0.3225,  ...,  0.1175,  0.1018,  0.0882]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4598, -0.6627,  0.0465,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [-0.4598, -0.6627,  0.0465,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [-0.4598, -0.6627,  0.0465,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        ...,\n",
      "        [-0.4598, -0.6627,  0.0465,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [-0.4598, -0.6627,  0.0465,  ...,  0.1175,  0.1018,  0.0882],\n",
      "        [-0.4598, -0.6627,  0.0465,  ...,  0.1175,  0.1018,  0.0882]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8293, -0.2874,  0.4091,  ...,  0.1174,  0.1017,  0.0881],\n",
      "        [-0.8293, -0.2874,  0.4091,  ...,  0.1174,  0.1017,  0.0881],\n",
      "        [-0.8293, -0.2874,  0.4091,  ...,  0.1174,  0.1017,  0.0881],\n",
      "        ...,\n",
      "        [-0.8293, -0.2874,  0.4091,  ...,  0.1174,  0.1017,  0.0881],\n",
      "        [-0.8293, -0.2874,  0.4091,  ...,  0.1174,  0.1017,  0.0881],\n",
      "        [-0.8293, -0.2874,  0.4091,  ...,  0.1174,  0.1017,  0.0881]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9957,  0.1410,  0.7148,  ...,  0.1173,  0.1016,  0.0881],\n",
      "        [-0.9957,  0.1410,  0.7148,  ...,  0.1173,  0.1016,  0.0881],\n",
      "        [-0.9957,  0.1410,  0.7148,  ...,  0.1173,  0.1016,  0.0881],\n",
      "        ...,\n",
      "        [-0.9957,  0.1410,  0.7148,  ...,  0.1173,  0.1016,  0.0881],\n",
      "        [-0.9957,  0.1410,  0.7148,  ...,  0.1173,  0.1016,  0.0881],\n",
      "        [-0.9957,  0.1410,  0.7148,  ...,  0.1173,  0.1016,  0.0881]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9183,  0.5434,  0.9213,  ...,  0.1172,  0.1016,  0.0880],\n",
      "        [-0.9183,  0.5434,  0.9213,  ...,  0.1172,  0.1016,  0.0880],\n",
      "        [-0.9183,  0.5434,  0.9213,  ...,  0.1172,  0.1016,  0.0880],\n",
      "        ...,\n",
      "        [-0.9183,  0.5434,  0.9213,  ...,  0.1172,  0.1016,  0.0880],\n",
      "        [-0.9183,  0.5434,  0.9213,  ...,  0.1172,  0.1016,  0.0880],\n",
      "        [-0.9183,  0.5434,  0.9213,  ...,  0.1172,  0.1016,  0.0880]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6161,  0.8455,  0.9997,  ...,  0.1171,  0.1015,  0.0879],\n",
      "        [-0.6161,  0.8455,  0.9997,  ...,  0.1171,  0.1015,  0.0879],\n",
      "        [-0.6161,  0.8455,  0.9997,  ...,  0.1171,  0.1015,  0.0879],\n",
      "        ...,\n",
      "        [-0.6161,  0.8455,  0.9997,  ...,  0.1171,  0.1015,  0.0879],\n",
      "        [-0.6161,  0.8455,  0.9997,  ...,  0.1171,  0.1015,  0.0879],\n",
      "        [-0.6161,  0.8455,  0.9997,  ...,  0.1171,  0.1015,  0.0879]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1631,  0.9915,  0.9392,  ...,  0.1171,  0.1014,  0.0879],\n",
      "        [-0.1631,  0.9915,  0.9392,  ...,  0.1171,  0.1014,  0.0879],\n",
      "        [-0.1631,  0.9915,  0.9392,  ...,  0.1171,  0.1014,  0.0879],\n",
      "        ...,\n",
      "        [-0.1631,  0.9915,  0.9392,  ...,  0.1171,  0.1014,  0.0879],\n",
      "        [-0.1631,  0.9915,  0.9392,  ...,  0.1171,  0.1014,  0.0879],\n",
      "        [-0.1631,  0.9915,  0.9392,  ...,  0.1171,  0.1014,  0.0879]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.3299, 0.9546, 0.7482,  ..., 0.1170, 0.1014, 0.0878],\n",
      "        [0.3299, 0.9546, 0.7482,  ..., 0.1170, 0.1014, 0.0878],\n",
      "        [0.3299, 0.9546, 0.7482,  ..., 0.1170, 0.1014, 0.0878],\n",
      "        ...,\n",
      "        [0.3299, 0.9546, 0.7482,  ..., 0.1170, 0.1014, 0.0878],\n",
      "        [0.3299, 0.9546, 0.7482,  ..., 0.1170, 0.1014, 0.0878],\n",
      "        [0.3299, 0.9546, 0.7482,  ..., 0.1170, 0.1014, 0.0878]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.7421, 0.7414, 0.4533,  ..., 0.1169, 0.1013, 0.0878],\n",
      "        [0.7421, 0.7414, 0.4533,  ..., 0.1169, 0.1013, 0.0878],\n",
      "        [0.7421, 0.7414, 0.4533,  ..., 0.1169, 0.1013, 0.0878],\n",
      "        ...,\n",
      "        [0.7421, 0.7414, 0.4533,  ..., 0.1169, 0.1013, 0.0878],\n",
      "        [0.7421, 0.7414, 0.4533,  ..., 0.1169, 0.1013, 0.0878],\n",
      "        [0.7421, 0.7414, 0.4533,  ..., 0.1169, 0.1013, 0.0878]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9726, 0.3914, 0.0953,  ..., 0.1168, 0.1012, 0.0877],\n",
      "        [0.9726, 0.3914, 0.0953,  ..., 0.1168, 0.1012, 0.0877],\n",
      "        [0.9726, 0.3914, 0.0953,  ..., 0.1168, 0.1012, 0.0877],\n",
      "        ...,\n",
      "        [0.9726, 0.3914, 0.0953,  ..., 0.1168, 0.1012, 0.0877],\n",
      "        [0.9726, 0.3914, 0.0953,  ..., 0.1168, 0.1012, 0.0877],\n",
      "        [0.9726, 0.3914, 0.0953,  ..., 0.1168, 0.1012, 0.0877]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9650, -0.0308, -0.2758,  ...,  0.1168,  0.1012,  0.0877],\n",
      "        [ 0.9650, -0.0308, -0.2758,  ...,  0.1168,  0.1012,  0.0877],\n",
      "        [ 0.9650, -0.0308, -0.2758,  ...,  0.1168,  0.1012,  0.0877],\n",
      "        ...,\n",
      "        [ 0.9650, -0.0308, -0.2758,  ...,  0.1168,  0.1012,  0.0877],\n",
      "        [ 0.9650, -0.0308, -0.2758,  ...,  0.1168,  0.1012,  0.0877],\n",
      "        [ 0.9650, -0.0308, -0.2758,  ...,  0.1168,  0.1012,  0.0877]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7211, -0.4473, -0.6087,  ...,  0.1167,  0.1011,  0.0876],\n",
      "        [ 0.7211, -0.4473, -0.6087,  ...,  0.1167,  0.1011,  0.0876],\n",
      "        [ 0.7211, -0.4473, -0.6087,  ...,  0.1167,  0.1011,  0.0876],\n",
      "        ...,\n",
      "        [ 0.7211, -0.4473, -0.6087,  ...,  0.1167,  0.1011,  0.0876],\n",
      "        [ 0.7211, -0.4473, -0.6087,  ...,  0.1167,  0.1011,  0.0876],\n",
      "        [ 0.7211, -0.4473, -0.6087,  ...,  0.1167,  0.1011,  0.0876]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.3007, -0.7813, -0.8570,  ...,  0.1166,  0.1010,  0.0875],\n",
      "        [ 0.3007, -0.7813, -0.8570,  ...,  0.1166,  0.1010,  0.0875],\n",
      "        [ 0.3007, -0.7813, -0.8570,  ...,  0.1166,  0.1010,  0.0875],\n",
      "        ...,\n",
      "        [ 0.3007, -0.7813, -0.8570,  ...,  0.1166,  0.1010,  0.0875],\n",
      "        [ 0.3007, -0.7813, -0.8570,  ...,  0.1166,  0.1010,  0.0875],\n",
      "        [ 0.3007, -0.7813, -0.8570,  ...,  0.1166,  0.1010,  0.0875]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1934, -0.9711, -0.9862,  ...,  0.1165,  0.1010,  0.0875],\n",
      "        [-0.1934, -0.9711, -0.9862,  ...,  0.1165,  0.1010,  0.0875],\n",
      "        [-0.1934, -0.9711, -0.9862,  ...,  0.1165,  0.1010,  0.0875],\n",
      "        ...,\n",
      "        [-0.1934, -0.9711, -0.9862,  ...,  0.1165,  0.1010,  0.0875],\n",
      "        [-0.1934, -0.9711, -0.9862,  ...,  0.1165,  0.1010,  0.0875],\n",
      "        [-0.1934, -0.9711, -0.9862,  ...,  0.1165,  0.1010,  0.0875]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6401, -0.9816, -0.9783,  ...,  0.1165,  0.1009,  0.0874],\n",
      "        [-0.6401, -0.9816, -0.9783,  ...,  0.1165,  0.1009,  0.0874],\n",
      "        [-0.6401, -0.9816, -0.9783,  ...,  0.1165,  0.1009,  0.0874],\n",
      "        ...,\n",
      "        [-0.6401, -0.9816, -0.9783,  ...,  0.1165,  0.1009,  0.0874],\n",
      "        [-0.6401, -0.9816, -0.9783,  ...,  0.1165,  0.1009,  0.0874],\n",
      "        [-0.6401, -0.9816, -0.9783,  ...,  0.1165,  0.1009,  0.0874]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9301, -0.8110, -0.8346,  ...,  0.1164,  0.1008,  0.0874],\n",
      "        [-0.9301, -0.8110, -0.8346,  ...,  0.1164,  0.1008,  0.0874],\n",
      "        [-0.9301, -0.8110, -0.8346,  ...,  0.1164,  0.1008,  0.0874],\n",
      "        ...,\n",
      "        [-0.9301, -0.8110, -0.8346,  ...,  0.1164,  0.1008,  0.0874],\n",
      "        [-0.9301, -0.8110, -0.8346,  ...,  0.1164,  0.1008,  0.0874],\n",
      "        [-0.9301, -0.8110, -0.8346,  ...,  0.1164,  0.1008,  0.0874]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9923, -0.4907, -0.5749,  ...,  0.1163,  0.1008,  0.0873],\n",
      "        [-0.9923, -0.4907, -0.5749,  ...,  0.1163,  0.1008,  0.0873],\n",
      "        [-0.9923, -0.4907, -0.5749,  ...,  0.1163,  0.1008,  0.0873],\n",
      "        ...,\n",
      "        [-0.9923, -0.4907, -0.5749,  ...,  0.1163,  0.1008,  0.0873],\n",
      "        [-0.9923, -0.4907, -0.5749,  ...,  0.1163,  0.1008,  0.0873],\n",
      "        [-0.9923, -0.4907, -0.5749,  ...,  0.1163,  0.1008,  0.0873]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8116, -0.0798, -0.2353,  ...,  0.1162,  0.1007,  0.0872],\n",
      "        [-0.8116, -0.0798, -0.2353,  ...,  0.1162,  0.1007,  0.0872],\n",
      "        [-0.8116, -0.0798, -0.2353,  ...,  0.1162,  0.1007,  0.0872],\n",
      "        ...,\n",
      "        [-0.8116, -0.0798, -0.2353,  ...,  0.1162,  0.1007,  0.0872],\n",
      "        [-0.8116, -0.0798, -0.2353,  ...,  0.1162,  0.1007,  0.0872],\n",
      "        [-0.8116, -0.0798, -0.2353,  ...,  0.1162,  0.1007,  0.0872]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4322,  0.3458,  0.1370,  ...,  0.1162,  0.1006,  0.0872],\n",
      "        [-0.4322,  0.3458,  0.1370,  ...,  0.1162,  0.1006,  0.0872],\n",
      "        [-0.4322,  0.3458,  0.1370,  ...,  0.1162,  0.1006,  0.0872],\n",
      "        ...,\n",
      "        [-0.4322,  0.3458,  0.1370,  ...,  0.1162,  0.1006,  0.0872],\n",
      "        [-0.4322,  0.3458,  0.1370,  ...,  0.1162,  0.1006,  0.0872],\n",
      "        [-0.4322,  0.3458,  0.1370,  ...,  0.1162,  0.1006,  0.0872]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.0530, 0.7076, 0.4903,  ..., 0.1161, 0.1006, 0.0871],\n",
      "        [0.0530, 0.7076, 0.4903,  ..., 0.1161, 0.1006, 0.0871],\n",
      "        [0.0530, 0.7076, 0.4903,  ..., 0.1161, 0.1006, 0.0871],\n",
      "        ...,\n",
      "        [0.0530, 0.7076, 0.4903,  ..., 0.1161, 0.1006, 0.0871],\n",
      "        [0.0530, 0.7076, 0.4903,  ..., 0.1161, 0.1006, 0.0871],\n",
      "        [0.0530, 0.7076, 0.4903,  ..., 0.1161, 0.1006, 0.0871]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.5253, 0.9388, 0.7754,  ..., 0.1160, 0.1005, 0.0871],\n",
      "        [0.5253, 0.9388, 0.7754,  ..., 0.1160, 0.1005, 0.0871],\n",
      "        [0.5253, 0.9388, 0.7754,  ..., 0.1160, 0.1005, 0.0871],\n",
      "        ...,\n",
      "        [0.5253, 0.9388, 0.7754,  ..., 0.1160, 0.1005, 0.0871],\n",
      "        [0.5253, 0.9388, 0.7754,  ..., 0.1160, 0.1005, 0.0871],\n",
      "        [0.5253, 0.9388, 0.7754,  ..., 0.1160, 0.1005, 0.0871]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8689, 0.9967, 0.9528,  ..., 0.1159, 0.1004, 0.0870],\n",
      "        [0.8689, 0.9967, 0.9528,  ..., 0.1159, 0.1004, 0.0870],\n",
      "        [0.8689, 0.9967, 0.9528,  ..., 0.1159, 0.1004, 0.0870],\n",
      "        ...,\n",
      "        [0.8689, 0.9967, 0.9528,  ..., 0.1159, 0.1004, 0.0870],\n",
      "        [0.8689, 0.9967, 0.9528,  ..., 0.1159, 0.1004, 0.0870],\n",
      "        [0.8689, 0.9967, 0.9528,  ..., 0.1159, 0.1004, 0.0870]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9998, 0.8707, 0.9978,  ..., 0.1158, 0.1004, 0.0870],\n",
      "        [0.9998, 0.8707, 0.9978,  ..., 0.1158, 0.1004, 0.0870],\n",
      "        [0.9998, 0.8707, 0.9978,  ..., 0.1158, 0.1004, 0.0870],\n",
      "        ...,\n",
      "        [0.9998, 0.8707, 0.9978,  ..., 0.1158, 0.1004, 0.0870],\n",
      "        [0.9998, 0.8707, 0.9978,  ..., 0.1158, 0.1004, 0.0870],\n",
      "        [0.9998, 0.8707, 0.9978,  ..., 0.1158, 0.1004, 0.0870]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.8860, 0.5840, 0.9042,  ..., 0.1158, 0.1003, 0.0869],\n",
      "        [0.8860, 0.5840, 0.9042,  ..., 0.1158, 0.1003, 0.0869],\n",
      "        [0.8860, 0.5840, 0.9042,  ..., 0.1158, 0.1003, 0.0869],\n",
      "        ...,\n",
      "        [0.8860, 0.5840, 0.9042,  ..., 0.1158, 0.1003, 0.0869],\n",
      "        [0.8860, 0.5840, 0.9042,  ..., 0.1158, 0.1003, 0.0869],\n",
      "        [0.8860, 0.5840, 0.9042,  ..., 0.1158, 0.1003, 0.0869]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.5552, 0.1895, 0.6849,  ..., 0.1157, 0.1002, 0.0868],\n",
      "        [0.5552, 0.1895, 0.6849,  ..., 0.1157, 0.1002, 0.0868],\n",
      "        [0.5552, 0.1895, 0.6849,  ..., 0.1157, 0.1002, 0.0868],\n",
      "        ...,\n",
      "        [0.5552, 0.1895, 0.6849,  ..., 0.1157, 0.1002, 0.0868],\n",
      "        [0.5552, 0.1895, 0.6849,  ..., 0.1157, 0.1002, 0.0868],\n",
      "        [0.5552, 0.1895, 0.6849,  ..., 0.1157, 0.1002, 0.0868]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.0884, -0.2400,  0.3705,  ...,  0.1156,  0.1002,  0.0868],\n",
      "        [ 0.0884, -0.2400,  0.3705,  ...,  0.1156,  0.1002,  0.0868],\n",
      "        [ 0.0884, -0.2400,  0.3705,  ...,  0.1156,  0.1002,  0.0868],\n",
      "        ...,\n",
      "        [ 0.0884, -0.2400,  0.3705,  ...,  0.1156,  0.1002,  0.0868],\n",
      "        [ 0.0884, -0.2400,  0.3705,  ...,  0.1156,  0.1002,  0.0868],\n",
      "        [ 0.0884, -0.2400,  0.3705,  ...,  0.1156,  0.1002,  0.0868]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3999, -0.6252,  0.0045,  ...,  0.1155,  0.1001,  0.0867],\n",
      "        [-0.3999, -0.6252,  0.0045,  ...,  0.1155,  0.1001,  0.0867],\n",
      "        [-0.3999, -0.6252,  0.0045,  ...,  0.1155,  0.1001,  0.0867],\n",
      "        ...,\n",
      "        [-0.3999, -0.6252,  0.0045,  ...,  0.1155,  0.1001,  0.0867],\n",
      "        [-0.3999, -0.6252,  0.0045,  ...,  0.1155,  0.1001,  0.0867],\n",
      "        [-0.3999, -0.6252,  0.0045,  ...,  0.1155,  0.1001,  0.0867]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7904, -0.8950, -0.3620,  ...,  0.1155,  0.1000,  0.0867],\n",
      "        [-0.7904, -0.8950, -0.3620,  ...,  0.1155,  0.1000,  0.0867],\n",
      "        [-0.7904, -0.8950, -0.3620,  ...,  0.1155,  0.1000,  0.0867],\n",
      "        ...,\n",
      "        [-0.7904, -0.8950, -0.3620,  ...,  0.1155,  0.1000,  0.0867],\n",
      "        [-0.7904, -0.8950, -0.3620,  ...,  0.1155,  0.1000,  0.0867],\n",
      "        [-0.7904, -0.8950, -0.3620,  ...,  0.1155,  0.1000,  0.0867]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9873, -0.9996, -0.6782,  ...,  0.1154,  0.1000,  0.0866],\n",
      "        [-0.9873, -0.9996, -0.6782,  ...,  0.1154,  0.1000,  0.0866],\n",
      "        [-0.9873, -0.9996, -0.6782,  ...,  0.1154,  0.1000,  0.0866],\n",
      "        ...,\n",
      "        [-0.9873, -0.9996, -0.6782,  ...,  0.1154,  0.1000,  0.0866],\n",
      "        [-0.9873, -0.9996, -0.6782,  ...,  0.1154,  0.1000,  0.0866],\n",
      "        [-0.9873, -0.9996, -0.6782,  ...,  0.1154,  0.1000,  0.0866]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9425, -0.9197, -0.9002,  ...,  0.1153,  0.0999,  0.0866],\n",
      "        [-0.9425, -0.9197, -0.9002,  ...,  0.1153,  0.0999,  0.0866],\n",
      "        [-0.9425, -0.9197, -0.9002,  ...,  0.1153,  0.0999,  0.0866],\n",
      "        ...,\n",
      "        [-0.9425, -0.9197, -0.9002,  ...,  0.1153,  0.0999,  0.0866],\n",
      "        [-0.9425, -0.9197, -0.9002,  ...,  0.1153,  0.0999,  0.0866],\n",
      "        [-0.9425, -0.9197, -0.9002,  ...,  0.1153,  0.0999,  0.0866]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.6670, -0.6701, -0.9971,  ...,  0.1152,  0.0998,  0.0865],\n",
      "        [-0.6670, -0.6701, -0.9971,  ...,  0.1152,  0.0998,  0.0865],\n",
      "        [-0.6670, -0.6701, -0.9971,  ...,  0.1152,  0.0998,  0.0865],\n",
      "        ...,\n",
      "        [-0.6670, -0.6701, -0.9971,  ...,  0.1152,  0.0998,  0.0865],\n",
      "        [-0.6670, -0.6701, -0.9971,  ...,  0.1152,  0.0998,  0.0865],\n",
      "        [-0.6670, -0.6701, -0.9971,  ...,  0.1152,  0.0998,  0.0865]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2281, -0.2968, -0.9555,  ...,  0.1152,  0.0998,  0.0864],\n",
      "        [-0.2281, -0.2968, -0.9555,  ...,  0.1152,  0.0998,  0.0864],\n",
      "        [-0.2281, -0.2968, -0.9555,  ...,  0.1152,  0.0998,  0.0864],\n",
      "        ...,\n",
      "        [-0.2281, -0.2968, -0.9555,  ...,  0.1152,  0.0998,  0.0864],\n",
      "        [-0.2281, -0.2968, -0.9555,  ...,  0.1152,  0.0998,  0.0864],\n",
      "        [-0.2281, -0.2968, -0.9555,  ...,  0.1152,  0.0998,  0.0864]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2666,  0.1313, -0.7811,  ...,  0.1151,  0.0997,  0.0864],\n",
      "        [ 0.2666,  0.1313, -0.7811,  ...,  0.1151,  0.0997,  0.0864],\n",
      "        [ 0.2666,  0.1313, -0.7811,  ...,  0.1151,  0.0997,  0.0864],\n",
      "        ...,\n",
      "        [ 0.2666,  0.1313, -0.7811,  ...,  0.1151,  0.0997,  0.0864],\n",
      "        [ 0.2666,  0.1313, -0.7811,  ...,  0.1151,  0.0997,  0.0864],\n",
      "        [ 0.2666,  0.1313, -0.7811,  ...,  0.1151,  0.0997,  0.0864]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6960,  0.5351, -0.4982,  ...,  0.1150,  0.0996,  0.0863],\n",
      "        [ 0.6960,  0.5351, -0.4982,  ...,  0.1150,  0.0996,  0.0863],\n",
      "        [ 0.6960,  0.5351, -0.4982,  ...,  0.1150,  0.0996,  0.0863],\n",
      "        ...,\n",
      "        [ 0.6960,  0.5351, -0.4982,  ...,  0.1150,  0.0996,  0.0863],\n",
      "        [ 0.6960,  0.5351, -0.4982,  ...,  0.1150,  0.0996,  0.0863],\n",
      "        [ 0.6960,  0.5351, -0.4982,  ...,  0.1150,  0.0996,  0.0863]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9551,  0.8402, -0.1460,  ...,  0.1149,  0.0996,  0.0863],\n",
      "        [ 0.9551,  0.8402, -0.1460,  ...,  0.1149,  0.0996,  0.0863],\n",
      "        [ 0.9551,  0.8402, -0.1460,  ...,  0.1149,  0.0996,  0.0863],\n",
      "        ...,\n",
      "        [ 0.9551,  0.8402, -0.1460,  ...,  0.1149,  0.0996,  0.0863],\n",
      "        [ 0.9551,  0.8402, -0.1460,  ...,  0.1149,  0.0996,  0.0863],\n",
      "        [ 0.9551,  0.8402, -0.1460,  ...,  0.1149,  0.0996,  0.0863]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.9803, 0.9902, 0.2264,  ..., 0.1149, 0.0995, 0.0862],\n",
      "        [0.9803, 0.9902, 0.2264,  ..., 0.1149, 0.0995, 0.0862],\n",
      "        [0.9803, 0.9902, 0.2264,  ..., 0.1149, 0.0995, 0.0862],\n",
      "        ...,\n",
      "        [0.9803, 0.9902, 0.2264,  ..., 0.1149, 0.0995, 0.0862],\n",
      "        [0.9803, 0.9902, 0.2264,  ..., 0.1149, 0.0995, 0.0862],\n",
      "        [0.9803, 0.9902, 0.2264,  ..., 0.1149, 0.0995, 0.0862]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.7655, 0.9574, 0.5674,  ..., 0.1148, 0.0994, 0.0862],\n",
      "        [0.7655, 0.9574, 0.5674,  ..., 0.1148, 0.0994, 0.0862],\n",
      "        [0.7655, 0.9574, 0.5674,  ..., 0.1148, 0.0994, 0.0862],\n",
      "        ...,\n",
      "        [0.7655, 0.9574, 0.5674,  ..., 0.1148, 0.0994, 0.0862],\n",
      "        [0.7655, 0.9574, 0.5674,  ..., 0.1148, 0.0994, 0.0862],\n",
      "        [0.7655, 0.9574, 0.5674,  ..., 0.1148, 0.0994, 0.0862]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[0.3632, 0.7480, 0.8295,  ..., 0.1147, 0.0994, 0.0861],\n",
      "        [0.3632, 0.7480, 0.8295,  ..., 0.1147, 0.0994, 0.0861],\n",
      "        [0.3632, 0.7480, 0.8295,  ..., 0.1147, 0.0994, 0.0861],\n",
      "        ...,\n",
      "        [0.3632, 0.7480, 0.8295,  ..., 0.1147, 0.0994, 0.0861],\n",
      "        [0.3632, 0.7480, 0.8295,  ..., 0.1147, 0.0994, 0.0861],\n",
      "        [0.3632, 0.7480, 0.8295,  ..., 0.1147, 0.0994, 0.0861]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.1279,  0.4005,  0.9764,  ...,  0.1146,  0.0993,  0.0860],\n",
      "        [-0.1279,  0.4005,  0.9764,  ...,  0.1146,  0.0993,  0.0860],\n",
      "        [-0.1279,  0.4005,  0.9764,  ...,  0.1146,  0.0993,  0.0860],\n",
      "        ...,\n",
      "        [-0.1279,  0.4005,  0.9764,  ...,  0.1146,  0.0993,  0.0860],\n",
      "        [-0.1279,  0.4005,  0.9764,  ...,  0.1146,  0.0993,  0.0860],\n",
      "        [-0.1279,  0.4005,  0.9764,  ...,  0.1146,  0.0993,  0.0860]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5877, -0.0209,  0.9876,  ...,  0.1145,  0.0993,  0.0860],\n",
      "        [-0.5877, -0.0209,  0.9876,  ...,  0.1145,  0.0993,  0.0860],\n",
      "        [-0.5877, -0.0209,  0.9876,  ...,  0.1145,  0.0993,  0.0860],\n",
      "        ...,\n",
      "        [-0.5877, -0.0209,  0.9876,  ...,  0.1145,  0.0993,  0.0860],\n",
      "        [-0.5877, -0.0209,  0.9876,  ...,  0.1145,  0.0993,  0.0860],\n",
      "        [-0.5877, -0.0209,  0.9876,  ...,  0.1145,  0.0993,  0.0860]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9037, -0.4385,  0.8616,  ...,  0.1145,  0.0992,  0.0859],\n",
      "        [-0.9037, -0.4385,  0.8616,  ...,  0.1145,  0.0992,  0.0859],\n",
      "        [-0.9037, -0.4385,  0.8616,  ...,  0.1145,  0.0992,  0.0859],\n",
      "        ...,\n",
      "        [-0.9037, -0.4385,  0.8616,  ...,  0.1145,  0.0992,  0.0859],\n",
      "        [-0.9037, -0.4385,  0.8616,  ...,  0.1145,  0.0992,  0.0859],\n",
      "        [-0.9037, -0.4385,  0.8616,  ...,  0.1145,  0.0992,  0.0859]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9983, -0.7751,  0.6159,  ...,  0.1144,  0.0991,  0.0859],\n",
      "        [-0.9983, -0.7751,  0.6159,  ...,  0.1144,  0.0991,  0.0859],\n",
      "        [-0.9983, -0.7751,  0.6159,  ...,  0.1144,  0.0991,  0.0859],\n",
      "        ...,\n",
      "        [-0.9983, -0.7751,  0.6159,  ...,  0.1144,  0.0991,  0.0859],\n",
      "        [-0.9983, -0.7751,  0.6159,  ...,  0.1144,  0.0991,  0.0859],\n",
      "        [-0.9983, -0.7751,  0.6159,  ...,  0.1144,  0.0991,  0.0859]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8486, -0.9687,  0.2846,  ...,  0.1143,  0.0991,  0.0858],\n",
      "        [-0.8486, -0.9687,  0.2846,  ...,  0.1143,  0.0991,  0.0858],\n",
      "        [-0.8486, -0.9687,  0.2846,  ...,  0.1143,  0.0991,  0.0858],\n",
      "        ...,\n",
      "        [-0.8486, -0.9687,  0.2846,  ...,  0.1143,  0.0991,  0.0858],\n",
      "        [-0.8486, -0.9687,  0.2846,  ...,  0.1143,  0.0991,  0.0858],\n",
      "        [-0.8486, -0.9687,  0.2846,  ...,  0.1143,  0.0991,  0.0858]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.4911, -0.9835, -0.0863,  ...,  0.1142,  0.0990,  0.0858],\n",
      "        [-0.4911, -0.9835, -0.0863,  ...,  0.1142,  0.0990,  0.0858],\n",
      "        [-0.4911, -0.9835, -0.0863,  ...,  0.1142,  0.0990,  0.0858],\n",
      "        ...,\n",
      "        [-0.4911, -0.9835, -0.0863,  ...,  0.1142,  0.0990,  0.0858],\n",
      "        [-0.4911, -0.9835, -0.0863,  ...,  0.1142,  0.0990,  0.0858],\n",
      "        [-0.4911, -0.9835, -0.0863,  ...,  0.1142,  0.0990,  0.0858]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0133, -0.8168, -0.4451,  ...,  0.1142,  0.0989,  0.0857],\n",
      "        [-0.0133, -0.8168, -0.4451,  ...,  0.1142,  0.0989,  0.0857],\n",
      "        [-0.0133, -0.8168, -0.4451,  ...,  0.1142,  0.0989,  0.0857],\n",
      "        ...,\n",
      "        [-0.0133, -0.8168, -0.4451,  ...,  0.1142,  0.0989,  0.0857],\n",
      "        [-0.0133, -0.8168, -0.4451,  ...,  0.1142,  0.0989,  0.0857],\n",
      "        [-0.0133, -0.8168, -0.4451,  ...,  0.1142,  0.0989,  0.0857]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4677, -0.4993, -0.7421,  ...,  0.1141,  0.0989,  0.0856],\n",
      "        [ 0.4677, -0.4993, -0.7421,  ...,  0.1141,  0.0989,  0.0856],\n",
      "        [ 0.4677, -0.4993, -0.7421,  ...,  0.1141,  0.0989,  0.0856],\n",
      "        ...,\n",
      "        [ 0.4677, -0.4993, -0.7421,  ...,  0.1141,  0.0989,  0.0856],\n",
      "        [ 0.4677, -0.4993, -0.7421,  ...,  0.1141,  0.0989,  0.0856],\n",
      "        [ 0.4677, -0.4993, -0.7421,  ...,  0.1141,  0.0989,  0.0856]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8342, -0.0897, -0.9360,  ...,  0.1140,  0.0988,  0.0856],\n",
      "        [ 0.8342, -0.0897, -0.9360,  ...,  0.1140,  0.0988,  0.0856],\n",
      "        [ 0.8342, -0.0897, -0.9360,  ...,  0.1140,  0.0988,  0.0856],\n",
      "        ...,\n",
      "        [ 0.8342, -0.0897, -0.9360,  ...,  0.1140,  0.0988,  0.0856],\n",
      "        [ 0.8342, -0.0897, -0.9360,  ...,  0.1140,  0.0988,  0.0856],\n",
      "        [ 0.8342, -0.0897, -0.9360,  ...,  0.1140,  0.0988,  0.0856]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9965,  0.3365, -0.9999,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9965,  0.3365, -0.9999,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9965,  0.3365, -0.9999,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        ...,\n",
      "        [ 0.9965,  0.3365, -0.9999,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9965,  0.3365, -0.9999,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9965,  0.3365, -0.9999,  ...,  0.1139,  0.0987,  0.0855]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9148,  0.7005, -0.9248,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9148,  0.7005, -0.9248,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9148,  0.7005, -0.9248,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        ...,\n",
      "        [ 0.9148,  0.7005, -0.9248,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9148,  0.7005, -0.9248,  ...,  0.1139,  0.0987,  0.0855],\n",
      "        [ 0.9148,  0.7005, -0.9248,  ...,  0.1139,  0.0987,  0.0855]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6091,  0.9353, -0.7212,  ...,  0.1138,  0.0986,  0.0854],\n",
      "        [ 0.6091,  0.9353, -0.7212,  ...,  0.1138,  0.0986,  0.0854],\n",
      "        [ 0.6091,  0.9353, -0.7212,  ...,  0.1138,  0.0986,  0.0854],\n",
      "        ...,\n",
      "        [ 0.6091,  0.9353, -0.7212,  ...,  0.1138,  0.0986,  0.0854],\n",
      "        [ 0.6091,  0.9353, -0.7212,  ...,  0.1138,  0.0986,  0.0854],\n",
      "        [ 0.6091,  0.9353, -0.7212,  ...,  0.1138,  0.0986,  0.0854]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.1543,  0.9975, -0.4174,  ...,  0.1137,  0.0985,  0.0853],\n",
      "        [ 0.1543,  0.9975, -0.4174,  ...,  0.1137,  0.0985,  0.0853],\n",
      "        [ 0.1543,  0.9975, -0.4174,  ...,  0.1137,  0.0985,  0.0853],\n",
      "        ...,\n",
      "        [ 0.1543,  0.9975, -0.4174,  ...,  0.1137,  0.0985,  0.0853],\n",
      "        [ 0.1543,  0.9975, -0.4174,  ...,  0.1137,  0.0985,  0.0853],\n",
      "        [ 0.1543,  0.9975, -0.4174,  ...,  0.1137,  0.0985,  0.0853]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.3383,  0.8755, -0.0556,  ...,  0.1136,  0.0985,  0.0853],\n",
      "        [-0.3383,  0.8755, -0.0556,  ...,  0.1136,  0.0985,  0.0853],\n",
      "        [-0.3383,  0.8755, -0.0556,  ...,  0.1136,  0.0985,  0.0853],\n",
      "        ...,\n",
      "        [-0.3383,  0.8755, -0.0556,  ...,  0.1136,  0.0985,  0.0853],\n",
      "        [-0.3383,  0.8755, -0.0556,  ...,  0.1136,  0.0985,  0.0853],\n",
      "        [-0.3383,  0.8755, -0.0556,  ...,  0.1136,  0.0985,  0.0853]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7480,  0.5920,  0.3139,  ...,  0.1136,  0.0984,  0.0852],\n",
      "        [-0.7480,  0.5920,  0.3139,  ...,  0.1136,  0.0984,  0.0852],\n",
      "        [-0.7480,  0.5920,  0.3139,  ...,  0.1136,  0.0984,  0.0852],\n",
      "        ...,\n",
      "        [-0.7480,  0.5920,  0.3139,  ...,  0.1136,  0.0984,  0.0852],\n",
      "        [-0.7480,  0.5920,  0.3139,  ...,  0.1136,  0.0984,  0.0852],\n",
      "        [-0.7480,  0.5920,  0.3139,  ...,  0.1136,  0.0984,  0.0852]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9746,  0.1992,  0.6398,  ...,  0.1135,  0.0983,  0.0852],\n",
      "        [-0.9746,  0.1992,  0.6398,  ...,  0.1135,  0.0983,  0.0852],\n",
      "        [-0.9746,  0.1992,  0.6398,  ...,  0.1135,  0.0983,  0.0852],\n",
      "        ...,\n",
      "        [-0.9746,  0.1992,  0.6398,  ...,  0.1135,  0.0983,  0.0852],\n",
      "        [-0.9746,  0.1992,  0.6398,  ...,  0.1135,  0.0983,  0.0852],\n",
      "        [-0.9746,  0.1992,  0.6398,  ...,  0.1135,  0.0983,  0.0852]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.9626, -0.2304,  0.8768,  ...,  0.1134,  0.0983,  0.0851],\n",
      "        [-0.9626, -0.2304,  0.8768,  ...,  0.1134,  0.0983,  0.0851],\n",
      "        [-0.9626, -0.2304,  0.8768,  ...,  0.1134,  0.0983,  0.0851],\n",
      "        ...,\n",
      "        [-0.9626, -0.2304,  0.8768,  ...,  0.1134,  0.0983,  0.0851],\n",
      "        [-0.9626, -0.2304,  0.8768,  ...,  0.1134,  0.0983,  0.0851],\n",
      "        [-0.9626, -0.2304,  0.8768,  ...,  0.1134,  0.0983,  0.0851]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.7149, -0.6174,  0.9920,  ...,  0.1133,  0.0982,  0.0851],\n",
      "        [-0.7149, -0.6174,  0.9920,  ...,  0.1133,  0.0982,  0.0851],\n",
      "        [-0.7149, -0.6174,  0.9920,  ...,  0.1133,  0.0982,  0.0851],\n",
      "        ...,\n",
      "        [-0.7149, -0.6174,  0.9920,  ...,  0.1133,  0.0982,  0.0851],\n",
      "        [-0.7149, -0.6174,  0.9920,  ...,  0.1133,  0.0982,  0.0851],\n",
      "        [-0.7149, -0.6174,  0.9920,  ...,  0.1133,  0.0982,  0.0851]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.2922, -0.8905,  0.9693,  ...,  0.1132,  0.0981,  0.0850],\n",
      "        [-0.2922, -0.8905,  0.9693,  ...,  0.1132,  0.0981,  0.0850],\n",
      "        [-0.2922, -0.8905,  0.9693,  ...,  0.1132,  0.0981,  0.0850],\n",
      "        ...,\n",
      "        [-0.2922, -0.8905,  0.9693,  ...,  0.1132,  0.0981,  0.0850],\n",
      "        [-0.2922, -0.8905,  0.9693,  ...,  0.1132,  0.0981,  0.0850],\n",
      "        [-0.2922, -0.8905,  0.9693,  ...,  0.1132,  0.0981,  0.0850]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.2021, -0.9992,  0.8120,  ...,  0.1132,  0.0981,  0.0849],\n",
      "        [ 0.2021, -0.9992,  0.8120,  ...,  0.1132,  0.0981,  0.0849],\n",
      "        [ 0.2021, -0.9992,  0.8120,  ...,  0.1132,  0.0981,  0.0849],\n",
      "        ...,\n",
      "        [ 0.2021, -0.9992,  0.8120,  ...,  0.1132,  0.0981,  0.0849],\n",
      "        [ 0.2021, -0.9992,  0.8120,  ...,  0.1132,  0.0981,  0.0849],\n",
      "        [ 0.2021, -0.9992,  0.8120,  ...,  0.1132,  0.0981,  0.0849]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6469, -0.9235,  0.5418,  ...,  0.1131,  0.0980,  0.0849],\n",
      "        [ 0.6469, -0.9235,  0.5418,  ...,  0.1131,  0.0980,  0.0849],\n",
      "        [ 0.6469, -0.9235,  0.5418,  ...,  0.1131,  0.0980,  0.0849],\n",
      "        ...,\n",
      "        [ 0.6469, -0.9235,  0.5418,  ...,  0.1131,  0.0980,  0.0849],\n",
      "        [ 0.6469, -0.9235,  0.5418,  ...,  0.1131,  0.0980,  0.0849],\n",
      "        [ 0.6469, -0.9235,  0.5418,  ...,  0.1131,  0.0980,  0.0849]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9333, -0.6774,  0.1964,  ...,  0.1130,  0.0979,  0.0848],\n",
      "        [ 0.9333, -0.6774,  0.1964,  ...,  0.1130,  0.0979,  0.0848],\n",
      "        [ 0.9333, -0.6774,  0.1964,  ...,  0.1130,  0.0979,  0.0848],\n",
      "        ...,\n",
      "        [ 0.9333, -0.6774,  0.1964,  ...,  0.1130,  0.0979,  0.0848],\n",
      "        [ 0.9333, -0.6774,  0.1964,  ...,  0.1130,  0.0979,  0.0848],\n",
      "        [ 0.9333, -0.6774,  0.1964,  ...,  0.1130,  0.0979,  0.0848]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9912, -0.3063, -0.1763,  ...,  0.1129,  0.0979,  0.0848],\n",
      "        [ 0.9912, -0.3063, -0.1763,  ...,  0.1129,  0.0979,  0.0848],\n",
      "        [ 0.9912, -0.3063, -0.1763,  ...,  0.1129,  0.0979,  0.0848],\n",
      "        ...,\n",
      "        [ 0.9912, -0.3063, -0.1763,  ...,  0.1129,  0.0979,  0.0848],\n",
      "        [ 0.9912, -0.3063, -0.1763,  ...,  0.1129,  0.0979,  0.0848],\n",
      "        [ 0.9912, -0.3063, -0.1763,  ...,  0.1129,  0.0979,  0.0848]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.8064,  0.1214, -0.5246,  ...,  0.1129,  0.0978,  0.0847],\n",
      "        [ 0.8064,  0.1214, -0.5246,  ...,  0.1129,  0.0978,  0.0847],\n",
      "        [ 0.8064,  0.1214, -0.5246,  ...,  0.1129,  0.0978,  0.0847],\n",
      "        ...,\n",
      "        [ 0.8064,  0.1214, -0.5246,  ...,  0.1129,  0.0978,  0.0847],\n",
      "        [ 0.8064,  0.1214, -0.5246,  ...,  0.1129,  0.0978,  0.0847],\n",
      "        [ 0.8064,  0.1214, -0.5246,  ...,  0.1129,  0.0978,  0.0847]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4242,  0.5267, -0.7999,  ...,  0.1128,  0.0977,  0.0847],\n",
      "        [ 0.4242,  0.5267, -0.7999,  ...,  0.1128,  0.0977,  0.0847],\n",
      "        [ 0.4242,  0.5267, -0.7999,  ...,  0.1128,  0.0977,  0.0847],\n",
      "        ...,\n",
      "        [ 0.4242,  0.5267, -0.7999,  ...,  0.1128,  0.0977,  0.0847],\n",
      "        [ 0.4242,  0.5267, -0.7999,  ...,  0.1128,  0.0977,  0.0847],\n",
      "        [ 0.4242,  0.5267, -0.7999,  ...,  0.1128,  0.0977,  0.0847]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0618,  0.8348, -0.9641,  ...,  0.1127,  0.0977,  0.0846],\n",
      "        [-0.0618,  0.8348, -0.9641,  ...,  0.1127,  0.0977,  0.0846],\n",
      "        [-0.0618,  0.8348, -0.9641,  ...,  0.1127,  0.0977,  0.0846],\n",
      "        ...,\n",
      "        [-0.0618,  0.8348, -0.9641,  ...,  0.1127,  0.0977,  0.0846],\n",
      "        [-0.0618,  0.8348, -0.9641,  ...,  0.1127,  0.0977,  0.0846],\n",
      "        [-0.0618,  0.8348, -0.9641,  ...,  0.1127,  0.0977,  0.0846]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5328,  0.9888, -0.9944,  ...,  0.1126,  0.0976,  0.0845],\n",
      "        [-0.5328,  0.9888, -0.9944,  ...,  0.1126,  0.0976,  0.0845],\n",
      "        [-0.5328,  0.9888, -0.9944,  ...,  0.1126,  0.0976,  0.0845],\n",
      "        ...,\n",
      "        [-0.5328,  0.9888, -0.9944,  ...,  0.1126,  0.0976,  0.0845],\n",
      "        [-0.5328,  0.9888, -0.9944,  ...,  0.1126,  0.0976,  0.0845],\n",
      "        [-0.5328,  0.9888, -0.9944,  ...,  0.1126,  0.0976,  0.0845]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8733,  0.9603, -0.8864,  ...,  0.1126,  0.0975,  0.0845],\n",
      "        [-0.8733,  0.9603, -0.8864,  ...,  0.1126,  0.0975,  0.0845],\n",
      "        [-0.8733,  0.9603, -0.8864,  ...,  0.1126,  0.0975,  0.0845],\n",
      "        ...,\n",
      "        [-0.8733,  0.9603, -0.8864,  ...,  0.1126,  0.0975,  0.0845],\n",
      "        [-0.8733,  0.9603, -0.8864,  ...,  0.1126,  0.0975,  0.0845],\n",
      "        [-0.8733,  0.9603, -0.8864,  ...,  0.1126,  0.0975,  0.0845]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-1.0000,  0.7545, -0.6553,  ...,  0.1125,  0.0975,  0.0844],\n",
      "        [-1.0000,  0.7545, -0.6553,  ...,  0.1125,  0.0975,  0.0844],\n",
      "        [-1.0000,  0.7545, -0.6553,  ...,  0.1125,  0.0975,  0.0844],\n",
      "        ...,\n",
      "        [-1.0000,  0.7545, -0.6553,  ...,  0.1125,  0.0975,  0.0844],\n",
      "        [-1.0000,  0.7545, -0.6553,  ...,  0.1125,  0.0975,  0.0844],\n",
      "        [-1.0000,  0.7545, -0.6553,  ...,  0.1125,  0.0975,  0.0844]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.8818,  0.4096, -0.3332,  ...,  0.1124,  0.0974,  0.0844],\n",
      "        [-0.8818,  0.4096, -0.3332,  ...,  0.1124,  0.0974,  0.0844],\n",
      "        [-0.8818,  0.4096, -0.3332,  ...,  0.1124,  0.0974,  0.0844],\n",
      "        ...,\n",
      "        [-0.8818,  0.4096, -0.3332,  ...,  0.1124,  0.0974,  0.0844],\n",
      "        [-0.8818,  0.4096, -0.3332,  ...,  0.1124,  0.0974,  0.0844],\n",
      "        [-0.8818,  0.4096, -0.3332,  ...,  0.1124,  0.0974,  0.0844]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.5478, -0.0110,  0.0352,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.5478, -0.0110,  0.0352,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.5478, -0.0110,  0.0352,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        ...,\n",
      "        [-0.5478, -0.0110,  0.0352,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.5478, -0.0110,  0.0352,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.5478, -0.0110,  0.0352,  ...,  0.1123,  0.0973,  0.0843]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[-0.0796, -0.4296,  0.3988,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.0796, -0.4296,  0.3988,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.0796, -0.4296,  0.3988,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        ...,\n",
      "        [-0.0796, -0.4296,  0.3988,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.0796, -0.4296,  0.3988,  ...,  0.1123,  0.0973,  0.0843],\n",
      "        [-0.0796, -0.4296,  0.3988,  ...,  0.1123,  0.0973,  0.0843]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.4080, -0.7688,  0.7069,  ...,  0.1122,  0.0972,  0.0842],\n",
      "        [ 0.4080, -0.7688,  0.7069,  ...,  0.1122,  0.0972,  0.0842],\n",
      "        [ 0.4080, -0.7688,  0.7069,  ...,  0.1122,  0.0972,  0.0842],\n",
      "        ...,\n",
      "        [ 0.4080, -0.7688,  0.7069,  ...,  0.1122,  0.0972,  0.0842],\n",
      "        [ 0.4080, -0.7688,  0.7069,  ...,  0.1122,  0.0972,  0.0842],\n",
      "        [ 0.4080, -0.7688,  0.7069,  ...,  0.1122,  0.0972,  0.0842]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.7958, -0.9662,  0.9169,  ...,  0.1121,  0.0971,  0.0841],\n",
      "        [ 0.7958, -0.9662,  0.9169,  ...,  0.1121,  0.0971,  0.0841],\n",
      "        [ 0.7958, -0.9662,  0.9169,  ...,  0.1121,  0.0971,  0.0841],\n",
      "        ...,\n",
      "        [ 0.7958, -0.9662,  0.9169,  ...,  0.1121,  0.0971,  0.0841],\n",
      "        [ 0.7958, -0.9662,  0.9169,  ...,  0.1121,  0.0971,  0.0841],\n",
      "        [ 0.7958, -0.9662,  0.9169,  ...,  0.1121,  0.0971,  0.0841]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9887, -0.9852,  0.9994,  ...,  0.1120,  0.0971,  0.0841],\n",
      "        [ 0.9887, -0.9852,  0.9994,  ...,  0.1120,  0.0971,  0.0841],\n",
      "        [ 0.9887, -0.9852,  0.9994,  ...,  0.1120,  0.0971,  0.0841],\n",
      "        ...,\n",
      "        [ 0.9887, -0.9852,  0.9994,  ...,  0.1120,  0.0971,  0.0841],\n",
      "        [ 0.9887, -0.9852,  0.9994,  ...,  0.1120,  0.0971,  0.0841],\n",
      "        [ 0.9887, -0.9852,  0.9994,  ...,  0.1120,  0.0971,  0.0841]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.9395, -0.8224,  0.9430,  ...,  0.1119,  0.0970,  0.0840],\n",
      "        [ 0.9395, -0.8224,  0.9430,  ...,  0.1119,  0.0970,  0.0840],\n",
      "        [ 0.9395, -0.8224,  0.9430,  ...,  0.1119,  0.0970,  0.0840],\n",
      "        ...,\n",
      "        [ 0.9395, -0.8224,  0.9430,  ...,  0.1119,  0.0970,  0.0840],\n",
      "        [ 0.9395, -0.8224,  0.9430,  ...,  0.1119,  0.0970,  0.0840],\n",
      "        [ 0.9395, -0.8224,  0.9430,  ...,  0.1119,  0.0970,  0.0840]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n",
      "input_trans_hideden_states.shape torch.Size([19, 128, 768])\n",
      "Forward step\n",
      "N x dim Tensor of positional embeddings tensor([[ 0.6604, -0.5078,  0.7557,  ...,  0.1119,  0.0969,  0.0840],\n",
      "        [ 0.6604, -0.5078,  0.7557,  ...,  0.1119,  0.0969,  0.0840],\n",
      "        [ 0.6604, -0.5078,  0.7557,  ...,  0.1119,  0.0969,  0.0840],\n",
      "        ...,\n",
      "        [ 0.6604, -0.5078,  0.7557,  ...,  0.1119,  0.0969,  0.0840],\n",
      "        [ 0.6604, -0.5078,  0.7557,  ...,  0.1119,  0.0969,  0.0840],\n",
      "        [ 0.6604, -0.5078,  0.7557,  ...,  0.1119,  0.0969,  0.0840]])\n",
      "Size of embedding torch.Size([19, 128])\n",
      "x: an [N x C x ...] Tensor of inputs size: torch.Size([19, 128, 768])\n",
      "emb_x.shape, emb_t.shape, self.position_embeddings\n",
      "torch.Size([19, 128, 768]) torch.Size([19, 768]) Embedding(512, 768)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "# FIXME just this time load the same data\n",
    "data_valid = iter(data_loader)\n",
    "\n",
    "all_test_data = []\n",
    "\n",
    "# NOTE can do a handling for separate nodes of GPU, just loading in one go here\n",
    "try:\n",
    "    while True:\n",
    "        batch, cond = next(data_valid)\n",
    "        # print(batch.shape)\n",
    "        all_test_data.append(cond)\n",
    "\n",
    "except StopIteration:\n",
    "    print('### End of reading iteration...')\n",
    "\n",
    "from tqdm import tqdm\n",
    "iterator = tqdm(all_test_data)\n",
    "\n",
    "# iterator = iter(all_test_data)\n",
    "\n",
    "for cond in iterator:\n",
    "    input_ids_x = cond.pop('input_ids')#.to(dist_util.dev())\n",
    "    x_start = model.get_embeds(input_ids_x)\n",
    "    input_ids_mask = cond.pop('input_mask')\n",
    "    input_ids_mask_ori = input_ids_mask\n",
    "\n",
    "    noise = th.randn_like(x_start)\n",
    "    input_ids_mask = th.broadcast_to(input_ids_mask.unsqueeze(dim=-1), x_start.shape)#.to(dist_util.dev())\n",
    "    x_noised = th.where(input_ids_mask == 0, x_start, noise)\n",
    "\n",
    "\n",
    "    # step argument\n",
    "    # if less than diffusion training steps, like 1000, use ddim sampling\n",
    "    # NOTE we have diffusion_steps = 2000, just use that for simplificity\n",
    "\n",
    "    # if args.step == args.diffusion_steps:\n",
    "    use_ddim = False\n",
    "    step_gap = 1\n",
    "\n",
    "    sample_fn = diffusion.p_sample_loop\n",
    "\n",
    "\n",
    "    # args.seq_len = seq_len \n",
    "    # args.hidden_dim = hidden_dim\n",
    "    sample_shape = (x_start.shape[0], seq_len, hidden_dim)\n",
    "\n",
    "    class Args:\n",
    "        seq_len = seq_len\n",
    "        hidden_dim = hidden_dim\n",
    "        use_ddim = False \n",
    "\n",
    "    args = Args()\n",
    "\n",
    "\n",
    "    samples = sample_fn(\n",
    "            model,\n",
    "            sample_shape,\n",
    "            noise=x_noised,\n",
    "            # clip_denoised=args.clip_denoised, takes default=True\n",
    "            # TODO check that params given to denoised_fn_round are correct\n",
    "            # partial(denoised_fn_round, args, model_emb)\n",
    "            # denoised_fn: if not None, a function which applies to the\n",
    "            # x_start prediction before it is used to sample.\n",
    "            # FIXME is this function required?\n",
    "            # denoised_fn=denoised_fn_round(model=model_emb, text_emb=model_emb),\n",
    "            model_kwargs={},\n",
    "            # top_p=args.top_p, -> top p used in sampling, default is off\n",
    "            clamp_step=1700, #args.clamp_step,\n",
    "            clamp_first=True, # clamp first mode\n",
    "            mask=input_ids_mask,\n",
    "            x_start=x_start,\n",
    "            gap=step_gap\n",
    "        )\n",
    "    \n",
    "    sample = samples[-1]\n",
    "\n",
    "    print('decoding for seq2seq', )\n",
    "    print(sample.shape)\n",
    "\n",
    "    logits = model.get_logits(sample)  # bsz, seqlen, vocab\n",
    "    cands = th.topk(logits, k=1, dim=-1)\n",
    "\n",
    "    word_lst_recover = []\n",
    "    word_lst_ref = []\n",
    "    word_lst_source = []\n",
    "\n",
    "    for seq, input_mask in zip(cands.indices, input_ids_mask_ori):\n",
    "        len_x = args.seq_len - sum(input_mask).tolist()\n",
    "        tokens = tokenizer.decode_token(seq[len_x:])\n",
    "        word_lst_recover.append(tokens)\n",
    "\n",
    "    for seq, input_mask in zip(input_ids_x, input_ids_mask_ori):\n",
    "        # tokens = tokenizer.decode_token(seq)\n",
    "        len_x = args.seq_len - sum(input_mask).tolist()\n",
    "        word_lst_source.append(tokenizer.decode_token(seq[:len_x]))\n",
    "        word_lst_ref.append(tokenizer.decode_token(seq[len_x:]))\n",
    "\n",
    "    # for i in range(world_size):\n",
    "    #     if i == rank:  # Write files sequentially\n",
    "    #         fout = open(out_path, 'a')\n",
    "    #         for (recov, ref, src) in zip(word_lst_recover, word_lst_ref, word_lst_source):\n",
    "    #             print(json.dumps({\"recover\": recov, \"reference\": ref, \"source\": src}), file=fout)\n",
    "    #         fout.close()\n",
    "    #     dist.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lst_recover[0]\n",
    "word_lst_ref[0]\n",
    "word_lst_source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compare with original input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i == rank:  # Write files sequentially\n",
    "out_path = \"test.txt\"\n",
    "fout = open(out_path, 'a')\n",
    "for (recov, ref, src) in zip(word_lst_recover, word_lst_ref, word_lst_source):\n",
    "    print(json.dumps({\"recover\": recov, \"reference\": ref, \"source\": src}), file=fout)\n",
    "fout.close()\n",
    "            # dist.barrier()\n",
    "\n",
    "    # print('### Total takes {:.2f}s .....'.format(time.time() - start_t))\n",
    "print(f'### Written the decoded output to {out_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
